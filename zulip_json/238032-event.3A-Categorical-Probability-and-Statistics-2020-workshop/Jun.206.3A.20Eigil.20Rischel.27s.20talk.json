[
    {
        "content": "<p>Hey all,<br>\nThis is the discussion thread of Eigil Rischel's talk, \"Introduction to Markov categories\".<br>\nThe talk, besides being on Zoom, is livestreamed here: <a href=\"https://youtu.be/zn7k15sq_TE\">https://youtu.be/zn7k15sq_TE</a></p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"zn7k15sq_TE\" href=\"https://youtu.be/zn7k15sq_TE\"><img src=\"https://i.ytimg.com/vi/zn7k15sq_TE/default.jpg\"></a></div>",
        "id": 199794150,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591297867
    },
    {
        "content": "<p>Date and time: Saturday, 6 Jun, 13h UTC.</p>",
        "id": 199796165,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591298661
    },
    {
        "content": "<p>(Just started)</p>",
        "id": 199974070,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591448457
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"285161\">@Oliver Shetler</span>  (I have the correct Oliver, right?) mentioned this during the talk: \"If a statistic is not sufficient, then your estimator depends on the parameter that you don’t know, so you get a “catch 22” where you need the parameter for your estimator to work. Sufficiency is just the condition for avoiding this.\" I'd like to know what this means exactly, which is why I want to keep it here for a record. In particular, what is an <em>estimator</em>?</p>",
        "id": 199976257,
        "sender_full_name": "Arthur Parzygnat",
        "timestamp": 1591451968
    },
    {
        "content": "<p>Does anyone know if there's a nice category generalizing Gauss, where one allows for more general exponential families?</p>",
        "id": 199976351,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591452093
    },
    {
        "content": "<p>@Eigil Rischel Nice talk, thanks! <br>\nI have a question on your remark at the end, that it is hard to treat measures with density in a Markov category. You said that the problem is that the comultiplication produces Dirac measures, which have no density. Did you just mean that, because of this, you cannot define a Markov category of measurable spaces where _every_ measure has a density? Or are there more problems?</p>",
        "id": 199976412,
        "sender_full_name": "Peter Arndt",
        "timestamp": 1591452165
    },
    {
        "content": "<p>Hi <span class=\"user-mention\" data-user-id=\"309295\">@Dario Stein</span>! I'd be very interested in seeing the type theory or internal language of Markov categories that you mentioned, if you think that you could sketch it here? And how would you express the <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Tutorial.3A.20What.20is.20a.20probability.20monad.3F.20%28Paolo.20Perrone%29/near/199887554\">existence of conditionals</a>? (Conditionals aren't part of the vanilla definition, but can be imposed as an additional axiom.) Can you have an inference rule for conditioning despite the issue of non-uniqueness of conditionals?</p>\n<p>And how would you express additional axioms? I guess in terms of equality judgments? I have two other axioms called \"positivity\" and \"causality\" (although the latter may deserve a better name) which are logically in the form of Horn formulas. Would you translate axioms of this type into inference rules for equality judgments in the obvious way?</p>",
        "id": 199976491,
        "sender_full_name": "Tobias Fritz",
        "timestamp": 1591452262
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"296639\">Arthur Parzygnat</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Eigil.20Rischel's.20talk/near/199976257\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"285161\">Oliver Shetler</span>  (I have the correct Oliver, right?) mentioned this during the talk: \"If a statistic is not sufficient, then your estimator depends on the parameter that you don’t know, so you get a “catch 22” where you need the parameter for your estimator to work. Sufficiency is just the condition for avoiding this.\" I'd like to know what this means exactly, which is why I want to keep it here for a record. In particular, what is an <em>estimator</em>?</p>\n</blockquote>\n<p>Hi Arthur. Thanks for asking. I was hoping to clarify the meaning of statistical sufficiency for the non-statisticians in the crowd. In this context, an estimator is a function from a sample to the real numbers. For example, if I take the average of my sample, that's an estimator. Another example would be if I take the average, and then compute the sum of the squared differences between each sample point and the average, and then divide by the degrees of freedom (in this case that's n-1 where n is the sample size). That would be an estimator of the variance of an assumed normal distribution.</p>\n<p>The reason we call these functions \"estimators\" is because we are pretty much always trying to use them to estimate a parameter of a distribution. For example, when we take the average of a sample, we are trying to estimate the true mean of the distribution.</p>\n<p>So if the goal of an estimator is to learn something about the parameter, it makes sense that we would want to make sure that the estimator does not depend on the parameter as input. This might seem trivial for the example of a mean, but it can happen more often than you'd think with complicated estimators. When that happens, the estimator is useless because you have to assume the parameter in order to use it. This is the \"catech 22\" I was referring to. You need the parameter to get the estimate, but you want the estimate so you can learn about the parameter.</p>\n<p>Statistical sufficiency just says that the parameter is independent from the estimator, so you avoid this \"catch 22.\"</p>",
        "id": 199977272,
        "sender_full_name": "Oliver Shetler",
        "timestamp": 1591453346
    },
    {
        "content": "<p>This was incredibly helpful, thank you!</p>",
        "id": 199977383,
        "sender_full_name": "Arthur Parzygnat",
        "timestamp": 1591453540
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"276165\">@Eigil Rischel</span>  or <span class=\"user-mention\" data-user-id=\"276702\">@Tobias Fritz</span> , have you worked on demonstrating that estimators are unbiased using this categorical framework? Also, what about using the string diagrams in particular?</p>",
        "id": 199978230,
        "sender_full_name": "Oliver Shetler",
        "timestamp": 1591454715
    },
    {
        "content": "<p>No, we haven't worked on estimators and unbiasedness yet. But our next speaker <span class=\"user-mention\" data-user-id=\"275965\">@Evan Patterson</span>  may have more to say about this! In order for the formalism to be convincing as a complete framework for statistics, I agree that this will have to be done.</p>",
        "id": 199979561,
        "sender_full_name": "Tobias Fritz",
        "timestamp": 1591456443
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276702\">Tobias Fritz</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Eigil.20Rischel's.20talk/near/199976491\">said</a>:</p>\n<blockquote>\n<p>Hi <span class=\"user-mention silent\" data-user-id=\"309295\">Dario Stein</span>! I'd be very interested in seeing the type theory or internal language of Markov categories that you mentioned, if you think that you could sketch it here? And how would you express the <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Tutorial.3A.20What.20is.20a.20probability.20monad.3F.20%28Paolo.20Perrone%29/near/199887554\">existence of conditionals</a>? (Conditionals aren't part of the vanilla definition, but can be imposed as an additional axiom.) Can you have an inference rule for conditioning despite the issue of non-uniqueness of conditionals?</p>\n<p>And how would you express additional axioms? I guess in terms of equality judgments? I have two other axioms called \"positivity\" and \"causality\" (although the latter may deserve a better name) which are logically in the form of Horn formulas. Would you translate axioms of this type into inference rules for equality judgments in the obvious way?</p>\n</blockquote>\n<p>Hi <span class=\"user-mention\" data-user-id=\"276702\">@Tobias Fritz</span> , I would imagine the internal language of a Markov category pretty much looks like the first-order fragment of a language like ML. So you can write </p>\n<p>let x = normal(0,1) in (2*x + 3,x)<br>\nor<br>\n(2*normal(0,1), normal(0,1))</p>\n<p>where normal, *, +, and the constants are just morphisms of Stoch. A slight subtlety is the the treatment of tuples, as they denote the tensor product and not cartesian product. However unlike in linear logic we can make use of the comonoids to copy freely and project out from tuples, so it wouldn't look too bad.  Unlike in <a href=\"http://www.cs.ox.ac.uk/people/samuel.staton/papers/esop2017.pdf\">http://www.cs.ox.ac.uk/people/samuel.staton/papers/esop2017.pdf</a>, there is no a-priori distinction between deterministic and probabilistic judgements, but it would also be interesting to annotate determinism explicitly, as you get better equations and could make use of e.g. positivity/causality. Properties of the Markov category would feature as admissible equations in some program logic. This is a useful practical view on probabilistic languages anyways, e.g. <a href=\"https://arxiv.org/pdf/1802.09598.pdf\">https://arxiv.org/pdf/1802.09598.pdf</a>.</p>\n<p>The question of a syntax for conditionals is a very good one. I'm currently trying to model it as a separate algebraic effect. Conditioning isn't a morphism in the Markov category, but maybe in a larger category. The question is then whether this larger category still has nice properties (it wouldn't be a Markov category as the conditioning effect is not discardable). Other difficulties are keeping track of supports to deal with the nonuniqueness of disintegrations, and how conditioning interacts with other program equations (in general not well: this is Borel's paradox).</p>",
        "id": 199980687,
        "sender_full_name": "Dario Stein",
        "timestamp": 1591457976
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"275989\">Paolo Perrone</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Eigil.20Rischel's.20talk/near/199976351\">said</a>:</p>\n<blockquote>\n<p>Does anyone know if there's a nice category generalizing Gauss, where one allows for more general exponential families?</p>\n</blockquote>\n<p>That's a great question. Couldn't you take any family of conjugate priors (<a href=\"https://en.wikipedia.org/wiki/Conjugate_prior\">https://en.wikipedia.org/wiki/Conjugate_prior</a>) and make a Markov category of that?</p>",
        "id": 199982888,
        "sender_full_name": "Manuel Bärenz",
        "timestamp": 1591461061
    },
    {
        "content": "<p>I've been wondering that too! And in particular whether conjugate priors give us a Markov category with conditionals. It's not obvious, since the parameter space and the sample space of an exponential family seem to have different kind of structure, with in particular the parameter space being a vector space. But this is the sort of thing that <span class=\"user-mention\" data-user-id=\"275965\">@Evan Patterson</span> 's lattices of supplies are made for, so perhaps he will be able to say more.</p>",
        "id": 199984883,
        "sender_full_name": "Tobias Fritz",
        "timestamp": 1591463949
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276702\">Tobias Fritz</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Eigil.20Rischel's.20talk/near/199979561\">said</a>:</p>\n<blockquote>\n<p>No, we haven't worked on estimators and unbiasedness yet. But our next speaker <span class=\"user-mention silent\" data-user-id=\"275965\">Evan Patterson</span>  may have more to say about this! In order for the formalism to be convincing as a complete framework for statistics, I agree that this will have to be done.</p>\n</blockquote>\n<p>A statistician might distinguish between three stages of fitting a model:</p>\n<ol>\n<li>Specifying a statistical model</li>\n<li>Choosing an estimator for the model</li>\n<li>Finding an algorithm to compute the estimator</li>\n</ol>\n<p>My impression is that most work on CT + stats, certainly including my own, has been about (1), with work on probabilistic programming also being about (3). I completely agree with Tobias that a fully convincing formalism would say something about (2).</p>\n<p>One idea I've thought about superficially is introducing an expectation operator <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"double-struck\">E</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbb{E}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68889em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">E</span></span></span></span></span> into the formalism, so that if <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>M</mi><mo>:</mo><mi mathvariant=\"script\">X</mi><mo>→</mo><mi mathvariant=\"script\">Y</mi></mrow><annotation encoding=\"application/x-tex\">M: \\mathcal{X} \\to \\mathcal{Y}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.14643em;\">X</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.78055em;vertical-align:-0.09722em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.08222em;\">Y</span></span></span></span></span> is a Markov kernel with <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"script\">Y</mi></mrow><annotation encoding=\"application/x-tex\">\\mathcal{Y}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.78055em;vertical-align:-0.09722em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.08222em;\">Y</span></span></span></span></span> a vector space, then <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"double-struck\">E</mi><mi>M</mi><mo>:</mo><mi mathvariant=\"script\">X</mi><mo>→</mo><mi mathvariant=\"script\">Y</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbb{E} M: \\mathcal{X} \\to \\mathcal{Y}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68889em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">E</span></span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.14643em;\">X</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.78055em;vertical-align:-0.09722em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.08222em;\">Y</span></span></span></span></span> is the deterministic kernel <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"double-struck\">E</mi><mi>M</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>:</mo><mo>=</mo><mi mathvariant=\"double-struck\">E</mi><mo stretchy=\"false\">[</mo><mi>M</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">(\\mathbb{E} M)(x) := \\mathbb{E}[M(x)]</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathbb\">E</span></span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"mclose\">)</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.36687em;vertical-align:0em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">E</span></span><span class=\"mopen\">[</span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span><span class=\"mclose\">]</span></span></span></span>. This would allow one to express unbiasedness. In terms of statistical theories, one could express that a probability distribution is parameterized by mean, which would often be useful. I think it would be interesting to properly work out this idea.</p>",
        "id": 199987626,
        "sender_full_name": "Evan Patterson",
        "timestamp": 1591468575
    },
    {
        "content": "<p>Hi Eigil. I liked your talk. Regarding the formulation of the infinite tensor, that I asked about at the end, would an equivalent way of axiomatising this be to say that the category of deterministic maps has countable products and the inclusion functor into general maps preserves cofiltered limits of diagrams of deterministic maps consisting of projections between finite  products?</p>",
        "id": 199988574,
        "sender_full_name": "Alex Simpson",
        "timestamp": 1591470150
    },
    {
        "content": "<p>In this case, then, the goal would simply be to show that \\mathbb{E}[M(X)] \\approx M(\\mathbb{E}[X])E[M(X)]≈M(E[X])?</p>",
        "id": 199988854,
        "sender_full_name": "Oliver Shetler",
        "timestamp": 1591470602
    },
    {
        "content": "<blockquote>\n<p>In this case, then, the goal would simply be to show that <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"double-struck\">E</mi><mo stretchy=\"false\">[</mo><mi>M</mi><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">]</mo><mo>≈</mo><mi>M</mi><mo stretchy=\"false\">(</mo><mi mathvariant=\"double-struck\">E</mi><mo stretchy=\"false\">[</mo><mi>X</mi><mo stretchy=\"false\">]</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\mathbb{E}[M(X)] \\approx M(\\mathbb{E}[X])</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">E</span></span><span class=\"mopen\">[</span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span><span class=\"mclose\">)</span><span class=\"mclose\">]</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathbb\">E</span></span><span class=\"mopen\">[</span><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span><span class=\"mclose\">]</span><span class=\"mclose\">)</span></span></span></span>?</p>\n</blockquote>\n<p>I was thinking that given a statistical model <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo>:</mo><mi mathvariant=\"normal\">Ω</mi><mo>→</mo><mi mathvariant=\"script\">X</mi></mrow><annotation encoding=\"application/x-tex\">P: \\Omega \\to \\mathcal{X}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\">Ω</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.14643em;\">X</span></span></span></span></span> and an estimator <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>d</mi><mo>:</mo><mi mathvariant=\"script\">X</mi><mo>→</mo><mi mathvariant=\"normal\">Ω</mi></mrow><annotation encoding=\"application/x-tex\">d:  \\mathcal{X} \\to \\Omega</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">d</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.14643em;\">X</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\">Ω</span></span></span></span>, unbiasedness is the equation <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"double-struck\">E</mi><mo stretchy=\"false\">[</mo><mi>P</mi><mo>⋅</mo><mi>d</mi><mo stretchy=\"false\">]</mo><mo>=</mo><msub><mn>1</mn><mi mathvariant=\"normal\">Ω</mi></msub><mo>:</mo><mi mathvariant=\"normal\">Ω</mi><mo>→</mo><mi mathvariant=\"normal\">Ω</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbb{E}[P \\cdot d] = 1_{\\Omega}: \\Omega \\to \\Omega</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">E</span></span><span class=\"mopen\">[</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">d</span><span class=\"mclose\">]</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.79444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">Ω</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\">Ω</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\">Ω</span></span></span></span>.</p>",
        "id": 199989101,
        "sender_full_name": "Evan Patterson",
        "timestamp": 1591470916
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"275965\">Evan Patterson</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Eigil.20Rischel's.20talk/near/199989101\">said</a>:</p>\n<blockquote>\n<blockquote>\n<p>In this case, then, the goal would simply be to show that <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"double-struck\">E</mi><mo stretchy=\"false\">[</mo><mi>M</mi><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">]</mo><mo>≈</mo><mi>M</mi><mo stretchy=\"false\">(</mo><mi mathvariant=\"double-struck\">E</mi><mo stretchy=\"false\">[</mo><mi>X</mi><mo stretchy=\"false\">]</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\mathbb{E}[M(X)] \\approx M(\\mathbb{E}[X])</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">E</span></span><span class=\"mopen\">[</span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span><span class=\"mclose\">)</span><span class=\"mclose\">]</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathbb\">E</span></span><span class=\"mopen\">[</span><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span><span class=\"mclose\">]</span><span class=\"mclose\">)</span></span></span></span>?</p>\n</blockquote>\n<p>I was thinking that given a statistical model <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo>:</mo><mi mathvariant=\"normal\">Ω</mi><mo>→</mo><mi mathvariant=\"script\">X</mi></mrow><annotation encoding=\"application/x-tex\">P: \\Omega \\to \\mathcal{X}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\">Ω</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.14643em;\">X</span></span></span></span></span> and an estimator <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>d</mi><mo>:</mo><mi mathvariant=\"normal\">Ω</mi><mo>→</mo><mi mathvariant=\"script\">X</mi></mrow><annotation encoding=\"application/x-tex\">d: \\Omega \\to \\mathcal{X}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">d</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\">Ω</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.14643em;\">X</span></span></span></span></span>, unbiasedness is the equation <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"double-struck\">E</mi><mo stretchy=\"false\">[</mo><mi>P</mi><mo>⋅</mo><mi>d</mi><mo stretchy=\"false\">]</mo><mo>=</mo><msub><mn>1</mn><mi mathvariant=\"normal\">Ω</mi></msub><mo>:</mo><mi mathvariant=\"normal\">Ω</mi><mo>→</mo><mi mathvariant=\"normal\">Ω</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbb{E}[P \\cdot d] = 1_{\\Omega}: \\Omega \\to \\Omega</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">E</span></span><span class=\"mopen\">[</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">d</span><span class=\"mclose\">]</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.79444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">Ω</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\">Ω</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\">Ω</span></span></span></span>.</p>\n</blockquote>\n<p>Yes. I was trying to suggest that there is a map to the sample and a deterministic map to the average of the sample. Then, if we take the composite of the two maps as a random variable, the expectation of such a random variable is equivalent to the expectation of the distribution random variable, so if we go out and back, we get an identity endomorphism.</p>",
        "id": 199989223,
        "sender_full_name": "Oliver Shetler",
        "timestamp": 1591471102
    },
    {
        "content": "<p>This could work for any estimator, too. Variance would rely on the same equation.</p>\n<p>Another interesting problem is to ask, what does it mean to extend the concept of a parameter and an estimator to the context of sentences in grammars, with a semantics category such as the vector space of word associations or conceptual spaces (i.e. convex relations re: Coecke's implementation of Peter Gardenfors work)?</p>",
        "id": 199989433,
        "sender_full_name": "Oliver Shetler",
        "timestamp": 1591471444
    },
    {
        "content": "<p>For example, can we build a sigma algebra in the semantic space of sentences and define a meaningful notion of the \"average\" of a sample of sentences? The application I have in mind is on surveys, where a psychologist or social scientist might ask for a one sentence answer to a fairly closed ended question. You might not be able to give an \"average sentence,\" but if you could define the \"average meaning\" then you could define a random variable with a much smaller variance than your sample and generate a few representative sentences that \"capture the meaning\" of the larger set, insofar as an average \"captures the center\" of a numerical data set. I'm still not mathematically equipped to really tackle this question, but it's been on my mind for a while.</p>",
        "id": 199989509,
        "sender_full_name": "Oliver Shetler",
        "timestamp": 1591471565
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276702\">Tobias Fritz</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Eigil.20Rischel's.20talk/near/199984883\">said</a>:</p>\n<blockquote>\n<p>I've been wondering that too! And in particular whether conjugate priors give us a Markov category with conditionals. It's not obvious, since the parameter space and the sample space of an exponential family seem to have different kind of structure, with in particular the parameter space being a vector space. But this is the sort of thing that <span class=\"user-mention silent\" data-user-id=\"275965\">Evan Patterson</span> 's lattices of supplies are made for, so perhaps he will be able to say more.</p>\n</blockquote>\n<p>Great questions. Until now, I never thought about whether there is a Markov category of exponential families (or maybe some larger class, say including exponential dispersion families). A classic example is that the negative binomial family is a composite of the gamma and Poisson families. (I put this example in Sec 3.1 of my thesis, just for fun.) Still, it seems too good to be true that such a class would be closed under composition in general. Another subtlety is that exponential families have multiple reasonable parameterizations. The canonical parameter belongs to a vector space, but under regularity conditions, the family can be invertibly reparameterized by its mean, which in general only belongs to a convex set. (This provides the \"canonical link function\" in generalized linear models; see Sec 4.4 of my thesis for examples as statistical theories.) But exponential families play a fundamental role in statistics and machine learning, so it would be great to understand them from a compositional viewpoint, if possible.</p>",
        "id": 199994156,
        "sender_full_name": "Evan Patterson",
        "timestamp": 1591479386
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"275965\">Evan Patterson</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Eigil.20Rischel's.20talk/near/199987626\">said</a>:</p>\n<blockquote>\n<p>One idea I've thought about superficially is introducing an expectation operator <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"double-struck\">E</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbb{E}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68889em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">E</span></span></span></span></span> into the formalism, so that if <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>M</mi><mo>:</mo><mi mathvariant=\"script\">X</mi><mo>→</mo><mi mathvariant=\"script\">Y</mi></mrow><annotation encoding=\"application/x-tex\">M: \\mathcal{X} \\to \\mathcal{Y}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.14643em;\">X</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.78055em;vertical-align:-0.09722em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.08222em;\">Y</span></span></span></span></span> is a Markov kernel with <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"script\">Y</mi></mrow><annotation encoding=\"application/x-tex\">\\mathcal{Y}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.78055em;vertical-align:-0.09722em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.08222em;\">Y</span></span></span></span></span> a vector space, then <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"double-struck\">E</mi><mi>M</mi><mo>:</mo><mi mathvariant=\"script\">X</mi><mo>→</mo><mi mathvariant=\"script\">Y</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbb{E} M: \\mathcal{X} \\to \\mathcal{Y}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68889em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">E</span></span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.14643em;\">X</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.78055em;vertical-align:-0.09722em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.08222em;\">Y</span></span></span></span></span> is the deterministic kernel <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"double-struck\">E</mi><mi>M</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>:</mo><mo>=</mo><mi mathvariant=\"double-struck\">E</mi><mo stretchy=\"false\">[</mo><mi>M</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">(\\mathbb{E} M)(x) := \\mathbb{E}[M(x)]</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathbb\">E</span></span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"mclose\">)</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.36687em;vertical-align:0em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">E</span></span><span class=\"mopen\">[</span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span><span class=\"mclose\">]</span></span></span></span>. This would allow one to express unbiasedness. In terms of statistical theories, one could express that a probability distribution is parameterized by mean, which would often be useful. I think it would be interesting to properly work out this idea.</p>\n</blockquote>\n<p>I am not positive I understand exactly what you are aiming for, but how about something like this:</p>\n<ol>\n<li>Rather than considering a vector space, provide <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"script\">Y</mi></mrow><annotation encoding=\"application/x-tex\">\\mathcal{Y}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.78055em;vertical-align:-0.09722em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.08222em;\">Y</span></span></span></span></span> with an algebra <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>e</mi><mspace></mspace><mspace width=\"0.1111111111111111em\"></mspace><mo lspace=\"0em\" rspace=\"0.17em\"></mo><mtext> ⁣</mtext><mo lspace=\"0em\" rspace=\"0em\">:</mo><mspace width=\"0.3333333333333333em\"></mspace><mi>P</mi><mi mathvariant=\"script\">Y</mi><mo>→</mo><mi mathvariant=\"script\">Y</mi></mrow><annotation encoding=\"application/x-tex\">e \\colon P \\mathcal{Y} \\to \\mathcal{Y} </annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.78055em;vertical-align:-0.09722em;\"></span><span class=\"mord mathdefault\">e</span><span class=\"mspace nobreak\"></span><span class=\"mspace\" style=\"margin-right:0.1111111111111111em;\"></span><span class=\"mpunct\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:-0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mrel\">:</span></span><span class=\"mspace\" style=\"margin-right:0.3333333333333333em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.08222em;\">Y</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.78055em;vertical-align:-0.09722em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.08222em;\">Y</span></span></span></span></span> for a probability monad <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi></mrow><annotation encoding=\"application/x-tex\">P</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span></span></span></span>, which (deterministically) specifies how formal convex combinations of elements of <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"script\">Y</mi></mrow><annotation encoding=\"application/x-tex\">\\mathcal{Y}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.78055em;vertical-align:-0.09722em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.08222em;\">Y</span></span></span></span></span> are evaluated to a particular element of <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"script\">Y</mi></mrow><annotation encoding=\"application/x-tex\">\\mathcal{Y}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.78055em;vertical-align:-0.09722em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.08222em;\">Y</span></span></span></span></span>. </li>\n<li>For a Markov kernel <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>M</mi><mspace></mspace><mspace width=\"0.1111111111111111em\"></mspace><mo lspace=\"0em\" rspace=\"0.17em\"></mo><mtext> ⁣</mtext><mo lspace=\"0em\" rspace=\"0em\">:</mo><mspace width=\"0.3333333333333333em\"></mspace><mi mathvariant=\"script\">X</mi><mo>→</mo><mi mathvariant=\"script\">Y</mi></mrow><annotation encoding=\"application/x-tex\">M \\colon \\mathcal{X} \\to \\mathcal{Y}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"mspace nobreak\"></span><span class=\"mspace\" style=\"margin-right:0.1111111111111111em;\"></span><span class=\"mpunct\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:-0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mrel\">:</span></span><span class=\"mspace\" style=\"margin-right:0.3333333333333333em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.14643em;\">X</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.78055em;vertical-align:-0.09722em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.08222em;\">Y</span></span></span></span></span>, define <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"double-struck\">E</mi><mo stretchy=\"false\">[</mo><mi>M</mi><mo stretchy=\"false\">]</mo><mo>:</mo><mo>=</mo><mi>e</mi><mo>∘</mo><mi>P</mi><mi>M</mi><mspace></mspace><mspace width=\"0.1111111111111111em\"></mspace><mo lspace=\"0em\" rspace=\"0.17em\"></mo><mtext> ⁣</mtext><mo lspace=\"0em\" rspace=\"0em\">:</mo><mspace width=\"0.3333333333333333em\"></mspace><mi>P</mi><mi mathvariant=\"script\">X</mi><mo>→</mo><mi mathvariant=\"script\">Y</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbb{E}[M] := e \\circ PM \\colon P \\mathcal{X} \\to \\mathcal{Y}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">E</span></span><span class=\"mopen\">[</span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"mclose\">]</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.36687em;vertical-align:0em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.44445em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">e</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∘</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"mspace nobreak\"></span><span class=\"mspace\" style=\"margin-right:0.1111111111111111em;\"></span><span class=\"mpunct\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:-0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mrel\">:</span></span><span class=\"mspace\" style=\"margin-right:0.3333333333333333em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.14643em;\">X</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.78055em;vertical-align:-0.09722em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.08222em;\">Y</span></span></span></span></span>. This applies the random variable <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>M</mi></mrow><annotation encoding=\"application/x-tex\">M</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span></span></span></span> (or, indeed, any kernel) to elements of the convex mixtures and then evaluates the convex combination within <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"script\">Y</mi></mrow><annotation encoding=\"application/x-tex\">\\mathcal{Y}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.78055em;vertical-align:-0.09722em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.08222em;\">Y</span></span></span></span></span>.</li>\n<li>The unbiasedness of <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>d</mi><mspace></mspace><mspace width=\"0.1111111111111111em\"></mspace><mo lspace=\"0em\" rspace=\"0.17em\"></mo><mtext> ⁣</mtext><mo lspace=\"0em\" rspace=\"0em\">:</mo><mspace width=\"0.3333333333333333em\"></mspace><mi mathvariant=\"script\">X</mi><mo>→</mo><mi mathvariant=\"normal\">Ω</mi></mrow><annotation encoding=\"application/x-tex\">d \\colon \\mathcal{X} \\to \\Omega</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">d</span><span class=\"mspace nobreak\"></span><span class=\"mspace\" style=\"margin-right:0.1111111111111111em;\"></span><span class=\"mpunct\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:-0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mrel\">:</span></span><span class=\"mspace\" style=\"margin-right:0.3333333333333333em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.14643em;\">X</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\">Ω</span></span></span></span> for <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi><mspace></mspace><mspace width=\"0.1111111111111111em\"></mspace><mo lspace=\"0em\" rspace=\"0.17em\"></mo><mtext> ⁣</mtext><mo lspace=\"0em\" rspace=\"0em\">:</mo><mspace width=\"0.3333333333333333em\"></mspace><mi mathvariant=\"normal\">Ω</mi><mo>→</mo><mi mathvariant=\"script\">X</mi></mrow><annotation encoding=\"application/x-tex\">p \\colon \\Omega \\to \\mathcal{X}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">p</span><span class=\"mspace nobreak\"></span><span class=\"mspace\" style=\"margin-right:0.1111111111111111em;\"></span><span class=\"mpunct\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:-0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mrel\">:</span></span><span class=\"mspace\" style=\"margin-right:0.3333333333333333em;\"></span><span class=\"mord\">Ω</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.14643em;\">X</span></span></span></span></span> would then presumably look like <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"double-struck\">E</mi><mo stretchy=\"false\">[</mo><mi>d</mi><mo>∘</mo><mi>p</mi><mo stretchy=\"false\">]</mo><mo>=</mo><msub><mi>e</mi><mi mathvariant=\"normal\">Ω</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\mathbb{E}[d \\circ p] = e_{\\Omega}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">E</span></span><span class=\"mopen\">[</span><span class=\"mord mathdefault\">d</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∘</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">p</span><span class=\"mclose\">]</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">Ω</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>?</li>\n</ol>\n<p><span class=\"user-mention silent\" data-user-id=\"275965\">Evan Patterson</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Eigil.20Rischel's.20talk/near/199989101\">said</a>:</p>\n<blockquote>\n<p>I was thinking that given a statistical model <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo>:</mo><mi mathvariant=\"normal\">Ω</mi><mo>→</mo><mi mathvariant=\"script\">X</mi></mrow><annotation encoding=\"application/x-tex\">P: \\Omega \\to \\mathcal{X}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\">Ω</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.14643em;\">X</span></span></span></span></span> and an estimator <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>d</mi><mo>:</mo><mi mathvariant=\"normal\">Ω</mi><mo>→</mo><mi mathvariant=\"script\">X</mi></mrow><annotation encoding=\"application/x-tex\">d: \\Omega \\to \\mathcal{X}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">d</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\">Ω</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.14643em;\">X</span></span></span></span></span>, unbiasedness is the equation <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"double-struck\">E</mi><mo stretchy=\"false\">[</mo><mi>P</mi><mo>⋅</mo><mi>d</mi><mo stretchy=\"false\">]</mo><mo>=</mo><msub><mn>1</mn><mi mathvariant=\"normal\">Ω</mi></msub><mo>:</mo><mi mathvariant=\"normal\">Ω</mi><mo>→</mo><mi mathvariant=\"normal\">Ω</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbb{E}[P \\cdot d] = 1_{\\Omega}: \\Omega \\to \\Omega</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">E</span></span><span class=\"mopen\">[</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">d</span><span class=\"mclose\">]</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.79444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">Ω</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\">Ω</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\">Ω</span></span></span></span>.</p>\n</blockquote>\n<p>By <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo>⋅</mo><mi>d</mi></mrow><annotation encoding=\"application/x-tex\">P \\cdot d</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">d</span></span></span></span>, do you mean <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>d</mi><mo>∘</mo><mi>P</mi></mrow><annotation encoding=\"application/x-tex\">d \\circ P</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">d</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∘</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span></span></span></span>?</p>",
        "id": 199995444,
        "sender_full_name": "Tomáš Gonda",
        "timestamp": 1591481611
    },
    {
        "content": "<p>Ok, nice, that seems like a more systematic way to think about it, which does not require introducing a vector space structure.</p>\n<p>And yes, by <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo>⋅</mo><mi>d</mi></mrow><annotation encoding=\"application/x-tex\">P \\cdot d</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">d</span></span></span></span>, I meant <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>d</mi><mo>∘</mo><mi>P</mi></mrow><annotation encoding=\"application/x-tex\">d \\circ P</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">d</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∘</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span></span></span></span>. Sorry, I get too used to that notation.</p>",
        "id": 199995782,
        "sender_full_name": "Evan Patterson",
        "timestamp": 1591482226
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"303936\">Peter Arndt</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Eigil.20Rischel's.20talk/near/199976412\">said</a>:</p>\n<blockquote>\n<p>@Eigil Rischel Nice talk, thanks! <br>\nI have a question on your remark at the end, that it is hard to treat measures with density in a Markov category. You said that the problem is that the comultiplication produces Dirac measures, which have no density. Did you just mean that, because of this, you cannot define a Markov category of measurable spaces where _every_ measure has a density? Or are there more problems?</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"303936\">@Peter Arndt</span> <span class=\"user-mention\" data-user-id=\"276165\">@Eigil Rischel</span>  I wonder if it is not possible to solve this problem keeping track of the support of the corresponding probability measures, and not only of the density. For instance, if X is a continuous r.v. on R with density f,  then (X,X) is a r.v. on R^2 supported on the diagonal and with density w.r.t. the Hausdorff measure on it. A similar problem appears when disintegrating (conditioning): in any nontrivial case, the disintegrated measures do not have a density with respect to the initial reference measure. I took this approach in Chapter 9-11 of my dissertation <a href=\"https://webusers.imj-prg.fr/~juan-pablo.vigneaux/these\">https://webusers.imj-prg.fr/~juan-pablo.vigneaux/these</a> , but this is not written in the language of Markov categories (and I don't know if it can  be adapted)</p>",
        "id": 199996619,
        "sender_full_name": "Juan Pablo Vigneaux",
        "timestamp": 1591483790
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"276702\">@Tobias Fritz</span> I also have a general question about this \"synthetic\" probability theory: many examples were mentioned in the talk, and even more in your paper. If the synthetic viewpoint is fruitful, I would expect proofs of the key theorems in any of these examples to make sense in all the others, once written in the general language. Hence the main theorems should be re-interpretable in terms of the other examples. Do you have this kind of result? Say, what is Kolmogorov's 0-1- Law for commutative rings? Etc.</p>",
        "id": 199996787,
        "sender_full_name": "Juan Pablo Vigneaux",
        "timestamp": 1591484134
    },
    {
        "content": "<p>Hi Juan Pablo! Those are great questions. Let me start with a disclaimer: although Markov categories have become <em>one</em> approach for doing synthetic probability theory, there may well be other ones, and my understanding is that <span class=\"user-mention\" data-user-id=\"308769\">@Alex Simpson</span>  will be talking about another one on Monday. It's also unclear how far we can actually go in developing probability theory synthetically. For example, reproducing the central limit theorem still seems out of reach at the moment. There's also the caveat that some results which usually are theorems rather become definitions in a synthetic treatment.</p>\n<p>That being said, I perfectly agree that all results of synthetic probability theory with Markov categories acquire a much greater generality than the usual one, and that this is worth exploring. For example, one can hope to instantiate synthetic theorems on diagram categories in a Markov category, since these again form Markov categories as sketched in Section 7 of <a href=\"https://arxiv.org/abs/1908.07021\">my paper</a>. In particular, this makes the synthetic theorems apply e.g. to stochastic processes.</p>\n<p>Our synthetic version of Kolmogorov's 0/1-law indeed applies in any Markov category in which our Kolmogorov products exist. In <a href=\"https://arxiv.org/abs/1912.02769\">the paper</a>, we've applied it to a certain Markov category of topological spaces, and obtained the following as a special case:</p>\n<p><strong>Theorem.</strong> Let <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>X</mi><mi>i</mi></msub><msub><mo stretchy=\"false\">)</mo><mrow><mi>i</mi><mo>∈</mo><mi>J</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">(X_i)_{i \\in J}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mrel mtight\">∈</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.09618em;\">J</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.17737em;\"><span></span></span></span></span></span></span></span></span></span> be a family of topological spaces, <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Y</mi></mrow><annotation encoding=\"application/x-tex\">Y</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.22222em;\">Y</span></span></span></span> a Hausdorff space, and let <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo>:</mo><msub><mo>∏</mo><mi>i</mi></msub><msub><mi>X</mi><mi>i</mi></msub><mo>→</mo><mi>Y</mi></mrow><annotation encoding=\"application/x-tex\">f : \\prod_i X_i \\to Y</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0497100000000001em;vertical-align:-0.29971000000000003em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∏</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.16195399999999993em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.22222em;\">Y</span></span></span></span> be a continuous function which is independent of any finite subset of its arguments. Then <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi></mrow><annotation encoding=\"application/x-tex\">f</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span></span></span></span> is constant.</p>\n<p>This is also quite easy to see directly, but it may give a flavour of the kind of statement that our result instantiates to. I don't know what it instantiates to for commutative rings, and that sounds like an interesting question! Generally we're still very much at the beginning with all of this: only very few theorems have been developed synthetically, and those that have have been instantiated only in very few Markov categories. So there's a lot left to do.</p>\n<p>BTW, I also wonder whether there's a Markov category for information theory. Something like this: the objects are finite sets (for simplicity), and a morphism <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo>:</mo><mi>A</mi><mo>→</mo><mi>B</mi></mrow><annotation encoding=\"application/x-tex\"> f : A \\to B</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">A</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05017em;\">B</span></span></span></span> is a family of Markov kernels <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>f</mi><mi>n</mi></msub><mo>:</mo><msup><mi>A</mi><mrow><mo>×</mo><mi>n</mi></mrow></msup><mo>→</mo><msup><mi>B</mi><mrow><mo>×</mo><mi>n</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">f_n : A^{\\times n} \\to B^{\\times n}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.771331em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">A</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.771331em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">×</span><span class=\"mord mathdefault mtight\">n</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.771331em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05017em;\">B</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.771331em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">×</span><span class=\"mord mathdefault mtight\">n</span></span></span></span></span></span></span></span></span></span></span></span> which are suitably compatible across all <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi><mo>∈</mo><mi mathvariant=\"double-struck\">N</mi></mrow><annotation encoding=\"application/x-tex\">n \\in \\mathbb{N}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"></span><span class=\"mord mathdefault\">n</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68889em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">N</span></span></span></span></span>, and quotiented with respect to a suitable notion of asymptotic equivalence of morphisms as <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi><mo>→</mo><mi mathvariant=\"normal\">∞</mi></mrow><annotation encoding=\"application/x-tex\">n \\to \\infty</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">n</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord\">∞</span></span></span></span>. So in this way, (aspects of) information theory may fall under the umbrella of synthetic probability theory. My hope is that this could make the parallels between probability theory and information theory precise; for example, conditional entropy, which has a well-known similarly to conditional probability, could perhaps be given exactly by the conditional in the Markov category. But so far this idea is just wild speculation. In case that it makes any sense, perhaps it could also be interesting to ask whether one can turn this upside down and find a cohomological interpretation of conditional probability :) But probably you've already thought about this?</p>",
        "id": 199999430,
        "sender_full_name": "Tobias Fritz",
        "timestamp": 1591488793
    },
    {
        "content": "<p>Hi all! Here's the video.<br>\n<a href=\"https://youtu.be/534f-9Qx2Lg\">https://youtu.be/534f-9Qx2Lg</a></p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"534f-9Qx2Lg\" href=\"https://youtu.be/534f-9Qx2Lg\"><img src=\"https://i.ytimg.com/vi/534f-9Qx2Lg/default.jpg\"></a></div>",
        "id": 200000944,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591491781
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"275989\">@Paolo Perrone</span> <span class=\"user-mention\" data-user-id=\"276165\">@Eigil Rischel</span> Are the slides available?</p>",
        "id": 200030816,
        "sender_full_name": "Bas Spitters",
        "timestamp": 1591546849
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276702\">Tobias Fritz</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Eigil.20Rischel's.20talk/near/199999430\">said</a>:</p>\n<blockquote>\n<p>That being said, I perfectly agree that all results of synthetic probability theory with Markov categories acquire a much greater generality than the usual one, and that this is worth exploring. For example, one can hope to instantiate synthetic theorems on diagram categories in a Markov category, since these again form Markov categories as sketched in Section 7 of <a href=\"https://arxiv.org/abs/1908.07021\">my paper</a>. In particular, this makes the synthetic theorems apply e.g. to stochastic processes.</p>\n</blockquote>\n<p>Interesting! Have you tried to simplify the presentation of basic theorems on stochastic processes using these ideas? Are you aware of two different theorems in the literature that are actually instances of the same synthetic result?</p>\n<p>I think that it'd be worth exploring other instances of the 0/1- law or any of the other known results. </p>\n<p>Give me some time to think about the eventual information-theoretic version.</p>",
        "id": 200046531,
        "sender_full_name": "Juan Pablo Vigneaux",
        "timestamp": 1591570229
    },
    {
        "content": "<p>No, as far as I know nobody has applied the theory to stochastic processes yet. And although theorems of synthetic probability theory (in terms of Markov cats) can be instantiated on stochastic processes, this only gives results which do not make explicit reference to time. So my suspicion is that those results will be somewhat uninteresting, and possibly merely pointwise in time. Nevertheless, one can probably develop a synthetic theory of stochastic processes if one equips Markov categories with some extra structure, such as a \"time translation functor\" given by an automorphism of the category, corresponding to shifting the diagrams of the original category in which the process lives. This would give explicit access to time.</p>\n<p>Sure, if you have any thoughts on the information-theoretic version (if it makes any sense at all), it would be great to hear about them!</p>",
        "id": 200047041,
        "sender_full_name": "Tobias Fritz",
        "timestamp": 1591571091
    },
    {
        "content": "<p>If anyone is interested, this week Tobias Fritz will give a talk about Markov categories at the <a href=\"#narrow/stream/229457-MIT-Categories.20Seminar\">MIT Categories Seminar</a>.<br>\nThread here: <a href=\"#narrow/stream/229457-MIT-Categories.20Seminar/topic/July.2016.3A.20Tobias.20Fritz'.20talk\">https://categorytheory.zulipchat.com/#narrow/stream/229457-MIT-Categories.20Seminar/topic/July.2016.3A.20Tobias.20Fritz'.20talk</a></p>",
        "id": 203878422,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1594755991
    },
    {
        "content": "<p>Eigil Rischel is giving another talk on the topic here: <a href=\"#narrow/stream/229457-MIT-Categories.20Seminar/topic/November.2019.3A.20Eigil.20Rischel's.20talk\">https://categorytheory.zulipchat.com/#narrow/stream/229457-MIT-Categories.20Seminar/topic/November.2019.3A.20Eigil.20Rischel's.20talk</a></p>",
        "id": 217010012,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1605623835
    }
]