[
    {
        "content": "<p>Hello! Here's Sam Staton's tutorial video, a categorical tutorial about probabilistic programming.<br>\n<a href=\"https://youtu.be/JimCpEG0nts\">https://youtu.be/JimCpEG0nts</a><br>\nAny questions about the video go in this thread!</p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"JimCpEG0nts\" href=\"https://youtu.be/JimCpEG0nts\"><img src=\"https://i.ytimg.com/vi/JimCpEG0nts/default.jpg\"></a></div>",
        "id": 199412771,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591039962
    },
    {
        "content": "<p>That is a great talk, Sam! I have a few questions if you don't mind.</p>\n<ul>\n<li>Could you elaborate a bit on why you prefer thinking of the/a category of probability kernels as a multicategory rather than a symmetric monoidal category?</li>\n<li>What are the main differences between different probabilistic programming languages? How much do they differ with respect to which kernels can be defined?</li>\n<li>With the question about whether s-finite kernels form a Kleisli category, are you considering all measurable spaces as objects? Or only a subclass like Polish spaces?</li>\n</ul>",
        "id": 199426772,
        "sender_full_name": "Tobias Fritz",
        "timestamp": 1591047169
    },
    {
        "content": "<p>Hi Tobias!</p>\n<p><span class=\"user-mention silent\" data-user-id=\"276702\">Tobias Fritz</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Tutorial.3A.20Probabilistic.20programming.20(Sam.20Staton)/near/199426772\">said</a>:<br>\n<code>Could you elaborate a bit on why you prefer thinking of the/a category of probability kernels as a multicategory rather than a symmetric monoidal category?</code></p>\n<ul>\n<li>It's not a big deal in the big picture, but the fact that they do form a multicategory / monoidal category relies on Fubini's theorem, which is perhaps slightly clearer in the multicategory formulation. Also I think that in general programming language / type theory syntax is closer to multicategories than to monoidal categories.</li>\n</ul>\n<p><code>What are the main differences between different probabilistic programming languages? How much do they differ with respect to which kernels can be defined?</code></p>\n<p>I'll just list some:</p>\n<ul>\n<li>Some of the languages are lisp-based and untyped, which means even understanding programs as probability kernels is very difficult. </li>\n<li>Some languages are really good for certain inference algorithms, which leads to some restrictions. e.g. Stan is really good for Hamiltonian Monte Carlo simulation, which means you're supposed to only build differentiable densities, and you have to go round the houses to make a mixture model.  Infer.Net is really good for variational message passing, but that means you have to use distribution families carefully. </li>\n<li>Some languages (like Pyro) interface with GPU code, allowing us to work with variational autoencoders from a probabilistic programming viewpoint</li>\n<li>Some languages (like Pyro and Gen) have  facilities for tying a clean model to a more intricate inference set-up. For example, in variational inference you might tie bits of your model to different things in a \"guide\" for a posterior, and for Metropolis Hastings you might specify a particular proposal if you expect things to correlate in a certain way. I think this is really important ongoing work. </li>\n<li>Some languages support non-parametric features to a greater or lesser extent. Personally I find this fascinating. </li>\n</ul>\n<p><code>With the question about whether s-finite kernels form a Kleisli category, are you considering all measurable spaces as objects? Or only a subclass like Polish spaces?</code></p>\n<ul>\n<li>Several of us have tried both questions -- all measurable spaces, and just the standard Borel spaces -- and we have no answers. <br>\n(I do know that they can be made into a Kleisli category over quasi-Borel spaces, but that's almost cheating.)</li>\n</ul>",
        "id": 199500905,
        "sender_full_name": "Sam Staton",
        "timestamp": 1591108378
    },
    {
        "content": "<p>Very interesting, thanks! Yes, I see the point about the de Finetti theorem having more of a multicategorical flavour.</p>\n<p>Out of curiosity: to what extent are you a user and/or developer of probabilistic programming languages, in addition to studying them at the theoretical level?</p>",
        "id": 199518613,
        "sender_full_name": "Tobias Fritz",
        "timestamp": 1591115489
    },
    {
        "content": "<p>David Myers once made me notice that lax monoidal functors, as opposed to strong, are naturally the morphisms not quite of monoidal categories, but rather of the underlying multicategories. If the structural functors that appear on probability kernels tend to be lax monoidal instead of strong (the underlying functor to the probability monad certainly is in this form), this could be an additional witness that \"really Fubini is about multicategories\".</p>",
        "id": 199523746,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591117937
    },
    {
        "content": "<p>Why is it more natural for a functor between multicategories rather than monoidal categories to be lax?</p>",
        "id": 199525991,
        "sender_full_name": "Oscar Cunningham",
        "timestamp": 1591119042
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276945\">Oscar Cunningham</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Tutorial.3A.20Probabilistic.20programming.20(Sam.20Staton)/near/199525991\">said</a>:</p>\n<blockquote>\n<p>Why is it more natural for a functor between multicategories rather than monoidal categories to be lax?</p>\n</blockquote>\n<p>The idea is that if T is lax monoidal, then it canonically maps a morphism f: A x B -&gt; C to a morphism TA x TB -&gt; TC.</p>",
        "id": 199533890,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591122648
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276702\">Tobias Fritz</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Tutorial.3A.20Probabilistic.20programming.20(Sam.20Staton)/near/199518613\">said</a>:</p>\n<blockquote>\n<p>to what extent are you a user and/or developer of probabilistic programming languages</p>\n</blockquote>\n<p>I dabble a bit, mainly because I'm interested to know what could be useful. I'm involved in a project with some social scientists on analyzing hate events on twitter and I've been writing probabilistic programs for that.</p>",
        "id": 199535776,
        "sender_full_name": "Sam Staton",
        "timestamp": 1591123552
    },
    {
        "content": "<p>Hi Sam, thanks for the tutorial! I was a bit confused by the first example (4 buses in an hour) of the weighted Monte Carlo, so let me rephrase it to check if I got it right:</p>\n<ul>\n<li>There is no actual \"simulation\" going on. The algorithm just samples from a uniform distribution and then scores each sample with the likelihood that on the given sampled day, one would see 4 buses. In the end, one then counts the weighted proportion of samples corresponding to a given hypothesis to get a posterior.</li>\n</ul>\n<p>I think what threw me off at first was the naive intuition that, in this example, somehow the most 'complicated' part of the calculation is computing the likelihood. Therefore, I was subconsciously expecting the simulation to be approximating that, but then the likelihoods just entered as an input to the algorithm.</p>",
        "id": 199683270,
        "sender_full_name": "Tomáš Gonda",
        "timestamp": 1591222102
    },
    {
        "content": "<p>Hi! Good question. <span class=\"user-mention silent\" data-user-id=\"302756\">Tomáš Gonda</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Tutorial.3A.20Probabilistic.20programming.20(Sam.20Staton)/near/199683270\">said</a>:</p>\n<blockquote>\n<p>The [weighted Monte Carlo] algorithm just samples from a uniform distribution and then scores each sample with the likelihood that on the given sampled day, one would see 4 buses. In the end, one then counts the weighted proportion of samples corresponding to a given hypothesis to get a posterior.</p>\n</blockquote>\n<p>That's exactly right. (The example is very simple, and in practice you would be sampling from a more interesting prior.)</p>\n<blockquote>\n<p>somehow the most 'complicated' part of the calculation is computing the likelihood</p>\n</blockquote>\n<p>Indeed, there are various approaches to automatically converting a generative model into a density / likelihood function. But here I assume that the likelihood function is given to us (the Poisson density), and that is often the approach taken in probabilistic programming in practice.</p>",
        "id": 199706843,
        "sender_full_name": "Sam Staton",
        "timestamp": 1591248831
    },
    {
        "content": "<p>Thanks for your talk! I have some very basic questions. Let <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi><mo>:</mo><mo>=</mo><mi>A</mi><mo>×</mo><mi>B</mi></mrow><annotation encoding=\"application/x-tex\">X:=A\\times B</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.36687em;vertical-align:0em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathdefault\">A</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05017em;\">B</span></span></span></span> be the space describing the values <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>a</mi></mrow><annotation encoding=\"application/x-tex\">a</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">a</span></span></span></span> and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">b</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">b</span></span></span></span> in <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>y</mi><mo>=</mo><mi>a</mi><mo>+</mo><mi>b</mi><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">y=a+bx</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.66666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathdefault\">a</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">b</span><span class=\"mord mathdefault\">x</span></span></span></span>, so it's the space parametrizing affine maps from <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"double-struck\">R</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbb{R}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68889em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">R</span></span></span></span></span> to itself. Given a fixed <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>a</mi><mo separator=\"true\">,</mo><mi>b</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(a,b)</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">a</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">b</span><span class=\"mclose\">)</span></span></span></span>, it is not guaranteed that when an observation is made, the values will all lie along a straight line. If <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi></mrow><annotation encoding=\"application/x-tex\">O</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">O</span></span></span></span> denotes the observation space, then this is described by a Markov kernel <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi><mo>⇝</mo><mi>O</mi></mrow><annotation encoding=\"application/x-tex\">X\\rightsquigarrow O</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel amsrm\">⇝</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">O</span></span></span></span>. If we assume that there is a definite value of <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>a</mi><mo separator=\"true\">,</mo><mi>b</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(a,b)</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">a</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">b</span><span class=\"mclose\">)</span></span></span></span> then this corresponds to a Dirac delta measure <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">{</mo><mo>∙</mo><mo stretchy=\"false\">}</mo><mo>→</mo><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">\\{\\bullet\\}\\rightarrow X</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">{</span><span class=\"mord\">∙</span><span class=\"mclose\">}</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span></span></span></span>. We can push forward this measure to get one on the observation space <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi></mrow><annotation encoding=\"application/x-tex\">O</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">O</span></span></span></span> which is describing the probabilities of witnessing certain observations. But what is <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi></mrow><annotation encoding=\"application/x-tex\">O</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">O</span></span></span></span> exactly in this example? If we have <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">n</span></span></span></span> observed data points, is it just <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mo>∐</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mi mathvariant=\"double-struck\">R</mi></mrow><annotation encoding=\"application/x-tex\">\\coprod_{i=1}^{n}\\mathbb{R}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:1.104002em;vertical-align:-0.29971000000000003em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∐</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.804292em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">R</span></span></span></span></span>? (the disjoint union of <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">n</span></span></span></span> copies of <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"double-struck\">R</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbb{R}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68889em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">R</span></span></span></span></span>)? If so, to obtain the posterior that you plotted visually as a collection of straight lines, we apply Bayesian inversion to produce the associated Markov kernel  <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi><mo>⇝</mo><mi>A</mi><mo>×</mo><mi>B</mi></mrow><annotation encoding=\"application/x-tex\">O\\rightsquigarrow A\\times B</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">O</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel amsrm\">⇝</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathdefault\">A</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05017em;\">B</span></span></span></span> having witnessed the specific observation of data?</p>",
        "id": 199863094,
        "sender_full_name": "Arthur Parzygnat",
        "timestamp": 1591356388
    },
    {
        "content": "<p>Hi <span class=\"user-mention silent\" data-user-id=\"296639\">Arthur Parzygnat</span>. I think <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi><mo>=</mo><mo stretchy=\"false\">(</mo><msup><mi mathvariant=\"double-struck\">R</mi><mn>2</mn></msup><msup><mo stretchy=\"false\">)</mo><mi>n</mi></msup></mrow><annotation encoding=\"application/x-tex\">O=(\\mathbb{R}^2)^n</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">O</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.064108em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">R</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.664392em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">n</span></span></span></span></span></span></span></span></span></span></span>, if there are $n$ observations in the plane. But maybe I misunderstood your notation?</p>",
        "id": 199873936,
        "sender_full_name": "Sam Staton",
        "timestamp": 1591362953
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"308397\">@Sam Staton</span>  Ah, I assumed that because the x values are only natural numbers then you get the disjoint union. But yes, if you allow arbitrary x positions, then yes. Okay, but it's good to know we agree.</p>",
        "id": 199888896,
        "sender_full_name": "Arthur Parzygnat",
        "timestamp": 1591369261
    }
]