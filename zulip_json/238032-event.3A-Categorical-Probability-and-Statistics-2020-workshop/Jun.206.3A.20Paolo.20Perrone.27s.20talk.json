[
    {
        "content": "<p>Hey all,<br>\nThis is the discussion thread of my talk, \"Probability monads and stochastic dominance\".<br>\nThe talk, besides being on Zoom, is livestreamed here: <a href=\"https://youtu.be/kKDMCDUaxxE\">https://youtu.be/kKDMCDUaxxE</a></p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"kKDMCDUaxxE\" href=\"https://youtu.be/kKDMCDUaxxE\"><img src=\"https://i.ytimg.com/vi/kKDMCDUaxxE/default.jpg\"></a></div>",
        "id": 199794284,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591297933
    },
    {
        "content": "<p>Date and time: Saturday, 6 Jun, 15h UTC.</p>",
        "id": 199796139,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591298645
    },
    {
        "content": "<p>Hi! We start in 30 minutes.</p>",
        "id": 199977588,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591453810
    },
    {
        "content": "<p>Great talk.<br>\nCan you say something about the bar construction mentioned in the abstract?</p>",
        "id": 199981512,
        "sender_full_name": "Joscha Diehl",
        "timestamp": 1591459033
    },
    {
        "content": "<p>Do these ideas have anything to say about deciding between two investments p, q with nonzero probability of both p&lt;=q and p&gt;q, on the basis of expected return and risk?</p>",
        "id": 199981569,
        "sender_full_name": "Joshua Meyers",
        "timestamp": 1591459099
    },
    {
        "content": "<p>Yes, great talk!<br>\nIs there a formal formulation for this process of \"moving the mass\"? Maybe pullback along projetion and then pushforward?</p>",
        "id": 199981577,
        "sender_full_name": "Peter Arndt",
        "timestamp": 1591459141
    },
    {
        "content": "<p>I am wondering what is the main reason for considering order isomorphisms rather than homomorphisms for the complete metric space case? That is, why do we exclude coarse-grainings (of the order information)? Is (one) reason that we would be mixing up the first-order and second-order dominance (since the latter is related to coarse-grainings)?</p>",
        "id": 199981732,
        "sender_full_name": "Tomáš Gonda",
        "timestamp": 1591459325
    },
    {
        "content": "<p>A more exotic question: Is there a chance to have a unified treatment (which is still sufficiently expressive) of both first-order and second-order dominance at some level of abstraction? There are parallels between them, but also some important differences.</p>",
        "id": 199982005,
        "sender_full_name": "Tomáš Gonda",
        "timestamp": 1591459766
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"303393\">Joscha Diehl</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199981512\">said</a>:</p>\n<blockquote>\n<p>Great talk.<br>\nCan you say something about the bar construction mentioned in the abstract?</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"303393\">@Joscha Diehl</span>  Thanks! Yep. The maps <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>E</mi></mrow><annotation encoding=\"application/x-tex\">E</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span></span></span></span> and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mi>e</mi></mrow><annotation encoding=\"application/x-tex\">P e</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord mathdefault\">e</span></span></span></span> which give the equivalent characterization to second-order stochastic dominance are exactly the source and target maps of 1-simplices in the bar construction. This turns out to be quite structural!<br>\nThere's quite a bit to talk about - if you want I can expand. For now, two references are Chapter 4 of my thesis, and my MFPS talk here: <a href=\"https://youtu.be/28EASeG1RBA\">https://youtu.be/28EASeG1RBA</a> (paper here: <a href=\"https://arxiv.org/abs/1810.06037\">https://arxiv.org/abs/1810.06037</a>)</p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"28EASeG1RBA\" href=\"https://youtu.be/28EASeG1RBA\"><img src=\"https://i.ytimg.com/vi/28EASeG1RBA/default.jpg\"></a></div>",
        "id": 199984868,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591463892
    },
    {
        "content": "<p>By the way, here's the link to my thesis: <a href=\"http://paoloperrone.org/phdthesis.pdf\">http://paoloperrone.org/phdthesis.pdf</a></p>",
        "id": 199984876,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591463911
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"280784\">Joshua Meyers</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199981569\">said</a>:</p>\n<blockquote>\n<p>Do these ideas have anything to say about deciding between two investments p, q with nonzero probability of both p&lt;=q and p&gt;q, on the basis of expected return and risk?</p>\n</blockquote>\n<p>If I understand you correctly, yes. So one can prove that if we are over a <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi></mrow><annotation encoding=\"application/x-tex\">P</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span></span></span></span>-algebras, for example real numbers, then if <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">p</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">p</span></span></span></span> is lower than <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">q</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span></span></span></span> in the stochastic order, <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">p</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">p</span></span></span></span> has lower expectation value than <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">q</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span></span></span></span> - this expectation map is even <em>strictly</em> monotone. <br>\nFor what concerns risk, the second-order stochastic dominance is precisely the \"riskiness\". One can also use the two orders together, and that's sometimes also called second-order stochastic dominance. I can expand on this, if you want. In any case if you want a reference, this is worked out in my thesis, the link is above.</p>",
        "id": 199985065,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591464256
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"303936\">Peter Arndt</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199981577\">said</a>:</p>\n<blockquote>\n<p>Yes, great talk!<br>\nIs there a formal formulation for this process of \"moving the mass\"? Maybe pullback along projetion and then pushforward?</p>\n</blockquote>\n<p>Yes, but in general it's a <em>random</em> transport map, not a deterministic one. In the sense that the mass over a certain point may be split, and sent to two different points.</p>",
        "id": 199985116,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591464359
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"302756\">Tomáš Gonda</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199981732\">said</a>:</p>\n<blockquote>\n<p>I am wondering what is the main reason for considering order isomorphisms rather than homomorphisms for the complete metric space case? That is, why do we exclude coarse-grainings (of the order information)? Is (one) reason that we would be mixing up the first-order and second-order dominance (since the latter is related to coarse-grainings)?</p>\n</blockquote>\n<p>Oh, we are not using only order isomorphisms, but homomorphisms. We can coarse-grain all we want. Only the unit of the monad (the Dirac delta) happens to be an order-embedding, everything else is not. Sorry if that wasn't clear!</p>",
        "id": 199985180,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591464451
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"302756\">Tomáš Gonda</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199982005\">said</a>:</p>\n<blockquote>\n<p>A more exotic question: Is there a chance to have a unified treatment (which is still sufficiently expressive) of both first-order and second-order dominance at some level of abstraction? There are parallels between them, but also some important differences.</p>\n</blockquote>\n<p>Yep, there is, unfortunately I didn't have time to talk about that. It even satisfies a very nice universal property, it's a \"lax codescent object\". A way to obtain this composite order is to take the coinserter of the two maps <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>E</mi><mo separator=\"true\">,</mo><mi>T</mi><mi>e</mi><mo>:</mo><mi>P</mi><mi>A</mi><mo>→</mo><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">E, Te:PA\\to A</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span><span class=\"mord mathdefault\">e</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord mathdefault\">A</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">A</span></span></span></span>. I can expand on this, if you want.</p>",
        "id": 199985238,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591464534
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"275989\">Paolo Perrone</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199985180\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"302756\">Tomáš Gonda</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199981732\">said</a>:</p>\n<blockquote>\n<p>I am wondering what is the main reason for considering order isomorphisms rather than homomorphisms for the complete metric space case? That is, why do we exclude coarse-grainings (of the order information)? Is (one) reason that we would be mixing up the first-order and second-order dominance (since the latter is related to coarse-grainings)?</p>\n</blockquote>\n<p>Oh, we are not using only order isomorphisms, but homomorphisms. We can coarse-grain all we want. Only the unit of the monad (the Dirac delta) happens to be an order-embedding, everything else is not. Sorry if that wasn't clear!</p>\n</blockquote>\n<p>hm, ok, so what was the extra property of morphisms in COMet besides being order-preserving and 1-Lipschitz?</p>",
        "id": 199985382,
        "sender_full_name": "Tomáš Gonda",
        "timestamp": 1591464758
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"275989\">Paolo Perrone</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199985238\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"302756\">Tomáš Gonda</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199982005\">said</a>:</p>\n<blockquote>\n<p>A more exotic question: Is there a chance to have a unified treatment (which is still sufficiently expressive) of both first-order and second-order dominance at some level of abstraction? There are parallels between them, but also some important differences.</p>\n</blockquote>\n<p>Yep, there is, unfortunately I didn't have time to talk about that. It even satisfies a very nice universal property, it's a \"lax codescent object\". A way to obtain this composite order is to take the coinserter of the two maps <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>E</mi><mo separator=\"true\">,</mo><mi>T</mi><mi>e</mi><mo>:</mo><mi>P</mi><mi>A</mi><mo>→</mo><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">E, Te:PA\\to A</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span><span class=\"mord mathdefault\">e</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord mathdefault\">A</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">A</span></span></span></span>. I can expand on this, if you want.</p>\n</blockquote>\n<p>That sounds intriguing (although probably slightly different to what I actually had in mind). Does it give you the \"combined\" order (i.e. the intersection of the two order relations)? I would love to know more about that, is it in some of your articles?</p>",
        "id": 199985468,
        "sender_full_name": "Tomáš Gonda",
        "timestamp": 1591464939
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"302756\">Tomáš Gonda</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199985382\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"275989\">Paolo Perrone</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199985180\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"302756\">Tomáš Gonda</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199981732\">said</a>:</p>\n<blockquote>\n<p>I am wondering what is the main reason for considering order isomorphisms rather than homomorphisms for the complete metric space case? That is, why do we exclude coarse-grainings (of the order information)? Is (one) reason that we would be mixing up the first-order and second-order dominance (since the latter is related to coarse-grainings)?</p>\n</blockquote>\n<p>Oh, we are not using only order isomorphisms, but homomorphisms. We can coarse-grain all we want. Only the unit of the monad (the Dirac delta) happens to be an order-embedding, everything else is not. Sorry if that wasn't clear!</p>\n</blockquote>\n<p>hm, ok, so what was the extra property of morphisms in COMet besides being order-preserving and 1-Lipschitz?</p>\n</blockquote>\n<p>That's not on the morphisms, it's on the orders. It's definition 4.1.1 in this paper: <a href=\"https://arxiv.org/abs/1808.09898\">https://arxiv.org/abs/1808.09898</a><br>\nIt says that 1-Lipschitz monotone functions are \"enough to tell the order\", the order is never too \"steep\". Example 4.1.2 there gives a space which does not satisfy that property.</p>",
        "id": 199987919,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591469091
    },
    {
        "content": "<p>By the way, we called those spaces \"L-ordered\" in honor of Lawvere - I should have said that since he was in the audience!</p>",
        "id": 199987935,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591469132
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"302756\">Tomáš Gonda</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199985468\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"275989\">Paolo Perrone</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199985238\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"302756\">Tomáš Gonda</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199982005\">said</a>:</p>\n<blockquote>\n<p>A more exotic question: Is there a chance to have a unified treatment (which is still sufficiently expressive) of both first-order and second-order dominance at some level of abstraction? There are parallels between them, but also some important differences.</p>\n</blockquote>\n<p>Yep, there is, unfortunately I didn't have time to talk about that. It even satisfies a very nice universal property, it's a \"lax codescent object\". A way to obtain this composite order is to take the coinserter of the two maps <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>E</mi><mo separator=\"true\">,</mo><mi>T</mi><mi>e</mi><mo>:</mo><mi>P</mi><mi>A</mi><mo>→</mo><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">E, Te:PA\\to A</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span><span class=\"mord mathdefault\">e</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord mathdefault\">A</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">A</span></span></span></span>. I can expand on this, if you want.</p>\n</blockquote>\n<p>That sounds intriguing (although probably slightly different to what I actually had in mind). Does it give you the \"combined\" order (i.e. the intersection of the two order relations)? I would love to know more about that, is it in some of your articles?</p>\n</blockquote>\n<p>Oh, I think I see what you meant in your original question. I'd love to find a uniform treatment - so far we weren.t able to find it except pretty much for what I said during the talk. I suspect one can do this in Markov categories with conditionals though.<br>\nIf you want to know more about the combined order, see Section 4.3 of my thesis (link above). Hopefully it will become a paper soon.</p>",
        "id": 199988019,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591469269
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"275989\">Paolo Perrone</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199987919\">said</a>:</p>\n<blockquote>\n<p>That's not on the morphisms, it's on the orders. It's definition 4.1.1 in this paper: <a href=\"https://arxiv.org/abs/1808.09898\">https://arxiv.org/abs/1808.09898</a><br>\nIt says that 1-Lipschitz monotone functions are \"enough to tell the order\", the order is never too \"steep\". Example 4.1.2 there gives a space which does not satisfy that property.</p>\n</blockquote>\n<p>oh, that makes a lot of sense, thanks! I must have had a brief attention glitch while you were explaining it <span aria-label=\"sleeping\" class=\"emoji emoji-1f634\" role=\"img\" title=\"sleeping\">:sleeping:</span></p>",
        "id": 199988296,
        "sender_full_name": "Tomáš Gonda",
        "timestamp": 1591469726
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"275989\">Paolo Perrone</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199988019\">said</a>:</p>\n<blockquote>\n<p>Oh, I think I see what you meant in your original question. I'd love to find a uniform treatment - so far we weren.t able to find it except pretty much for what I said during the talk. I suspect one can do this in Markov categories with conditionals though.<br>\nIf you want to know more about the combined order, see Section 4.3 of my thesis (link above). Hopefully it will become a paper soon.</p>\n</blockquote>\n<p>I guess one way to interpret what I'd like to have from my (biased) perspective is finding a class of resource theories that would have enough structure to allow one to prove classification theorems about their resource orderings and which would include, as special cases, the first-order and second-order stochastic dominance among other preorders.</p>",
        "id": 199992095,
        "sender_full_name": "Tomáš Gonda",
        "timestamp": 1591475855
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"275989\">Paolo Perrone</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199985065\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"280784\">Joshua Meyers</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199981569\">said</a>:</p>\n<blockquote>\n<p>Do these ideas have anything to say about deciding between two investments p, q with nonzero probability of both p&lt;=q and p&gt;q, on the basis of expected return and risk?</p>\n</blockquote>\n<p>If I understand you correctly, yes. So one can prove that if we are over a <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi></mrow><annotation encoding=\"application/x-tex\">P</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span></span></span></span>-algebras, for example real numbers, then if <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">p</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">p</span></span></span></span> is lower than <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">q</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span></span></span></span> in the stochastic order, <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">p</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">p</span></span></span></span> has lower expectation value than <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">q</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span></span></span></span> - this expectation map is even <em>strictly</em> monotone. <br>\nFor what concerns risk, the second-order stochastic dominance is precisely the \"riskiness\". One can also use the two orders together, and that's sometimes also called second-order stochastic dominance. I can expand on this, if you want. In any case if you want a reference, this is worked out in my thesis, the link is above.</p>\n</blockquote>\n<p>Yes but if the events p&lt;=q and p&gt;q both have nonzero probability, then neither has first-order stochastic dominance over the other, as you have defined it.  And second-order stochastic dominance doesn't even apply, as they are not about \"the same data\".</p>\n<p>Yes p&lt;=q in the stochastic order implies that E(p)&lt;=E(q), but not conversely.</p>\n<p>Update:  I should have said that the events p&lt;q and q&lt;p both have nonzero probability, sorry for the confusion.</p>",
        "id": 199995635,
        "sender_full_name": "Joshua Meyers",
        "timestamp": 1591481967
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"280784\">Joshua Meyers</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199995635\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"275989\">Paolo Perrone</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199985065\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"280784\">Joshua Meyers</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199981569\">said</a>:</p>\n<blockquote>\n<p>Do these ideas have anything to say about deciding between two investments p, q with nonzero probability of both p&lt;=q and p&gt;q, on the basis of expected return and risk?</p>\n</blockquote>\n<p>If I understand you correctly, yes. So one can prove that if we are over a <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi></mrow><annotation encoding=\"application/x-tex\">P</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span></span></span></span>-algebras, for example real numbers, then if <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">p</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">p</span></span></span></span> is lower than <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">q</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span></span></span></span> in the stochastic order, <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">p</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">p</span></span></span></span> has lower expectation value than <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">q</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span></span></span></span> - this expectation map is even <em>strictly</em> monotone. <br>\nFor what concerns risk, the second-order stochastic dominance is precisely the \"riskiness\". One can also use the two orders together, and that's sometimes also called second-order stochastic dominance. I can expand on this, if you want. In any case if you want a reference, this is worked out in my thesis, the link is above.</p>\n</blockquote>\n<p>Yes but if the events p&lt;=q and p&gt;q both have nonzero probability, then neither has first-order stochastic dominance over the other, as you have defined it.  And second-order stochastic dominance doesn't even apply, as they are not about \"the same data\".</p>\n<p>Yes p&lt;=q in the stochastic order implies that E(p)&lt;=E(q), but not conversely.</p>\n<p>Update:  I should have said that the events p&lt;q and q&lt;p both have nonzero probability, sorry for the confusion.</p>\n</blockquote>\n<p>Uhm, I think I don't understand. There are (at least) 2 orders that one can construct, first and second order stochastic dominance, and their composite order as well. What is the question exactly, possibly in other words?</p>",
        "id": 199996921,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591484360
    },
    {
        "content": "<p>Perhaps Joshua is talking about the pointwise order on random variables that Paolo spoke about at the beginning? Joshua, what do you mean by the probability of the event p&lt;=q?</p>\n<p>If <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">p</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">p</span></span></span></span> and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">q</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span></span></span></span> are just probability measures on an ordered space, then it makes sense to try and compare them with respect to first-order stochastic dominance, even if no joint distribution is given, meaning that even if we cannot talk about the probability of \"the event <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi><mo>≥</mo><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">p \\ge q</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8304100000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">p</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≥</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span></span></span></span>\". So you should think of it like this: if someone offers you a bet with 50:50 odds and someone else offers you one with 80:20 odds against you, then you'd rather choose the 50:50 one, right? (Assuming that the stakes are the same.) That's because the 50:50 is higher up in first-order stochastic dominance. And to make this decision, there's no need to know how the two bets are correlated or whether they're independent! It's merely a relation involving pairs of distributions.</p>",
        "id": 199997274,
        "sender_full_name": "Tobias Fritz",
        "timestamp": 1591484922
    },
    {
        "content": "<p>Hi all! Here's the video.<br>\n<a href=\"https://youtu.be/auIuhRjMokQ\">https://youtu.be/auIuhRjMokQ</a></p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"auIuhRjMokQ\" href=\"https://youtu.be/auIuhRjMokQ\"><img src=\"https://i.ytimg.com/vi/auIuhRjMokQ/default.jpg\"></a></div>",
        "id": 200001732,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591493506
    },
    {
        "content": "<p>By the way, somebody was asking whether the stochastic order can be equivalently obtained by comparing quantiles: the answer is, yes if X = R, while in the general case of a partial order one cannot define quantiles. (Thanks to Sharwin Rezagholi for pointing that out!)</p>",
        "id": 200003653,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591497322
    },
    {
        "content": "<p>I am thinking that <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">p</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">p</span></span></span></span> and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">q</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span></span></span></span> are random variables, perhaps <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">p</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">p</span></span></span></span> is the return on investing in bananas and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">q</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span></span></span></span> is the return on investing in oranges.  Suppose that the sets <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">{</mo><mi>ω</mi><mo>∈</mo><mi mathvariant=\"normal\">Ω</mi><mi mathvariant=\"normal\">∣</mi><mi>q</mi><mo stretchy=\"false\">(</mo><mi>ω</mi><mo stretchy=\"false\">)</mo><mo>&gt;</mo><mi>p</mi><mo stretchy=\"false\">(</mo><mi>ω</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">}</mo></mrow><annotation encoding=\"application/x-tex\">\\{\\omega\\in\\Omega | q(\\omega)&gt;p(\\omega)\\}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">{</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">ω</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">Ω</span><span class=\"mord\">∣</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">ω</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&gt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">p</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">ω</span><span class=\"mclose\">)</span><span class=\"mclose\">}</span></span></span></span> and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">{</mo><mi>ω</mi><mo>∈</mo><mi mathvariant=\"normal\">Ω</mi><mi mathvariant=\"normal\">∣</mi><mi>p</mi><mo stretchy=\"false\">(</mo><mi>ω</mi><mo stretchy=\"false\">)</mo><mo>&gt;</mo><mi>q</mi><mo stretchy=\"false\">(</mo><mi>ω</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">}</mo></mrow><annotation encoding=\"application/x-tex\"> \\{\\omega\\in\\Omega | p(\\omega)&gt;q(\\omega)\\}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">{</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">ω</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">Ω</span><span class=\"mord\">∣</span><span class=\"mord mathdefault\">p</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">ω</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&gt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">ω</span><span class=\"mclose\">)</span><span class=\"mclose\">}</span></span></span></span> both have nonzero measure.  Then by your definition, we cannot say that either <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">p</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">p</span></span></span></span> or <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">q</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span></span></span></span> has first-order stochastic dominance over the other.  (I am recalling that you define <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">p</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">p</span></span></span></span> to have stochastic dominance over <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">q</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span></span></span></span> iff <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>μ</mi><mo stretchy=\"false\">(</mo><mo stretchy=\"false\">{</mo><mi>ω</mi><mo>∈</mo><mi mathvariant=\"normal\">Ω</mi><mi mathvariant=\"normal\">∣</mi><mi>p</mi><mo stretchy=\"false\">(</mo><mi>ω</mi><mo stretchy=\"false\">)</mo><mo>≥</mo><mi>q</mi><mo stretchy=\"false\">(</mo><mi>ω</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">}</mo><mo stretchy=\"false\">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">\\mu(\\{\\omega\\in\\Omega | p(\\omega)\\geq q(\\omega)\\})=1</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">μ</span><span class=\"mopen\">(</span><span class=\"mopen\">{</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">ω</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">Ω</span><span class=\"mord\">∣</span><span class=\"mord mathdefault\">p</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">ω</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≥</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">ω</span><span class=\"mclose\">)</span><span class=\"mclose\">}</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span>.)  Is there a way to still compare them in this case?  (Tobias's example of the two uncorrelated bets is an example of this.)</p>",
        "id": 200019388,
        "sender_full_name": "Joshua Meyers",
        "timestamp": 1591528029
    },
    {
        "content": "<p>Thank you very much for the effort to explain clearly and comprehensibly, <span class=\"user-mention\" data-user-id=\"275989\">@Paolo Perrone</span> . As a non-expert I deeply appreciate that, and I really enjoyed your talk, though much of it is way over my head. At least I feel your work is not completely out of reach for me, and that makes me very happy!</p>\n<p>Please take the following as a gentle suggestion and not as criticism. How about occasionally replacing examples using goods and gains by examples using, e.g., biological traits and fitness (these happen to be the constructs I'm mostly interested in <span aria-label=\"see no evil\" class=\"emoji emoji-1f648\" role=\"img\" title=\"see no evil\">:see_no_evil:</span>)? Traits can be anything from a cell's production rate of a protein, to the kind of care given by a parent to its offspring, and to the ploidy of the genetic system of the organism (multiplicity of chromosomes) or the pinkness of unicorns. Fitness usually represents some sort of success in reproduction or persistence that, crucially, does not necessarily occur at the expense of other entities (I am aware this may be possible also in economic contexts). IMHO this setting provides much nicer stories. I apologise if this suggestion is inappropriate.</p>",
        "id": 200019674,
        "sender_full_name": "Christoph Thies",
        "timestamp": 1591528527
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"280784\">Joshua Meyers</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200019388\">said</a>:</p>\n<blockquote>\n<p>I am thinking that <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">p</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">p</span></span></span></span> and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">q</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span></span></span></span> are random variables, perhaps <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">p</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">p</span></span></span></span> is the return on investing in bananas and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">q</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span></span></span></span> is the return on investing in oranges.  Suppose that the sets <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">{</mo><mi>ω</mi><mo>∈</mo><mi mathvariant=\"normal\">Ω</mi><mi mathvariant=\"normal\">∣</mi><mi>q</mi><mo stretchy=\"false\">(</mo><mi>ω</mi><mo stretchy=\"false\">)</mo><mo>&gt;</mo><mi>p</mi><mo stretchy=\"false\">(</mo><mi>ω</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">}</mo></mrow><annotation encoding=\"application/x-tex\">\\{\\omega\\in\\Omega | q(\\omega)&gt;p(\\omega)\\}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">{</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">ω</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">Ω</span><span class=\"mord\">∣</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">ω</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&gt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">p</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">ω</span><span class=\"mclose\">)</span><span class=\"mclose\">}</span></span></span></span> and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">{</mo><mi>ω</mi><mo>∈</mo><mi mathvariant=\"normal\">Ω</mi><mi mathvariant=\"normal\">∣</mi><mi>p</mi><mo stretchy=\"false\">(</mo><mi>ω</mi><mo stretchy=\"false\">)</mo><mo>&gt;</mo><mi>q</mi><mo stretchy=\"false\">(</mo><mi>ω</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">}</mo></mrow><annotation encoding=\"application/x-tex\"> \\{\\omega\\in\\Omega | p(\\omega)&gt;q(\\omega)\\}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">{</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">ω</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">Ω</span><span class=\"mord\">∣</span><span class=\"mord mathdefault\">p</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">ω</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&gt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">ω</span><span class=\"mclose\">)</span><span class=\"mclose\">}</span></span></span></span> both have nonzero measure.  Then by your definition, we cannot say that either <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">p</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">p</span></span></span></span> or <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">q</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span></span></span></span> has first-order stochastic dominance over the other.  (I am recalling that you define <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">p</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">p</span></span></span></span> to have stochastic dominance over <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">q</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span></span></span></span> iff <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>μ</mi><mo stretchy=\"false\">(</mo><mo stretchy=\"false\">{</mo><mi>ω</mi><mo>∈</mo><mi mathvariant=\"normal\">Ω</mi><mi mathvariant=\"normal\">∣</mi><mi>p</mi><mo stretchy=\"false\">(</mo><mi>ω</mi><mo stretchy=\"false\">)</mo><mo>≥</mo><mi>q</mi><mo stretchy=\"false\">(</mo><mi>ω</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">}</mo><mo stretchy=\"false\">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">\\mu(\\{\\omega\\in\\Omega | p(\\omega)\\geq q(\\omega)\\})=1</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">μ</span><span class=\"mopen\">(</span><span class=\"mopen\">{</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">ω</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">Ω</span><span class=\"mord\">∣</span><span class=\"mord mathdefault\">p</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">ω</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≥</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">ω</span><span class=\"mclose\">)</span><span class=\"mclose\">}</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span>.)  Is there a way to still compare them in this case?  (Tobias's example of the two uncorrelated bets is an example of this.)</p>\n</blockquote>\n<p>I see. If I understand correctly, if <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">p</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">p</span></span></span></span> and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">q</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span></span></span></span> come from random variables, and their joint assigns nonzero probability both to <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi><mo>≤</mo><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">x \\le y</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7719400000000001em;vertical-align:-0.13597em;\"></span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span></span></span></span> and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>y</mi><mo>≤</mo><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">y\\le x</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8304100000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">x</span></span></span></span>, then they are not comparable as random variables. However, it could still be that there exists some <em>other</em> joint entirely supported on the order relation - in that case <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">p</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">p</span></span></span></span> and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">q</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span></span></span></span> are comparable as random variables (in the stochastic order). It turns out that in many cases (such as over the real line) the stochastic order is a partial order, so if there is a joint assigning probability 1 to <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi><mo>≤</mo><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">x\\le y</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7719400000000001em;vertical-align:-0.13597em;\"></span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span></span></span></span> then there is no joint assigning probability 1 to <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>y</mi><mo>≤</mo><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">y\\le x</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8304100000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">x</span></span></span></span>. (A reference for the latter, for example, is this paper of Tobias, <a href=\"https://arxiv.org/abs/1810.06771\">https://arxiv.org/abs/1810.06771</a>.)</p>",
        "id": 200020315,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591529681
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"307303\">Christoph Thies</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200019674\">said</a>:</p>\n<blockquote>\n<p>Thank you very much for the effort to explain clearly and comprehensibly, <span class=\"user-mention silent\" data-user-id=\"275989\">Paolo Perrone</span> . As a non-expert I deeply appreciate that, and I really enjoyed your talk, though much of it is way over my head. At least I feel your work is not completely out of reach for me, and that makes me very happy!</p>\n<p>Please take the following as a gentle suggestion and not as criticism. How about occasionally replacing examples using goods and gains by examples using, e.g., biological traits and fitness (these happen to be the constructs I'm mostly interested in <span aria-label=\"see no evil\" class=\"emoji emoji-1f648\" role=\"img\" title=\"see no evil\">:see_no_evil:</span>)? Traits can be anything from a cell's production rate of a protein, to the kind of care given by a parent to its offspring, and to the ploidy of the genetic system of the organism (multiplicity of chromosomes) or the pinkness of unicorns. Fitness usually represents some sort of success in reproduction or persistence that, crucially, does not necessarily occur at the expense of other entities (I am aware this may be possible also in economic contexts). IMHO this setting provides much nicer stories. I apologise if this suggestion is inappropriate.</p>\n</blockquote>\n<p>Thank you for the appreciation!<br>\nIt would be nice to use examples from biology. Unfortunately I don't know enough about it though. Do you have a particular example in mind, that you'd like to explain to me?</p>",
        "id": 200020375,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591529797
    },
    {
        "content": "<p>By the way, some people asked which program I used as virtual blackboard. It's called Xournal, <a href=\"http://xournal.sourceforge.net/\">http://xournal.sourceforge.net/</a>.</p>",
        "id": 200020426,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591529905
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"275989\">@Paolo Perrone</span> You showed that conditional expectations on X can be phrased as partial evaluation/double distributions in the case where X is convex. Do you know how this could connect to other synthetic notions of conditioning (assuming our Markov category comes from a monad)? What if X is not convex, e.g. can we somehow express conditioning on boolean outputs?</p>",
        "id": 200022712,
        "sender_full_name": "Dario Stein",
        "timestamp": 1591533848
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"275989\">Paolo Perrone</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200020375\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"307303\">Christoph Thies</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200019674\">said</a>:</p>\n<blockquote>\n<p>Thank you very much for the effort to explain clearly and comprehensibly, <span class=\"user-mention silent\" data-user-id=\"275989\">Paolo Perrone</span> . As a non-expert I deeply appreciate that, and I really enjoyed your talk, though much of it is way over my head. At least I feel your work is not completely out of reach for me, and that makes me very happy!</p>\n<p>Please take the following as a gentle suggestion and not as criticism. How about occasionally replacing examples using goods and gains by examples using, e.g., biological traits and fitness (these happen to be the constructs I'm mostly interested in <span aria-label=\"see no evil\" class=\"emoji emoji-1f648\" role=\"img\" title=\"see no evil\">:see_no_evil:</span>)? Traits can be anything from a cell's production rate of a protein, to the kind of care given by a parent to its offspring, and to the ploidy of the genetic system of the organism (multiplicity of chromosomes) or the pinkness of unicorns. Fitness usually represents some sort of success in reproduction or persistence that, crucially, does not necessarily occur at the expense of other entities (I am aware this may be possible also in economic contexts). IMHO this setting provides much nicer stories. I apologise if this suggestion is inappropriate.</p>\n</blockquote>\n<p>Thank you for the appreciation!<br>\nIt would be nice to use examples from biology. Unfortunately I don't know enough about it though. Do you have a particular example in mind, that you'd like to explain to me?</p>\n</blockquote>\n<p>Hm, I don't have a specific example. In fact, wrt your talk I think your examples were perfectly appropriate. It just occurred to me this might be a useful suggestion since biology instantiates these abstract matters in ways quite different from economy.</p>\n<p>Personally, I am interested for example in biological scenarios in which taking the codomain of random variables that represent, say, traits to be the real numbers is not adequate so that classical statistics becomes sort of dodgy as a language for reasoning about them (and I am here in order to understand better what I mean by this and other things I don't quite understand).</p>",
        "id": 200023369,
        "sender_full_name": "Christoph Thies",
        "timestamp": 1591534907
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"309295\">Dario Stein</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200022712\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"275989\">Paolo Perrone</span> You showed that conditional expectations on X can be phrased as partial evaluation/double distributions in the case where X is convex. Do you know how this could connect to other synthetic notions of conditioning (assuming our Markov category comes from a monad)? What if X is not convex, e.g. can we somehow express conditioning on boolean outputs?</p>\n</blockquote>\n<p>That's a very good question! We are currently working on it actually (Tobias, Eigil, Tomáš and I), we suspect that you can. <br>\nFor non-convex things, when one conditions, one is usually doing one of these two things: either conditioning a function on <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">X</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span></span></span></span> <em>into</em> a convex set (say, US states to political preferences), or, working on the free convex space <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">PX</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span></span></span></span>.</p>",
        "id": 200025684,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591538809
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"275989\">@Paolo Perrone</span> I don't understand your example in the beginning. Why is the white curve better than the yellow?</p>",
        "id": 200025968,
        "sender_full_name": "Manuel Bärenz",
        "timestamp": 1591539316
    },
    {
        "content": "<p>(Following up from in-person conversation: the intuition is that the white curve is both \"higher up\", so that you are likely to gain more, and \"more peaked\", so you have a better idea of how much exactly you will gain - which can be useful for planning a strategy.)</p>",
        "id": 200026177,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591539674
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"275989\">Paolo Perrone</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200025684\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"309295\">Dario Stein</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200022712\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"275989\">Paolo Perrone</span> You showed that conditional expectations on X can be phrased as partial evaluation/double distributions in the case where X is convex. Do you know how this could connect to other synthetic notions of conditioning (assuming our Markov category comes from a monad)? What if X is not convex, e.g. can we somehow express conditioning on boolean outputs?</p>\n</blockquote>\n<p>That's a very good question! We are currently working on it actually (Tobias, Eigil, Tomáš and I), we suspect that you can. <br>\nFor non-convex things, when one conditions, one is usually doing one of these two things: either conditioning a function on <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">X</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span></span></span></span> <em>into</em> a convex set (say, US states to political preferences), or, working on the free convex space <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">PX</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span></span></span></span>.</p>\n</blockquote>\n<p>Fantastic, very interested by that. Sam's and my Beta-Bernoulli monad encodes essentially the conjugate prior relationship of the two distributions and nothing more; I'd be keen to work out if we can formalize conditioning on the Bernoulli flips in a synthetic way (the main difficulty so far was the central position of if/coproducts in the language, which Markov categories still don't reflect well).</p>",
        "id": 200033475,
        "sender_full_name": "Dario Stein",
        "timestamp": 1591550608
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"309295\">Dario Stein</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200033475\">said</a>:</p>\n<blockquote>\n<p>Fantastic, very interested by that. Sam's and my Beta-Bernoulli monad encodes essentially the conjugate prior relationship of the two distributions and nothing more; I'd be keen to work out if we can formalize conditioning on the Bernoulli flips in a synthetic way (the main difficulty so far was the central position of if/coproducts in the language, which Markov categories still don't reflect well).</p>\n</blockquote>\n<p>I'd like to understand what you mean in a little more detail, if you could elaborate or point me to a reference. For example, what exactly is the Beta-Bernoulli monad? Perhaps <a href=\"http://math.mit.edu/~freer//papers/SSYAFR-Beta-Bernoulli.pdf\">this paper</a> of yours? And is what you're talking about related to Jacobs' work on conjugate priors [Ref: <a href=\"https://arxiv.org/abs/1707.00269]\">https://arxiv.org/abs/1707.00269]</a>? From my understanding of his paper, he had a nice description of conjugate priors in the Markov category language.</p>",
        "id": 200039167,
        "sender_full_name": "Arthur Parzygnat",
        "timestamp": 1591559195
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"275989\">Paolo Perrone</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199984868\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"303393\">Joscha Diehl</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199981512\">said</a>:</p>\n<blockquote>\n<p>Great talk.<br>\nCan you say something about the bar construction mentioned in the abstract?</p>\n</blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"303393\">Joscha Diehl</span>  Thanks! Yep. The maps <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>E</mi></mrow><annotation encoding=\"application/x-tex\">E</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span></span></span></span> and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mi>e</mi></mrow><annotation encoding=\"application/x-tex\">P e</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord mathdefault\">e</span></span></span></span> which give the equivalent characterization to second-order stochastic dominance are exactly the source and target maps of 1-simplices in the bar construction. This turns out to be quite structural!<br>\nThere's quite a bit to talk about - if you want I can expand. For now, two references are Chapter 4 of my thesis, and my MFPS talk here: <a href=\"https://youtu.be/28EASeG1RBA\">https://youtu.be/28EASeG1RBA</a> (paper here: <a href=\"https://arxiv.org/abs/1810.06037\">https://arxiv.org/abs/1810.06037</a>)</p>\n</blockquote>\n<p>Thanks! The paper should be a good entry point for me to get what's going on. I was thinking of the bar construction in algebra, that builds a coalgebra out of an algebra. I guess the categorial bar construction is an abstraction of that?<br>\nMore conceptually: is the hope in understanding 'your' bar construction, to get to third-order dominance, etc?</p>",
        "id": 200064453,
        "sender_full_name": "Joscha Diehl",
        "timestamp": 1591600573
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"303393\">Joscha Diehl</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200064453\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"275989\">Paolo Perrone</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199984868\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"303393\">Joscha Diehl</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199981512\">said</a>:</p>\n<blockquote>\n<p>Great talk.<br>\nCan you say something about the bar construction mentioned in the abstract?</p>\n</blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"303393\">Joscha Diehl</span>  Thanks! Yep. The maps <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>E</mi></mrow><annotation encoding=\"application/x-tex\">E</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span></span></span></span> and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mi>e</mi></mrow><annotation encoding=\"application/x-tex\">P e</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord mathdefault\">e</span></span></span></span> which give the equivalent characterization to second-order stochastic dominance are exactly the source and target maps of 1-simplices in the bar construction. This turns out to be quite structural!<br>\nThere's quite a bit to talk about - if you want I can expand. For now, two references are Chapter 4 of my thesis, and my MFPS talk here: <a href=\"https://youtu.be/28EASeG1RBA\">https://youtu.be/28EASeG1RBA</a> (paper here: <a href=\"https://arxiv.org/abs/1810.06037\">https://arxiv.org/abs/1810.06037</a>)</p>\n</blockquote>\n<p>Thanks! The paper should be a good entry point for me to get what's going on. I was thinking of the bar construction in algebra, that builds a coalgebra out of an algebra. I guess the categorial bar construction is an abstraction of that?<br>\nMore conceptually: is the hope in understanding 'your' bar construction, to get to third-order dominance, etc?</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"303393\">@Joscha Diehl</span> I don't know if we get a coalgebra in this general case, it could be interesting! Anybody knows how this works?<br>\nIn any case, here's roughly what happens. In the category of sets, the functor given by multiplying with a group (or monoid) <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi><mo>↦</mo><mi>G</mi><mo>×</mo><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">X\\mapsto G\\times X</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69433em;vertical-align:-0.011em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">↦</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathdefault\">G</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span></span></span></span> has a natural monad structure, with unit and multiplication given by those of <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>G</mi></mrow><annotation encoding=\"application/x-tex\">G</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">G</span></span></span></span>. It's called the <em>action monad</em>, or <em>writer monad</em> in computer science, <a href=\"https://ncatlab.org/nlab/show/action+monad\">https://ncatlab.org/nlab/show/action+monad</a><br>\nAlgebra over this monad are <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>G</mi></mrow><annotation encoding=\"application/x-tex\">G</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">G</span></span></span></span>-sets, i.e. sets with a <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>G</mi></mrow><annotation encoding=\"application/x-tex\">G</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">G</span></span></span></span>-action. The very same holds in the category of Abelian groups if you take a ring <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>R</mi></mrow><annotation encoding=\"application/x-tex\">R</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span></span></span></span> and the functor given by tensoring with the ring. Algebras in this case are <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>R</mi></mrow><annotation encoding=\"application/x-tex\">R</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span></span></span></span>-modules.<br>\nNow it turns out that in order to define the bar construction, one does not need a group or a ring, the monad structure is enough. Outside the category of Abelian groups one gets a simplicial object, which in the Abelian case is \"the same\" as a chain complex by the Dold-Kan correspondence.<br>\nIf you do that for probability monads, this simplicial object is such that 0-simplices are probability measures over a convex space (such as R), and 1-simplices are (basically) conditional expectations. Two measures are connected by an \"edge\" if one can be obtained by \"concentrating\" the other one (as we did in the US states example). </p>\n<p>The question about third-order stochastic dominance is very interesting, I've always wondered how to obtain it in this framework, but I never figured it out. Do you have an idea in mind?</p>",
        "id": 200085491,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591616339
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"296639\">Arthur Parzygnat</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200039167\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"309295\">Dario Stein</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200033475\">said</a>:</p>\n<blockquote>\n<p>Fantastic, very interested by that. Sam's and my Beta-Bernoulli monad encodes essentially the conjugate prior relationship of the two distributions and nothing more; I'd be keen to work out if we can formalize conditioning on the Bernoulli flips in a synthetic way (the main difficulty so far was the central position of if/coproducts in the language, which Markov categories still don't reflect well).</p>\n</blockquote>\n<p>I'd like to understand what you mean in a little more detail, if you could elaborate or point me to a reference. For example, what exactly is the Beta-Bernoulli monad? Perhaps <a href=\"http://math.mit.edu/~freer//papers/SSYAFR-Beta-Bernoulli.pdf\">this paper</a> of yours? And is what you're talking about related to Jacobs' work on conjugate priors [Ref: <a href=\"https://arxiv.org/abs/1707.00269]\">https://arxiv.org/abs/1707.00269]</a>? From my understanding of his paper, he had a nice description of conjugate priors in the Markov category language.</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"296639\">@Arthur Parzygnat</span> yes, I meant that paper -- we didn't frame things very categorically there, but this amounts to giving a commutative&amp;affine monad on the functor category [Fin,Set] (Sam mentioned this approach in his talk). Its Kleisli category is thus a minimalistic combinatorial Markov category that encodes beta+bernoulli+their conjugate relationship. Thanks for the reference to Bart's paper, I'll have a look at it.</p>",
        "id": 200088962,
        "sender_full_name": "Dario Stein",
        "timestamp": 1591618708
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"275989\">@Paolo Perrone</span> Thanks! Regarding third-order: no, I don't even know what third order dominance would mean. I'd hope it would pop out of the categorial view you have ..</p>",
        "id": 200106354,
        "sender_full_name": "Joscha Diehl",
        "timestamp": 1591627095
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"303393\">Joscha Diehl</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200106354\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"275989\">Paolo Perrone</span> Thanks! Regarding third-order: no, I don't even know what third order dominance would mean. I'd hope it would pop out of the categorial view you have ..</p>\n</blockquote>\n<p>My intuition would suggest, \"the measure is more concentrated on lower values and more spread on higher values\". But that's as much as I can say for now, nothing precise. (Imagine, on R, assigning a larger integral to functions such as f(x)=x^3.)</p>",
        "id": 200106644,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591627223
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"275989\">Paolo Perrone</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200106644\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"303393\">Joscha Diehl</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200106354\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"275989\">Paolo Perrone</span> Thanks! Regarding third-order: no, I don't even know what third order dominance would mean. I'd hope it would pop out of the categorial view you have ..</p>\n</blockquote>\n<p>My intuition would suggest, \"the measure is more concentrated on lower values and more spread on higher values\". But that's as much as I can say for now, nothing precise. (Imagine, on R, assigning a larger integral to functions such as f(x)=x^3.)</p>\n</blockquote>\n<p>Is there something like this already in the literature? Also, you might have mentioned it, but  it his obvious how first order and second order dominance are part of a 'ladder' of dominances?</p>",
        "id": 200106922,
        "sender_full_name": "Joscha Diehl",
        "timestamp": 1591627342
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"303393\">Joscha Diehl</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200106922\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"275989\">Paolo Perrone</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200106644\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"303393\">Joscha Diehl</span> <a href=\"#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200106354\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"275989\">Paolo Perrone</span> Thanks! Regarding third-order: no, I don't even know what third order dominance would mean. I'd hope it would pop out of the categorial view you have ..</p>\n</blockquote>\n<p>My intuition would suggest, \"the measure is more concentrated on lower values and more spread on higher values\". But that's as much as I can say for now, nothing precise. (Imagine, on R, assigning a larger integral to functions such as f(x)=x^3.)</p>\n</blockquote>\n<p>Is there something like this already in the literature? Also, you might have mentioned it, but  it his obvious how first order and second order dominance are part of a 'ladder' of dominances?</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"303393\">@Joscha Diehl</span>  Yep, but I don't understand them very well: <a href=\"https://en.wikipedia.org/wiki/Stochastic_dominance#Third-order\">https://en.wikipedia.org/wiki/Stochastic_dominance#Third-order</a></p>",
        "id": 200107110,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1591627432
    }
]