[
    {
        "content": "<p>Hi all, we just put up our paper <a href=\"https://arxiv.org/abs/2103.01931\">Categorical Foundations of Gradient-Based Learning</a> up on arxiv. This is joint work with <span class=\"user-mention\" data-user-id=\"317561\">@Geoff Cruttwell</span> , Neil Ghani, <span class=\"user-mention\" data-user-id=\"316240\">@Paul</span> and <span class=\"user-mention\" data-user-id=\"351836\">@Fabio Zanasi</span> .</p>\n<p>We provided a 2-categorical foundation for many types of neural networks in terms three things: 1)  parameterized maps (the <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">P</mi><mi mathvariant=\"bold\">a</mi><mi mathvariant=\"bold\">r</mi><mi mathvariant=\"bold\">a</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbf{Para}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68611em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathbf\">P</span><span class=\"mord mathbf\">a</span><span class=\"mord mathbf\">r</span><span class=\"mord mathbf\">a</span></span></span></span></span> construction), 2) lenses, and 3) reverse derivative categories.<br>\nThis includes learning on well-known Euclidean spaces, but also weird things like learning on Boolean Circuits (since, surprisingly, they are a reverse derivative category too).<br>\nIt also turns out a bunch of things called \"optimizers\" are lenses as well - starting from standard gradient descent, through Momentum and Nesterov Momentum to more complex optimizers like Adagrad and Adam. </p>\n<p>This was also a bit surprising but it somehow all fits together - since optimizers are lenses they end up being 2-cells in our category. But I'll stop here and defer you to all the details in the paper.</p>",
        "id": 228809432,
        "sender_full_name": "Bruno Gavranović",
        "timestamp": 1614877062
    },
    {
        "content": "<p>Looking for any feedback or thoughts you may have about it :)</p>",
        "id": 228809872,
        "sender_full_name": "Bruno Gavranović",
        "timestamp": 1614877206
    },
    {
        "content": "<p>This is great <span class=\"user-mention\" data-user-id=\"276875\">@Bruno Gavranovic</span> I will be reading this in the next couple of weeks. Will let you know if I have any comments</p>",
        "id": 228819101,
        "sender_full_name": "Georgios Bakirtzis",
        "timestamp": 1614880375
    },
    {
        "content": "<p>Well I just discovered that this stream, which I previously wasn't subscribed to, has a <em>lot</em> of stuff I'm interested in</p>",
        "id": 228819595,
        "sender_full_name": "Jules Hedges",
        "timestamp": 1614880567
    },
    {
        "content": "<p>I'll also supplement the paper with a <a href=\"https://youtu.be/tKM8JdXJEII\">video of the presentation I did on the paper</a>. The video should be much more informal, visual and it also takes a slightly different perspective on the paper.</p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"tKM8JdXJEII\" href=\"https://youtu.be/tKM8JdXJEII\"><img src=\"https://i.ytimg.com/vi/tKM8JdXJEII/default.jpg\"></a></div>",
        "id": 228821530,
        "sender_full_name": "Bruno Gavranović",
        "timestamp": 1614881236
    },
    {
        "content": "<p>Loving it! You mention that reverse differential categories are good for classification b/c the target dimension is low. Does that mean we should expect  forward differentials to be better for generative tasks?</p>",
        "id": 228825358,
        "sender_full_name": "Spencer Breiner",
        "timestamp": 1614882563
    },
    {
        "content": "<p>That's a great question and something I've been wondering about as well. I suspect so, but honestly, I don't know - I'd love to hear more from some AI expert on this</p>",
        "id": 228830298,
        "sender_full_name": "Bruno Gavranović",
        "timestamp": 1614884417
    }
]