[
    {
        "content": "<p>Fresh off the presses w/ Michalis Savvas and Ufuk Topcu <a href=\"https://arxiv.org/pdf/2208.13687.pdf\">https://arxiv.org/pdf/2208.13687.pdf</a></p>",
        "id": 297013625,
        "sender_full_name": "Georgios Bakirtzis",
        "timestamp": 1662222884
    },
    {
        "content": "<p>Have you tried promoting this paper with the AGI safety people? They would really like this stuff. Or the interpretable ml crowd?(edit, I might just post this to some related places)</p>",
        "id": 308197279,
        "sender_full_name": "Sichu Lu",
        "timestamp": 1667691182
    },
    {
        "content": "<p>I am not sure where these people hang out, please let me know how the conversation goes if you do (or let me know where it is if in public)</p>",
        "id": 308383212,
        "sender_full_name": "Georgios Bakirtzis",
        "timestamp": 1667826030
    },
    {
        "content": "<p>Well, I am waiting for some people to get back to me, but I was thinking about posting this on <a href=\"https://www.alignmentforum.org/\">https://www.alignmentforum.org/</a> and it cross posts to the less wrong as well. If there is interest, maybe you should be the one to do it since it's your paper.</p>",
        "id": 308489623,
        "sender_full_name": "Sichu Lu",
        "timestamp": 1667862189
    },
    {
        "content": "<p>You're welcome to do it since you know the community better if you have the time, I'll chip in if you setup the threads in the right locations for that community. But up to you!</p>",
        "id": 308608588,
        "sender_full_name": "Georgios Bakirtzis",
        "timestamp": 1667920484
    }
]