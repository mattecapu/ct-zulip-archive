[
    {
        "content": "<p><a href=\"https://mathstodon.xyz/@johncarlosbaez/112806557618056885\">Today I learned</a> that  Trump's vice presidential pick has unlocked a lot of financial support from Silicon Valley billionaires, because Vance is deeply connected to folks like Peter Thiel and Marc Andreesen, who are afraid that Biden will rein in AI and crypto.   I hope everyone using applied category theory for these technologies, or tech in general, keeps paying attention to these developments.</p>",
        "id": 452295704,
        "sender_full_name": "John Baez",
        "timestamp": 1721295021
    },
    {
        "content": "<p>Oof where are the billionaires funding AI legislation?</p>",
        "id": 452375596,
        "sender_full_name": "Morgan Rogers (he/him)",
        "timestamp": 1721316654
    },
    {
        "content": "<p>fwiw, we try to compete against Thiel and palantir not just on tech, but on ethics. The open-source ACT community clip art associating sigma/delta/pi with Tolkien's Lord of the Rings silmarils jewels at <a href=\"http://silmarils.tech\">http://silmarils.tech</a> actually has an anti-palantir bent: in Lord of the Rings, the creators of the palantiri had a great foe, who wore a crown with three jewels.  So I can offer this artwork as a symbol of resistance.</p>",
        "id": 452404118,
        "sender_full_name": "Ryan Wisnesky",
        "timestamp": 1721324778
    },
    {
        "content": "<p>Kind of odd to imagine identifying with Team Morgoth, but I see where you're coming from!</p>",
        "id": 452410356,
        "sender_full_name": "Kevin Carlson",
        "timestamp": 1721326535
    },
    {
        "content": "<p>the onion's thoughts on the matter: <a href=\"https://www.theonion.com/j-d-vance-vows-to-fight-for-forgotten-communities-in-s-1851602605\">https://www.theonion.com/j-d-vance-vows-to-fight-for-forgotten-communities-in-s-1851602605</a></p>",
        "id": 453731133,
        "sender_full_name": "Ryan Wisnesky",
        "timestamp": 1721835811
    },
    {
        "content": "<p><a href=\"https://seasonaltokens.org/\">Cryptocommodity</a> is a good thing!</p>\n<p>Bye bye dollar ;)</p>",
        "id": 485217919,
        "sender_full_name": "Posina Venkata Rayudu",
        "timestamp": 1732964655
    },
    {
        "content": "<p>I'm pretty disappointed by Robert Ghrist's recent writing on AI and mathematics. A lot of writing on AI seems to carry a note of bitter vindictiveness against mathematicians who are interested in logical rigor and correct arguments, as these are a form of Luddism in the age of AI.</p>\n<blockquote>\n<p>3A// academics : your life is more complicated still. you have to teach the courses, write the grants, manage your phd students. the students are using AI to write their theses. they are either better at it than you or not -- either way, you are frustrated. your vaunted network effects (conferences, journal editors you know personally, your cadre of students) have diminishing returns as AI advances. what good is knowing terry tao personally when anyone can hit up the TT API from DeepSeek? plus -- and this is crucial -- you're a research mathematician, which means you are very conservative and probably don't believe in all that AI crap since it's just linear algebra and probability. can't fool you, no. you'll wake up too late and be too behind. HFSP (have fun staying pure)</p>\n</blockquote>",
        "id": 496052417,
        "sender_full_name": "Patrick Nicodemus",
        "timestamp": 1737963279
    },
    {
        "content": "<blockquote>\n<p>and as long as you have some taste and management skill, you can rival a top mathematician in terms of generating an army of phdai students to work with you / for you. oh, sure, it will be infinitely easier to write crank 500-page nonsense proofs of the trisection of an angle, but that's because AI is a force multiplier.</p>\n</blockquote>\n<p>A lab staffed by an army of \"PhD\" AI models is an interesting concept. I mostly think this is just fantasy though.</p>",
        "id": 496052716,
        "sender_full_name": "Patrick Nicodemus",
        "timestamp": 1737963395
    },
    {
        "content": "<blockquote>\n<p>7/ end, for now. we'll see how this holds up in a few years. in the meantime, i've got some research to work on in fields that i've never published in before (neural networks architecture, financial network models, ...)</p>\n</blockquote>\n<p>I look forward to seeing his AI assisted research in new fields. I guess there's really nothing stopping us from publishing in several adjacent fields which are entirely new to us now that we can learn the basics in two weeks with AI. After all, medical science is expected to advance very quickly - <a href=\"https://observer.com/2025/01/anthropic-dario-amodei-ai-advances-double-human-lifespans/\">https://observer.com/2025/01/anthropic-dario-amodei-ai-advances-double-human-lifespans/</a></p>",
        "id": 496054078,
        "sender_full_name": "Patrick Nicodemus",
        "timestamp": 1737963961
    },
    {
        "content": "<blockquote>\n<p>2/ what does AI change? not today's AI -- the AI that is coming, that reasons better than a crack phd student, writes clearly, has creative ideas (but maybe not a sense of good taste), can upload to the ArXiV, and, most importantly, can be manifested in as large a group of agents as you (or a manager-AI) can handle...</p>\n</blockquote>\n<p>Wow, not just a lab staff of AI language models, but a manager too, to check their work and identify hallucinations. Like an ant farm of mathematicians. Lots to be optimistic about here.</p>",
        "id": 496060065,
        "sender_full_name": "Patrick Nicodemus",
        "timestamp": 1737966112
    },
    {
        "content": "<p>Wow I'm more than disappointed. That's deliberately irritating writing.</p>",
        "id": 496102473,
        "sender_full_name": "Morgan Rogers (he/him)",
        "timestamp": 1737978377
    },
    {
        "content": "<p>Where did you get those quotes?</p>",
        "id": 496108458,
        "sender_full_name": "Matteo Capucci (he/him)",
        "timestamp": 1737980339
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"275932\">Matteo Capucci (he/him)</span> <a href=\"#narrow/channel/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies/near/496108458\">said</a>:</p>\n<blockquote>\n<p>Where did you get those quotes?</p>\n</blockquote>\n<p>nitter doesn't work with articles, so here's a direct link to that other fascist's website <a href=\"https://x.com/robertghrist/article/1883646365777236306\">https://x.com/robertghrist/article/1883646365777236306</a></p>",
        "id": 496128261,
        "sender_full_name": "Josselin Poiret",
        "timestamp": 1737986180
    },
    {
        "content": "<p>I guess he's looking to jump ship into tech?</p>",
        "id": 496130921,
        "sender_full_name": "Morgan Rogers (he/him)",
        "timestamp": 1737986880
    },
    {
        "content": "<p>By coincidence someone at our Lunar New Year party last night said that Ghrist was involved in some kind of \"accelerationism\" - I forget the adjective they stuck in front of that noun, but the idea was something like: the only way to save civilization is to accelerate the development of AI.   This person seemed to be saying Ghrist had written a kind of accelerationist manifesto.  Does anyone here know about that?</p>\n<p>The <a href=\"https://x.com/robertghrist/article/1883646365777236306\">article just mentioned</a> doesn't seem to be that manifesto, quite.</p>",
        "id": 496170022,
        "sender_full_name": "John Baez",
        "timestamp": 1737996992
    },
    {
        "content": "<p>I think it was \"effective accelerationism\".</p>",
        "id": 496185592,
        "sender_full_name": "Joe Moeller",
        "timestamp": 1738001882
    },
    {
        "content": "<p>Oh, yeah, \"effective accelerationism\" is like a religion in silicon valley <a href=\"https://en.wikipedia.org/wiki/Effective_accelerationism\">https://en.wikipedia.org/wiki/Effective_accelerationism</a></p>",
        "id": 496188983,
        "sender_full_name": "Ryan Wisnesky",
        "timestamp": 1738003043
    },
    {
        "content": "<p>For context on this awful Internet nonsense, effective accelerationism is a movement named in parody of effective altruism that supposes we just need to go full speed ahead to let the AIs replace us with transhuman interdimensional beings or whatever. The leader of the movement, before being deanonymized, was known as Based Beff Jezos. It's rather grim to my mind that Ghrist is into this.</p>",
        "id": 496196972,
        "sender_full_name": "Kevin Carlson",
        "timestamp": 1738006039
    },
    {
        "content": "<p>Thanks!  I don't actually <em>know</em> that Ghrist is into effective accelerationism, but the person I'm alluding to said he was. </p>\n<p>I'm not sure if that explains Ghrist calling presheaves 'sheaves', but I suppose doing so speeds thing up a bit.   <span aria-label=\"upside down\" class=\"emoji emoji-1f643\" role=\"img\" title=\"upside down\">:upside_down:</span></p>",
        "id": 496218576,
        "sender_full_name": "John Baez",
        "timestamp": 1738015121
    },
    {
        "content": "<p>\"e/acc\" is dangerous pseudo-mystical claptrap that doesn't see any importance for the survival of humanity or human values in the future:</p>\n<blockquote>\n<p>The founders of the movement see it as rooted in <a href=\"https://en.wikipedia.org/wiki/Jeremy_England\">Jeremy England</a>'s theory on the <a href=\"https://en.wikipedia.org/wiki/Abiogenesis\">origin of life</a>, which is focused on <a href=\"https://en.wikipedia.org/wiki/Entropy\">entropy</a> and <a href=\"https://en.wikipedia.org/wiki/Thermodynamics\">thermodynamics</a>.<a href=\"https://en.wikipedia.org/wiki/Effective_accelerationism#cite_note-:7-11\">[11]</a> According to them, the universe aims to increase entropy, and life is a way of increasing it. By spreading life throughout the universe and making life use up ever increasing amounts of energy, the universe's purpose would thus be fulfilled.<a href=\"https://en.wikipedia.org/wiki/Effective_accelerationism#cite_note-:7-11\">[11]</a></p>\n</blockquote>\n<p>In other words, it means caring about life only insofar as life produces entropy.  Then as with libertarianism you get \"(im)moderate optimists\" who convince themselves that when following the core principle off of a cliff you actually won't encounter a cliff, and that the thing that maximizes production of entropy will be \"sufficiently like humans\" in some sense that's satisfying to them personally, thus having their cake and eating it too at the expense of intellectual honesty.</p>\n<p>I find it pretty disturbing that people like that are allowed to be involved in the development of AI.</p>",
        "id": 496361546,
        "sender_full_name": "James Deikun",
        "timestamp": 1738077894
    },
    {
        "content": "<p>\"e/acc\" more like \"eek\" am I right</p>",
        "id": 496376807,
        "sender_full_name": "Morgan Rogers (he/him)",
        "timestamp": 1738082139
    },
    {
        "content": "<p>Well, the thing is, there’s no entity to with the affordance to “allow” or “not allow”, and having a mindset like that is very positively correlated with <em>wanting</em> to work on AI…</p>",
        "id": 496394739,
        "sender_full_name": "Kevin Carlson",
        "timestamp": 1738087481
    },
    {
        "content": "<p>That's true in the strict sense of legality, but there are people making decisions about whether to <em>enable</em> such activity, such as those who give funding to these people, right?</p>",
        "id": 496395997,
        "sender_full_name": "Mike Shulman",
        "timestamp": 1738087821
    },
    {
        "content": "<p>From what I've read from Ghrist, I'd guess that he aligns with e/acc on aesthetic before ethical grounds. To a certain extent a lot of this seems like a re-edition of Italian futurism, it stems from a pre-rational excitement with new technology and wish to be a \"person of the new century\" and not one of those left behind. As in the case of futurists largely embracing fascism, though, this often goes hand in hand with an ethos of \"adapt or die\" that's easy to exploit for reactionaries (who will choose who exactly is \"standing in the way of progress\").</p>",
        "id": 496405038,
        "sender_full_name": "Amar Hadzihasanovic",
        "timestamp": 1738090896
    },
    {
        "content": "<p>I mean, from what I see in his social media presence, Ghrist</p>\n<ul>\n<li>is genuinely excited about LLMs and aggressively using them in his work,</li>\n<li>styles himself as an artist-polymath-intellectual,</li>\n<li>has a penchant for contrarianism and a bit of provocation</li>\n</ul>\n<p>all of which make me think of futurist intellectuals, and also makes me doubt that he would genuinely embrace some form of sci-fi-utopianism (but not that he would claim ironically/provocatively to be on the side of those who do)</p>",
        "id": 496408959,
        "sender_full_name": "Amar Hadzihasanovic",
        "timestamp": 1738092288
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276777\">Mike Shulman</span> <a href=\"#narrow/channel/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies/near/496395997\">said</a>:</p>\n<blockquote>\n<p>That's true in the strict sense of legality, but there are people making decisions about whether to <em>enable</em> such activity, such as those who give funding to these people, right?</p>\n</blockquote>\n<p>Mmm, yes, but those people still an extremely distributed entity, including every venture capitalist in the country, various different managers at every major tech company, every government research funding agency, not to mention analogous structures in Europe, China, etc... I don't think \"allowed to work on AI\" as a unified property of a person is a very meaningful frame. You could instead say \"I think funders of AI should be discouraged from supporting such people working on AI\", and at least that makes the problem clearer, of eg convincing every tech billionaire and everyone with budgetary authority at Microsoft, Google, or Meta independently not to fund such people.</p>",
        "id": 496427214,
        "sender_full_name": "Kevin Carlson",
        "timestamp": 1738099663
    },
    {
        "content": "<p>I like the analogy with futurism; everything obsessed with the new is old again, I suppose.</p>",
        "id": 496427343,
        "sender_full_name": "Kevin Carlson",
        "timestamp": 1738099703
    },
    {
        "content": "<p>The US government tried to slow Chinese and Russian work on AI in various ways, including the <a href=\"https://en.wikipedia.org/wiki/CHIPS_and_Science_Act\">CHIPS and Science act</a>:</p>\n<blockquote>\n<p>Companies are subjected to a ten-year ban prohibiting them from producing chips more advanced than <a href=\"https://en.wikipedia.org/wiki/28_nm_process\">28 nanometers</a> in China and Russia if they are awarded subsidies under the law.</p>\n</blockquote>\n<p>But, it seems the Chinese behind <a href=\"https://www.newsweek.com/deepseek-elon-musk-microchip-claims-2021394\">DeepSeek</a> figured out how to develop LLMs more efficiently:</p>\n<blockquote>\n<p>Deepseek says it only needed 2,000 specialized chips from <a href=\"https://www.newsweek.com/nvidia-cosmos-ai-chatgpt-moment-robotics-2010961\">Nvidia to train</a> its V3. This is in comparison to a reported 16,000 or more required to train leading models, according to <em>The New York Times</em>.</p>\n</blockquote>\n<p>So, if you're going to try to stop someone from working on AI, you have to have a lot of power over them.</p>",
        "id": 496430587,
        "sender_full_name": "John Baez",
        "timestamp": 1738101124
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276363\">Amar Hadzihasanovic</span> <a href=\"#narrow/channel/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies/near/496405038\">said</a>:</p>\n<blockquote>\n<p>To a certain extent a lot of this seems like a re-edition of Italian futurism, it stems from a pre-rational excitement with new technology and wish to be a \"person of the new century\" and not one of those left behind. As in the case of futurists largely embracing fascism, though, this often goes hand in hand with an ethos of \"adapt or die\" that's easy to exploit for reactionaries (who will choose who exactly is \"standing in the way of progress\").</p>\n</blockquote>\n<p>I <em>love</em> this comparison!</p>",
        "id": 496720909,
        "sender_full_name": "Matteo Capucci (he/him)",
        "timestamp": 1738226780
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276363\">Amar Hadzihasanovic</span> <a href=\"#narrow/channel/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies/near/496408959\">said</a>:</p>\n<blockquote>\n<p>and also makes me doubt that he would genuinely embrace some form of sci-fi-utopianism</p>\n</blockquote>\n<p>judging his personal intent here is completely irrelevant. i don't think we should extend goodwill and fall into the plausible deniability trap. the far right understands this very well, and actively exploits the inability of \"nicer\" actors to take a decisive stance. see the more extreme example of elon's fascist salutes.</p>\n<p>if anyone, by their actions, actively promotes effective accelerationism, we should take them at face value. even <em>if</em> they were doing it solely because they're fascinated with the aesthetics, they need to understand that what they're putting out there is a problem and be called out for it.</p>",
        "id": 496746477,
        "sender_full_name": "Josselin Poiret",
        "timestamp": 1738234556
    },
    {
        "content": "<p>i keep far right propaganda, either IRL or on social media, that uses aesthetics as the primary hook, and that avoids mentioning any political stances they might have. this definitely works very well, and lots of people end up being radicalized in this way.</p>",
        "id": 496747242,
        "sender_full_name": "Josselin Poiret",
        "timestamp": 1738234781
    },
    {
        "content": "<p>I think it is both interesting and very relevant wrt political action to be curious about people's motivation. The far right e.g. has historically succeeded by building heterogeneous coalitions whose actors often had incompatible motivations, and to dismantle these coalitions, it may be necessary to target different actors with different strategies.</p>",
        "id": 496764495,
        "sender_full_name": "Amar Hadzihasanovic",
        "timestamp": 1738240273
    },
    {
        "content": "<p>The example of Elon's salute is relevant, as, I believe, is part of a trollish right-wing culture which has made itself impermeable to being \"called out\" (winding up their political enemies is one of the things it craves), so that's not going to work out, unlike it would, e.g., with a more traditional far-right politician who has tried to style themselves as \"respectable\" and \"reassuring\".</p>",
        "id": 496765929,
        "sender_full_name": "Amar Hadzihasanovic",
        "timestamp": 1738240650
    }
]