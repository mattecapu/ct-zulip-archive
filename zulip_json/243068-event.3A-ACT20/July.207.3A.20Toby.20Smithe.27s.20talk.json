[
    {
        "content": "<p>Hello all! This is the thread of discussion for the talk of Toby St. Clere Smithe, \"Cyber Kittens, or First Steps Towards Categorical Cybernetics\".<br>\nDate and time: Tuesday July 7, 16:00 UTC.<br>\nZoom meeting: <a href=\"https://mit.zoom.us/j/7055345747\">https://mit.zoom.us/j/7055345747</a><br>\nYouTube live stream: <a href=\"https://www.youtube.com/watch?v=Is5mWZcCVf0&amp;list=PLCOXjXDLt3pZDHGYOIqtg1m1lLOURjl1Q\">https://www.youtube.com/watch?v=Is5mWZcCVf0&amp;list=PLCOXjXDLt3pZDHGYOIqtg1m1lLOURjl1Q</a></p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"Is5mWZcCVf0\" href=\"https://www.youtube.com/watch?v=Is5mWZcCVf0&amp;list=PLCOXjXDLt3pZDHGYOIqtg1m1lLOURjl1Q\"><img src=\"https://i.ytimg.com/vi/Is5mWZcCVf0/default.jpg\"></a></div>",
        "id": 202644315,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1593656530
    },
    {
        "content": "<p>Slides for my talk later: <a href=\"/user_uploads/21317/Vpm_AWjwkOyZMZLXjUHX1j9R/cyberkittens-act-2020.pdf\">cyberkittens-act-2020.pdf</a></p>",
        "id": 203116876,
        "sender_full_name": "Toby Smithe",
        "timestamp": 1594135308
    },
    {
        "content": "<p>We start in 30 minutes!</p>",
        "id": 203118158,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1594135802
    },
    {
        "content": "<p>(In case anyone is interested: the idea commented during the talk of \"inflating diagrams\" actually goes back to Bartlett, Douglas, Schommer-Pries, Vicary (where they do it with an embedding to R3 of the presentation) here: <a href=\"https://arxiv.org/abs/1509.06811\">https://arxiv.org/abs/1509.06811</a> Although they only appear on that slide, so this is probably not important here.)</p>\n<p>A question on the slides: are the vertical wires to be understood as cups/caps?</p>",
        "id": 203129684,
        "sender_full_name": "Mario Román",
        "timestamp": 1594140951
    },
    {
        "content": "<p>Hey Mario, can you refer to a particular diagram? I have lots of vertical wires!</p>",
        "id": 203130136,
        "sender_full_name": "Toby Smithe",
        "timestamp": 1594141171
    },
    {
        "content": "<p>I think it is slide 38</p>\n<p>(Oh, I think that has to be the monoidal product and the direction of the wires tells you everything else, right?)</p>",
        "id": 203130303,
        "sender_full_name": "Mario Román",
        "timestamp": 1594141242
    },
    {
        "content": "<p>Yes, you're right there (I think), which is why I had to put flèches on all my wires  :)</p>",
        "id": 203130685,
        "sender_full_name": "Toby Smithe",
        "timestamp": 1594141438
    },
    {
        "content": "<p>Yeah, the plain \"dot\" should have had an <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo>⊗</mo></mrow><annotation encoding=\"application/x-tex\">\\otimes</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.66666em;vertical-align:-0.08333em;\"></span><span class=\"mord\">⊗</span></span></span></span> in it, probably</p>",
        "id": 203130798,
        "sender_full_name": "Toby Smithe",
        "timestamp": 1594141476
    },
    {
        "content": "<p>Here's the video!<br>\n<a href=\"https://www.youtube.com/watch?v=y82hKxDeT6w&amp;list=PLCOXjXDLt3pYot9VNdLlZqGajHyZUywdI\">https://www.youtube.com/watch?v=y82hKxDeT6w&amp;list=PLCOXjXDLt3pYot9VNdLlZqGajHyZUywdI</a></p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"y82hKxDeT6w\" href=\"https://www.youtube.com/watch?v=y82hKxDeT6w&amp;list=PLCOXjXDLt3pYot9VNdLlZqGajHyZUywdI\"><img src=\"https://i.ytimg.com/vi/y82hKxDeT6w/default.jpg\"></a></div>",
        "id": 203205485,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1594157294
    },
    {
        "content": "<p>The examples with active inference and variational autoencoders are tantalizing.  What's the vision here?  Scaling up the complexity of active inference agents?</p>",
        "id": 203221368,
        "sender_full_name": "Van Bettauer",
        "timestamp": 1594170346
    },
    {
        "content": "<p>Hey <span class=\"user-mention\" data-user-id=\"319044\">@Van Bettauer</span>, I missed your question, sorry! There are, in the way of these things, many visions here. One of them is certainly trying to understand how complicated agents can be made up out of simple parts (like \"canonical circuits\" in the cortex). Another vision is simply to understand what it means to be a self-sustaining system embedded in a world, and how such systems can come together to form meta-self-sustaining systems (like corporations). Maybe both of these are just what you meant by \"scaling up the complexity\". But I think of it the other way around: rather than \"scaling up complexity\", I'm interested in \"reducing complexity\", from big hard-to-understand systems, to smaller bits that I <em>can</em> understand. As we saw in <span class=\"user-mention\" data-user-id=\"275901\">@Jules Hedges</span>'s talk (and elsewhere), there can be non-compositional \"emergent effects\". But this kind of compositional approach at least alerts us to their existence, so we can try to subject them to precise analysis, as well.</p>\n<p>Another vision, more distant, perhaps: maybe one day, by understand what it means to be a self-sustaining system, we'll be able to build a more \"self-sustaining\" society.</p>",
        "id": 203304427,
        "sender_full_name": "Toby Smithe",
        "timestamp": 1594232951
    }
]