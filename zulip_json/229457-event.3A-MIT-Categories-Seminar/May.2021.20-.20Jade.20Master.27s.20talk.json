[
    {
        "content": "<p>Hello all, <br>\nHere's the official thread of Jade's talk, \"The open algebraic path problem\".</p>",
        "id": 198267280,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1590015086
    },
    {
        "content": "<p>Youtube live: <a href=\"https://youtu.be/XMAl15VHMpg\">https://youtu.be/XMAl15VHMpg</a></p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"XMAl15VHMpg\" href=\"https://youtu.be/XMAl15VHMpg\"><img src=\"https://i.ytimg.com/vi/XMAl15VHMpg/default.jpg\"></a></div>",
        "id": 198267286,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1590015095
    },
    {
        "content": "<p>Zoom meeting: <a href=\"https://mit.zoom.us/j/280120646\">https://mit.zoom.us/j/280120646</a><br>\nMeeting ID: 280 120 646</p>",
        "id": 198267349,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1590015134
    },
    {
        "content": "<p>Hello all! In 5 minutes we start.</p>",
        "id": 198338108,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1590076507
    },
    {
        "content": "<p>30 seconds!</p>",
        "id": 198338781,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1590076802
    },
    {
        "content": "<p>question: could we think of the last idea about partitioning as a principled way to interpolate between Dijkstra and FloydWarshall?  (Repeated use of) the former is good for solving the same problem as F.W. for very sparse graphs (~ those with favorable partitionings?!)</p>",
        "id": 198343481,
        "sender_full_name": "Sam Tenka",
        "timestamp": 1590078763
    },
    {
        "content": "<p>So, I know approximately nothing about tropical geometry, but I know the rig you mentioned for weighted graphs comes up.  Is there some algebro-geometric way of interpreting what you're doing?</p>",
        "id": 198344258,
        "sender_full_name": "Brian Pinsky",
        "timestamp": 1590079120
    },
    {
        "content": "<p>My computer's audio is having trouble so it looks like I can't join breakout rooms (in case someone is wondering what happened to me).  This was a really nice talk.  Thanks Jade</p>",
        "id": 198345961,
        "sender_full_name": "Brian Pinsky",
        "timestamp": 1590079891
    },
    {
        "content": "<p>Brian, enriching in [0,\\infty ] with \\ge is precisely Lawvere's generalized metric spaces. Then Jade's construction is the free (Lawvere) metric space construction. If that count as geometric intuition....</p>",
        "id": 198346366,
        "sender_full_name": "Ittay Weiss",
        "timestamp": 1590080084
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"281272\">Sam Tenka</span> <a href=\"#narrow/stream/229457-MIT-Categories.20Seminar/topic/May.2021.3A.20Jade.20Master's.20talk/near/198343481\">said</a>:</p>\n<blockquote>\n<p>question: could we think of the last idea about partitioning as a principled way to interpolate between Dijkstra and FloydWarshall?  (Repeated use of) the former is good for solving the same problem as F.W. for very sparse graphs (~ those with favorable partitionings?!)</p>\n</blockquote>\n<p>Thinking about this a bit more. It seems like the Floyd-Warshall algorithm computes shortest paths by enlarging your graph one vertex at a time. I.e. it produces a sequence of graphs</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>G</mi><mn>1</mn></msub><mo>↪</mo><msub><mi>G</mi><mn>2</mn></msub><mo>↪</mo><msub><mi>G</mi><mn>3</mn></msub><mo>…</mo></mrow><annotation encoding=\"application/x-tex\"> G_1 \\hookrightarrow G_2 \\hookrightarrow G_3 \\ldots </annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">G</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">↪</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">G</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">↪</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">G</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">…</span></span></span></span></p>\n<p>where each graph in the sequence has one vertex more.  Each time you enlarge the graph, you can use pushouts to compute the updated solution to the algebraic path problem. Djikstra's algorithm on the other hand, only computes the shortest distances from a given starting node. I think that this corresponds to a similar sequence of graphs, except now these graphs are matrices whose first dimension is 1. The solution to the algebraic path problem on this sequence of graphs could also be computed using pushouts in a similar way.</p>\n<p>So yes, I do think that this strategy could interpolatea between Dijkstra and Floyd--Warshall. Really any enlargement of your graph is allowed.</p>",
        "id": 198346777,
        "sender_full_name": "Jade Master",
        "timestamp": 1590080264
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"281268\">Brian Pinsky</span> <a href=\"#narrow/stream/229457-MIT-Categories.20Seminar/topic/May.2021.3A.20Jade.20Master's.20talk/near/198344258\">said</a>:</p>\n<blockquote>\n<p>So, I know approximately nothing about tropical geometry, but I know the rig you mentioned for weighted graphs comes up.  Is there some algebro-geometric way of interpreting what you're doing?</p>\n</blockquote>\n<p>Maybe! I'm really not sure but I would love to find out :)</p>",
        "id": 198346987,
        "sender_full_name": "Jade Master",
        "timestamp": 1590080366
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"304223\">Ittay Weiss</span> <a href=\"#narrow/stream/229457-MIT-Categories.20Seminar/topic/May.2021.3A.20Jade.20Master's.20talk/near/198346366\">said</a>:</p>\n<blockquote>\n<p>Brian, enriching in [0,\\infty ] with \\ge is precisely Lawvere's generalized metric spaces. Then Jade's construction is the free (Lawvere) metric space construction. If that count as geometric intuition....</p>\n</blockquote>\n<p>Right that's another connection. By the way, the free forgetful adjunction for enriched categories in general is constructed in this paper: <a href=\"https://www.sciencedirect.com/science/article/pii/0022404974900188\">https://www.sciencedirect.com/science/article/pii/0022404974900188</a></p>",
        "id": 198347277,
        "sender_full_name": "Jade Master",
        "timestamp": 1590080496
    },
    {
        "content": "<p>There's some lovely work on the open automata case in a note by Walters, Sabadini, and Rosebrugh: <a href=\"https://arxiv.org/abs/0712.2525\">https://arxiv.org/abs/0712.2525</a>. Simon Cho and I have been working on expanding it out more thoroughly from a bicategorical and decorated/structured cospans perspective. It fits very nicely with what you're doing Jade</p>",
        "id": 198349021,
        "sender_full_name": "Brendan Fong",
        "timestamp": 1590081284
    },
    {
        "content": "<p>Also I'm very curious about the problem of finding good decompositions, which seems to me to be at the heart of a number of algorithms (at least in the max flow case that I've looked into most). As Sam suggests, many seem to start with an assumption about what sort of decomposition is natural for the graph at hand, and then take advantage of the compositional structure as much as possible. But they're rarely phrased explicitly in this language</p>",
        "id": 198349413,
        "sender_full_name": "Brendan Fong",
        "timestamp": 1590081477
    },
    {
        "content": "<p>I confess I don't understand the \"expanding your graph\" interpretation of Floyd-Warshall. I think of it more as \"taking a further step along 'all paths' in your graph, one step at a time\".</p>\n<p>It is also not clear to me if Dijkstra's algorithm is as general -- i.e. can it be used in all settings with a quantale-valuation to get equivalent results to Floyd-Warshall or does it take more advantage of some special features present in just the standard setting? (I think it may actually be equally general, I just haven't worked it out for sure).</p>",
        "id": 198350559,
        "sender_full_name": "Gershom",
        "timestamp": 1590082035
    },
    {
        "content": "<p>In general, I think the problem of \"finding a good decomposition\" tends to be as hard as the problem you're trying to solve in the first place. A nice, simple, example of this is the problem of picking a pivot in quicksort. You can get better results under assumptions like \"when most decompositions are good\", or often you work to pick a decomposition that is \"on average not terrible\" to defeat malicious data sets.</p>",
        "id": 198351214,
        "sender_full_name": "Gershom",
        "timestamp": 1590082323
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276053\">Brendan Fong</span> <a href=\"#narrow/stream/229457-MIT-Categories.20Seminar/topic/May.2021.3A.20Jade.20Master's.20talk/near/198349021\">said</a>:</p>\n<blockquote>\n<p>There's some lovely work on the open automata case in a note by Walters, Sabadini, and Rosebrugh: <a href=\"https://arxiv.org/abs/0712.2525\">https://arxiv.org/abs/0712.2525</a>. Simon Cho and I have been working on expanding it out more thoroughly from a bicategorical and decorated/structured cospans perspective. It fits very nicely with what you're doing Jade</p>\n</blockquote>\n<p>Yay. I'm glad. This paper also looks really great.</p>\n<p><span class=\"user-mention silent\" data-user-id=\"276053\">Brendan Fong</span> <a href=\"#narrow/stream/229457-MIT-Categories.20Seminar/topic/May.2021.3A.20Jade.20Master's.20talk/near/198349413\">said</a>:</p>\n<blockquote>\n<p>Also I'm very curious about the problem of finding good decompositions, which seems to me to be at the heart of a number of algorithms (at least in the max flow case that I've looked into most). As Sam suggests, many seem to start with an assumption about what sort of decomposition is natural for the graph at hand, and then take advantage of the compositional structure as much as possible. But they're rarely phrased explicitly in this language</p>\n</blockquote>\n<p>Agreed. This part usually involves a good deal of cleverness it seems. It would be good to get mathematical tools which measure how \"good\" a given cut is.</p>",
        "id": 198351455,
        "sender_full_name": "Jade Master",
        "timestamp": 1590082444
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276650\">Gershom</span> <a href=\"#narrow/stream/229457-MIT-Categories.20Seminar/topic/May.2021.3A.20Jade.20Master's.20talk/near/198350559\">said</a>:</p>\n<blockquote>\n<p>I confess I don't understand the \"expanding your graph\" interpretation of Floyd-Warshall. I think of it more as \"taking a further step along 'all paths' in your graph, one step at a time\".</p>\n<p>It is also not clear to me if Dijkstra's algorithm is as general -- i.e. can it be used in all settings with a quantale-valuation to get equivalent results to Floyd-Warshall or does it take more advantage of some special features present in just the standard setting? (I think it may actually be equally general, I just haven't worked it out for sure).</p>\n</blockquote>\n<p>The sequence of graphs I am thinking of adds one vertex and all edges connecting that vertex to the already existing nodes in each step. Whenever you add another node and the edges attached to it, then you need to minimize again. This minimization can be thought of as the pushout of the smaller graph, and the graph with the new node and all of it's adjacent nodes.</p>",
        "id": 198352134,
        "sender_full_name": "Jade Master",
        "timestamp": 1590082790
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276650\">Gershom</span> <a href=\"#narrow/stream/229457-MIT-Categories.20Seminar/topic/May.2021.3A.20Jade.20Master's.20talk/near/198351214\">said</a>:</p>\n<blockquote>\n<p>In general, I think the problem of \"finding a good decomposition\" tends to be as hard as the problem you're trying to solve in the first place. A nice, simple, example of this is the problem of picking a pivot in quicksort. You can get better results under assumptions like \"when most decompositions are good\", or often you work to pick a decomposition that is \"on average not terrible\" to defeat malicious data sets.</p>\n</blockquote>\n<p>I tend to agree. Finding good decompositions is about finding subgraphs which \"compose well\"</p>",
        "id": 198352350,
        "sender_full_name": "Jade Master",
        "timestamp": 1590082915
    },
    {
        "content": "<p>Did my explanation of the expanding graphs for the Floyd-Warshall algorithm make sense? It might be hard to see the picture...</p>",
        "id": 198352574,
        "sender_full_name": "Jade Master",
        "timestamp": 1590083028
    },
    {
        "content": "<p>I haven't carefully checked, but I think Dijkstra works for any commutative quantale.  Someone should take <a href=\"https://en.wikipedia.org/wiki/Shortest_path_problem#Algorithms\">a bunch of shortest path algorithms</a>, starting with Dijkstra and Floyd-Warshall, try to generalize them to commutative quantales, <em>and</em> put them into a nice categorical framework.  The last step might let one create new algorithms.  I think the best opportunity for new algorithms is in solving problems with partial data, changing data, etc.</p>",
        "id": 198355341,
        "sender_full_name": "John Baez",
        "timestamp": 1590084363
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276037\">Jade Master</span> <a href=\"#narrow/stream/229457-MIT-Categories.20Seminar/topic/May.2021.3A.20Jade.20Master's.20talk/near/198352134\">said</a>:</p>\n<blockquote>\n<p>The sequence of graphs I am thinking of adds one vertex and all edges connecting that vertex to the already existing nodes in each step. Whenever you add another node and the edges attached to it, then you need to minimize again. This minimization can be thought of as the pushout of the smaller graph, and the graph with the new node and all of it's adjacent nodes.</p>\n</blockquote>\n<p>This description seems to be what happens in the tightest inner loop -- how one updates a single cell with regards to a single extension of a path. The trick to Floyd-Warshall (and so what I would think of as its \"heart\") is at a bit of a higher level, I think. In particular, it takes advantage of a fair number of operations re-associating and commuting so that one can extend fewer times than one might naively imagine. This is the dynamic programming aspect -- taking advantage of \"common subexpressions\" in the naive formula in a structured way.</p>",
        "id": 198358576,
        "sender_full_name": "Gershom",
        "timestamp": 1590086032
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276650\">Gershom</span> <a href=\"#narrow/stream/229457-MIT-Categories.20Seminar/topic/May.2021.3A.20Jade.20Master's.20talk/near/198358576\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"276037\">Jade Master</span> <a href=\"#narrow/stream/229457-MIT-Categories.20Seminar/topic/May.2021.3A.20Jade.20Master's.20talk/near/198352134\">said</a>:</p>\n<blockquote>\n<p>The sequence of graphs I am thinking of adds one vertex and all edges connecting that vertex to the already existing nodes in each step. Whenever you add another node and the edges attached to it, then you need to minimize again. This minimization can be thought of as the pushout of the smaller graph, and the graph with the new node and all of it's adjacent nodes.</p>\n</blockquote>\n<p>This description seems to be what happens in the tightest inner loop -- how one updates a single cell with regards to a single extension of a path. The trick to Floyd-Warshall (and so what I would think of as its \"heart\") is at a bit of a higher level, I think. In particular, it takes advantage of a fair number of operations re-associating and commuting so that one can extend fewer times than one might naively imagine. This is the dynamic programming aspect -- taking advantage of \"common subexpressions\" in the naive formula in a structured way.</p>\n</blockquote>\n<p>Right. The nice observation of Floyd-Warshall is that in the case when you're adding just one more node,  computation of the corresponding pushout takes the nice form that you are describing.</p>",
        "id": 198361174,
        "sender_full_name": "Jade Master",
        "timestamp": 1590087353
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"275920\">John Baez</span> <a href=\"#narrow/stream/229457-MIT-Categories.20Seminar/topic/May.2021.3A.20Jade.20Master's.20talk/near/198355341\">said</a>:</p>\n<blockquote>\n<p>I haven't carefully checked, but I think Dijkstra works for any commutative quantale.  Someone should take <a href=\"https://en.wikipedia.org/wiki/Shortest_path_problem#Algorithms\">a bunch of shortest path algorithms</a>, starting with Dijkstra and Floyd-Warshall, try to generalize them to commutative quantales, <em>and</em> put them into a nice categorical framework.  The last step might let one create new algorithms.  I think the best opportunity for new algorithms is in solving problems with partial data, changing data, etc.</p>\n</blockquote>\n<p>One restriction that's important to consider is that Dijkstra's algorithm does not work on graphs with negative weights. Floyd-Warshall does, and furthermore can be used to detect \"negative cycles\" as well.</p>",
        "id": 198361542,
        "sender_full_name": "Gershom",
        "timestamp": 1590087525
    },
    {
        "content": "<p>Anyone interested in general versions of Floyd-Warshall should look at Dioids and *-semirings in general.  Russell O'Connor wrote a nice blog post (in Haskell) explaining why: <a href=\"http://r6.ca/blog/20110808T035622Z.html\">http://r6.ca/blog/20110808T035622Z.html</a></p>",
        "id": 198362684,
        "sender_full_name": "Jacques Carette",
        "timestamp": 1590088058
    },
    {
        "content": "<p>Warshall's algorithm starts with all the one-step paths.<br>\nThen for the first vertex it adds all paths that start anywhere, end anywhere, and have only the first vertex as intermediate place.<br>\nThen for thesecond vertex it adds all paths that start anywhere, end anywhere, and have only the first two vertices as intermediate places.<br>\netc., until it has all paths that start anywhere, end anywhere, and have any vertices as intermediate places.</p>\n<p>It can be coded like an in-place matrix multiply, with the matrix being multiplied by itself while it is being modified by placing the resulting elements in itself too, but you have to be very careful of the proper nesting of the three loops.  The one iterating through the intermediate vertices has to be the outer loop.  In the form A_ij times A_jk (summed over j) the j loop is the outer one.</p>\n<p>-- hendrik</p>",
        "id": 198366920,
        "sender_full_name": "Hendrik Boom",
        "timestamp": 1590090224
    },
    {
        "content": "<p>Hey all, here's the permanent video:<br>\n<a href=\"https://youtu.be/04azeAGbn9U\">https://youtu.be/04azeAGbn9U</a><br>\nThe HD version should be ready soon, at the same link.</p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"04azeAGbn9U\" href=\"https://youtu.be/04azeAGbn9U\"><img src=\"https://i.ytimg.com/vi/04azeAGbn9U/default.jpg\"></a></div>",
        "id": 198380555,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1590097135
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"296322\">Jacques Carette</span> <a href=\"#narrow/stream/229457-MIT-Categories.20Seminar/topic/May.2021.20-.20Jade.20Master's.20talk/near/198362684\">said</a>:</p>\n<blockquote>\n<p>Anyone interested in general versions of Floyd-Warshall should look at Dioids and *-semirings in general.  Russell O'Connor wrote a nice blog post (in Haskell) explaining why: <a href=\"http://r6.ca/blog/20110808T035622Z.html\">http://r6.ca/blog/20110808T035622Z.html</a></p>\n</blockquote>\n<p>Related to Floyd-Warshall and petri nets is this paper from '08 \"Petri Nets are Dioids\" <a href=\"https://www.semanticscholar.org/paper/Petri-Nets-Are-Dioids-Baldan-Gadducci/f22418833902f4fb5c80cabae2934150ccb52451\">https://www.semanticscholar.org/paper/Petri-Nets-Are-Dioids-Baldan-Gadducci/f22418833902f4fb5c80cabae2934150ccb52451</a></p>",
        "id": 198408942,
        "sender_full_name": "Gershom",
        "timestamp": 1590127994
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276650\">Gershom</span> <a href=\"#narrow/stream/229457-MIT-Categories.20Seminar/topic/May.2021.20-.20Jade.20Master's.20talk/near/198361542\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"275920\">John Baez</span> <a href=\"#narrow/stream/229457-MIT-Categories.20Seminar/topic/May.2021.3A.20Jade.20Master's.20talk/near/198355341\">said</a>:</p>\n<blockquote>\n<p>I haven't carefully checked, but I think Dijkstra works for any commutative quantale.  Someone should take <a href=\"https://en.wikipedia.org/wiki/Shortest_path_problem#Algorithms\">a bunch of shortest path algorithms</a>, starting with Dijkstra and Floyd-Warshall, try to generalize them to commutative quantales, <em>and</em> put them into a nice categorical framework.  The last step might let one create new algorithms.  I think the best opportunity for new algorithms is in solving problems with partial data, changing data, etc.</p>\n</blockquote>\n<p>One restriction that's important to consider is that Dijkstra's algorithm does not work on graphs with negative weights. Floyd-Warshall does, and furthermore can be used to detect \"negative cycles\" as well.</p>\n</blockquote>\n<p>Right. If I recall correctly, there are rigs you can choose so that graphs valued in it can have negative weights...but the transistive closure doesn't always exist.</p>",
        "id": 198483968,
        "sender_full_name": "Jade Master",
        "timestamp": 1590175391
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276650\">Gershom</span> <a href=\"#narrow/stream/229457-MIT-Categories.20Seminar/topic/May.2021.20-.20Jade.20Master's.20talk/near/198408942\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"296322\">Jacques Carette</span> <a href=\"#narrow/stream/229457-MIT-Categories.20Seminar/topic/May.2021.20-.20Jade.20Master's.20talk/near/198362684\">said</a>:</p>\n<blockquote>\n<p>Anyone interested in general versions of Floyd-Warshall should look at Dioids and *-semirings in general.  Russell O'Connor wrote a nice blog post (in Haskell) explaining why: <a href=\"http://r6.ca/blog/20110808T035622Z.html\">http://r6.ca/blog/20110808T035622Z.html</a></p>\n</blockquote>\n<p>Related to Floyd-Warshall and petri nets is this paper from '08 \"Petri Nets are Dioids\" <a href=\"https://www.semanticscholar.org/paper/Petri-Nets-Are-Dioids-Baldan-Gadducci/f22418833902f4fb5c80cabae2934150ccb52451\">https://www.semanticscholar.org/paper/Petri-Nets-Are-Dioids-Baldan-Gadducci/f22418833902f4fb5c80cabae2934150ccb52451</a></p>\n</blockquote>\n<p>Ah thanks so much. This seems like a very relevant and useful connection.</p>",
        "id": 198484038,
        "sender_full_name": "Jade Master",
        "timestamp": 1590175435
    },
    {
        "content": "<p>[Quoting…]<br>\nWhat do you think goes wrong?</p>",
        "id": 198484116,
        "sender_full_name": "Jade Master",
        "timestamp": 1590175461
    },
    {
        "content": "<p>I think it's good to ignore negative weights if one is trying to get a good theory along the lines of Jade's.  In a world where one can run around the block and go -3 miles, shortest path problems are gonna be weird!</p>",
        "id": 198484166,
        "sender_full_name": "John Baez",
        "timestamp": 1590175491
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"299803\">Hendrik Boom</span> <a href=\"#narrow/stream/229457-MIT-Categories.20Seminar/topic/May.2021.20-.20Jade.20Master's.20talk/near/198366920\">said</a>:</p>\n<blockquote>\n<p>Warshall's algorithm starts with all the one-step paths.<br>\nThen for the first vertex it adds all paths that start anywhere, end anywhere, and have only the first vertex as intermediate place.<br>\nThen for thesecond vertex it adds all paths that start anywhere, end anywhere, and have only the first two vertices as intermediate places.<br>\netc., until it has all paths that start anywhere, end anywhere, and have any vertices as intermediate places.</p>\n<p>It can be coded like an in-place matrix multiply, with the matrix being multiplied by itself while it is being modified by placing the resulting elements in itself too, but you have to be very careful of the proper nesting of the three loops.  The one iterating through the intermediate vertices has to be the outer loop.  In the form A_ij times A_jk (summed over j) the j loop is the outer one.</p>\n<p>-- hendrik</p>\n</blockquote>\n<p>Thanks Hendrik. You mean that the outermost loop has to be the one which adds new vertices which are allowed to be intermediate steps?</p>",
        "id": 198484371,
        "sender_full_name": "Jade Master",
        "timestamp": 1590175606
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"275920\">John Baez</span> <a href=\"#narrow/stream/229457-MIT-Categories.20Seminar/topic/May.2021.20-.20Jade.20Master's.20talk/near/198484166\">said</a>:</p>\n<blockquote>\n<p>I think it's good to ignore negative weights if one is trying to get a good theory along the lines of Jade's.  In a world where one can run around the block and go -3 miles, shortest path problems are gonna be weird!</p>\n</blockquote>\n<p>Right. Suppose your graph has a loop consisting entirely of negative weights. Let <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>M</mi></mrow><annotation encoding=\"application/x-tex\">M</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span></span></span></span> be the the matrix representing your graph. Then the sum <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mo>∑</mo><mrow><mi>n</mi><mo>≥</mo><mn>0</mn></mrow></msub><msup><mi>M</mi><mi>n</mi></msup></mrow><annotation encoding=\"application/x-tex\">\\sum_{n\\geq 0} M^n</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:1.144889em;vertical-align:-0.39488900000000005em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139799999999992em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">n</span><span class=\"mrel mtight\">≥</span><span class=\"mord mtight\">0</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.39488900000000005em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.664392em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">n</span></span></span></span></span></span></span></span></span></span></span> won't converge. Every time you multiply the matrix by itself (using min and +), the values between two points in your loop will get more negative.</p>",
        "id": 198488572,
        "sender_full_name": "Jade Master",
        "timestamp": 1590177728
    },
    {
        "content": "<p>Right, so I think you should feel completely free to ignore commutative rigs that aren't commutative quantales, when you're developing your vision here.</p>",
        "id": 198488846,
        "sender_full_name": "John Baez",
        "timestamp": 1590177930
    },
    {
        "content": "<blockquote>\n<p>Thanks Hendrik. You mean that the outermost loop has to be the one which adds new vertices which are allowed to be intermediate steps?</p>\n</blockquote>\n<p>Yes, exactly.</p>",
        "id": 198598510,
        "sender_full_name": "Hendrik Boom",
        "timestamp": 1590351853
    },
    {
        "content": "<p>Btw I have made a major update to this paper: <a href=\"https://arxiv.org/abs/2005.06682\">https://arxiv.org/abs/2005.06682</a><br>\nThe main changes are that I improved a lot of the exposition, and there is a new section on <em>functional</em> open matrices. Functional open matrices are a subclass of open matrices for which the theory developed here, in my opinion, has some more practical implications.</p>",
        "id": 224278347,
        "sender_full_name": "Jade Master",
        "timestamp": 1611801796
    },
    {
        "content": "<p>Namely there are two relevant facts. </p>\n<ol>\n<li>If F is the functor which sends a matrix to the solution of its algebraic path problem, then for functional open matrices <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>M</mi><mo>:</mo><mi>X</mi><mo>→</mo><mi>Y</mi></mrow><annotation encoding=\"application/x-tex\">M: X \\to Y</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span></span></span></span> and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi><mo>:</mo><mi>Y</mi><mo>→</mo><mi>Z</mi></mrow><annotation encoding=\"application/x-tex\">N : Y \\to Z</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">Z</span></span></span></span>, <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>F</mi><mo stretchy=\"false\">(</mo><mi>M</mi><mo>∘</mo><mi>N</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">F(M \\circ N)</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∘</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mclose\">)</span></span></span></span> can be computed as the matrix product <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>F</mi><mo stretchy=\"false\">(</mo><mi>M</mi><mo stretchy=\"false\">)</mo><mi>F</mi><mo stretchy=\"false\">(</mo><mi>N</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">F(M)F(N)</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"mclose\">)</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mclose\">)</span></span></span></span>.</li>\n</ol>",
        "id": 224278451,
        "sender_full_name": "Jade Master",
        "timestamp": 1611801961
    },
    {
        "content": "<ol start=\"2\">\n<li>The solution to the algebraic path problem for a composite of functional open matrices <em>which occurs in exactly n-steps</em> can be computed using a sort of binomial theorem: <a href=\"/user_uploads/21317/kRdoDBgYrG0ewgifXnb2-A-2/Screenshot-from-2021-01-27-18-47-48.png\">Screenshot-from-2021-01-27-18-47-48.png</a><div class=\"message_inline_image\"><a href=\"/user_uploads/21317/kRdoDBgYrG0ewgifXnb2-A-2/Screenshot-from-2021-01-27-18-47-48.png\" title=\"Screenshot-from-2021-01-27-18-47-48.png\"><img src=\"/user_uploads/21317/kRdoDBgYrG0ewgifXnb2-A-2/Screenshot-from-2021-01-27-18-47-48.png\"></a></div></li>\n</ol>",
        "id": 224278594,
        "sender_full_name": "Jade Master",
        "timestamp": 1611802178
    },
    {
        "content": "<p>This equation says that on the composite of functional open matrices M and N, the solution of the algebraic path problem which is restricted to the boundary and occurs in exactly n-steps is computed by summing over i+j=n the contributions from M which occur in i steps with the product of the contribution from N which occurs in j steps.</p>",
        "id": 224278754,
        "sender_full_name": "Jade Master",
        "timestamp": 1611802339
    },
    {
        "content": "<p>If this doesn't make sense maybe it will help to know that for a matrix <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>M</mi></mrow><annotation encoding=\"application/x-tex\">M</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span></span></span></span>, the minimum paths which occur in n-steps between all vertices is represented by the power <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>M</mi><mi>n</mi></msup></mrow><annotation encoding=\"application/x-tex\">M^n</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.664392em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span></span></span></span></span></span></span>.</p>",
        "id": 224278804,
        "sender_full_name": "Jade Master",
        "timestamp": 1611802430
    },
    {
        "content": "<p>Also you can read the paper for more details but the black box indicates that the open matrix is restricted to its boundary.</p>",
        "id": 224278854,
        "sender_full_name": "Jade Master",
        "timestamp": 1611802459
    },
    {
        "content": "<p>Anyway, I turned the formula above into some code, in the case of markov processes: <a href=\"https://github.com/Jademaster/compositionalmarkov\">https://github.com/Jademaster/compositionalmarkov</a></p>",
        "id": 224278896,
        "sender_full_name": "Jade Master",
        "timestamp": 1611802533
    }
]