[
    {
        "content": "<p>Erik Hoel has a <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hoel,+E\">series of papers</a> with coauthors looking to understand emergence. Seeing the most recent one come out the other day reminded me that I was contemplating a category-theoretic understanding of his approach a while ago. </p>\n<p>Central to his position is the idea of seeing how near we are to situations where a cause necessarily and sufficiently brings about its effect. So Comolatti and Hoel (<a href=\"https://arxiv.org/abs/2202.01854\">Causal emergence is widespread across measures of causation</a>) explore emergence in terms of differences in causal strength (CS) calculated at different levels, where CS is measuring the control one has on effects (E) via causes (C). If this were perfect, there would be an isomorphism <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi><mo>→</mo><mi>E</mi></mrow><annotation encoding=\"application/x-tex\">C \\to E</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span></span></span></span>.</p>\n<p>In general, the process is a probabilistic mapping, a matrix with non-negative entries, each row summing to <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>1.</mn></mrow><annotation encoding=\"application/x-tex\">1.</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">1.</span></span></span></span> A cause is sufficient for an effect if <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>e</mi><mi mathvariant=\"normal\">∣</mi><mi>c</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">P(e|c) = 1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">e</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\">c</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">1</span></span></span></span>, and necessary if <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>e</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">¬</mi><mi>c</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">P(e|\\neg c) = 0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">e</span><span class=\"mord\">∣¬</span><span class=\"mord mathnormal\">c</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0</span></span></span></span>. Departures over the set of causes and effects correspond to indeterminacy and degeneracy, respectively. A good coarse-graining of a system will display high determinacy and low degeneracy.</p>\n<p>I had thought to tie this to </p>\n<ul>\n<li><span class=\"user-mention\" data-user-id=\"549203\">@Caterina Puca</span>, <span class=\"user-mention\" data-user-id=\"276363\">@Amar Hadzihasanovic</span>, <span class=\"user-mention\" data-user-id=\"679887\">@Fabrizio Romano Genovese</span>,  <span class=\"user-mention\" data-user-id=\"276692\">@Bob Coecke</span>, <a href=\"https://arxiv.org/abs/2307.14461\">Obstructions to Compositionality</a>,</li>\n</ul>\n<p>which looks to provide measures of departure from isomorphism via mono and split epi characteristics. They end with a comment on generalizing beyond <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">S</mi><mi mathvariant=\"bold\">e</mi><mi mathvariant=\"bold\">t</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbf{Set}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6861em;\"></span><span class=\"mord\"><span class=\"mord mathbf\">Set</span></span></span></span></span>:</p>\n<blockquote>\n<p>Most importantly, we hope to have opened a new avenue in “formal compositionality theory”. The greatest challenge will be to graduate from proof-of-concept examples to ones that reveal more interesting structure, perhaps in non-<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">S</mi><mi mathvariant=\"bold\">e</mi><mi mathvariant=\"bold\">t</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbf{Set}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6861em;\"></span><span class=\"mord\"><span class=\"mord mathbf\">Set</span></span></span></span></span>-like categories where a split epi or mono is not simply a surjective or injective map. We have been looking at case studies of this sort, which nevertheless have manageable combinatorics permitting an exhaustive study of their homotopy posets, and we hope to discuss them in future work.</p>\n</blockquote>\n<p>I was thinking then that we might consider departures from isomorphism in the Markov category of finite sets and probability distributions. I think we have that: if each effect has a sufficient cause, then the morphism is a split epi. If each cause is necessary to its effects, then it's mono.</p>\n<p>Does that sound right?</p>",
        "id": 546875992,
        "sender_full_name": "David Corfield",
        "timestamp": 1761306269
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"302507\">David Corfield</span> <a href=\"#narrow/channel/229199-learning.3A-questions/topic/Hoel.20et.20al.20on.20emergence/near/546875992\">said</a>:</p>\n<blockquote>\n<p>I think we have that: if each effect has a sufficient cause, then the morphism is a split epi. If each cause is necessary to its effects, then it's mono.</p>\n</blockquote>\n<p>How does that work? What is a split epi in the Markov category of finite sets and probability distributions [aka <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">F</mi><mi mathvariant=\"bold\">i</mi><mi mathvariant=\"bold\">n</mi><mi mathvariant=\"bold\">S</mi><mi mathvariant=\"bold\">t</mi><mi mathvariant=\"bold\">o</mi><mi mathvariant=\"bold\">c</mi><mi mathvariant=\"bold\">h</mi></mrow><annotation encoding=\"application/x-tex\">\\bf FinStoch</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord\"><span class=\"mord mathbf\">FinStoch</span></span></span></span></span>]?</p>",
        "id": 547041903,
        "sender_full_name": "Matteo Capucci (he/him)",
        "timestamp": 1761383009
    },
    {
        "content": "<p>I think a split epi from <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\">A</span></span></span></span> to <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi></mrow><annotation encoding=\"application/x-tex\">B</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span></span></span></span> should be such that for every <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>b</mi><mo>∈</mo><mi>B</mi></mrow><annotation encoding=\"application/x-tex\">b \\in B</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7335em;vertical-align:-0.0391em;\"></span><span class=\"mord mathnormal\">b</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span></span></span></span> there's an <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>a</mi></mrow><annotation encoding=\"application/x-tex\">a</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">a</span></span></span></span> such that <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>b</mi><mi mathvariant=\"normal\">∣</mi><mi>a</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">P(b|a)=1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">b</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\">a</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">1</span></span></span></span>. Then there's a suitable deterministic map backwards.</p>",
        "id": 547042453,
        "sender_full_name": "David Corfield",
        "timestamp": 1761383462
    },
    {
        "content": "<p>Does something like this crop up in category-theoretic probability theory, where (proximity to) being mono/split epi in a Markov category has the flavour of necessary/sufficient causation? (Hoping the likes of <span class=\"user-mention\" data-user-id=\"276702\">@Tobias Fritz</span>, <span class=\"user-mention\" data-user-id=\"275989\">@Paolo Perrone</span>, <span class=\"user-mention\" data-user-id=\"308397\">@Sam Staton</span> might be able to answer.)</p>",
        "id": 547271911,
        "sender_full_name": "David Corfield",
        "timestamp": 1761570367
    },
    {
        "content": "<p>I don't quite know the 'causation' meaning of what follows, but maybe someone finds it suggestive.</p>\n<ul>\n<li>Most Markov categories of interest for probability are <a href=\"https://ncatlab.org/nlab/show/Markov+category#positivity_and_causality\">positive</a>, which corresponds roughly to the fact that there are no negative probabilities. FinStoch, Stoch and all those are positive.</li>\n<li>In a positive Markov category, if we have a retraction <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo>:</mo><mi>X</mi><mo>→</mo><mi>Y</mi></mrow><annotation encoding=\"application/x-tex\">f:X\\to Y</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span></span></span></span>, <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>g</mi><mo>:</mo><mi>Y</mi><mo>→</mo><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">g:Y\\to X</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span></span></span></span> with <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>g</mi><mo>∘</mo><mi>f</mi><mo>=</mo><msub><mn>1</mn><mi>X</mi></msub></mrow><annotation encoding=\"application/x-tex\">g\\circ f = 1_X</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6389em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">∘</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7944em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3283em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07847em;\">X</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>, then <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>g</mi></mrow><annotation encoding=\"application/x-tex\">g</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span></span></span></span> is <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi></mrow><annotation encoding=\"application/x-tex\">f</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span></span></span></span>-almost surely deterministic. So, in a certain sense, split epis are 'almost' deterministic. </li>\n<li>Concretely, in (say) FinStoch, this means that, up to probability zero:</li>\n<li>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>g</mi></mrow><annotation encoding=\"application/x-tex\">g</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span></span></span></span> is a deterministic function, which partitions <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Y</mi></mrow><annotation encoding=\"application/x-tex\">Y</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span></span></span></span> into 'cells', namely its fibers <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>g</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">g^{-1}(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0641em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span>, indexed by the <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi><mo>∈</mo><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">x\\in X</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span></span></span></span>. </li>\n</ul>\n</li>\n<li>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi></mrow><annotation encoding=\"application/x-tex\">f</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span></span></span></span>, seen as a map from points to distributions, maps each <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi><mo>∈</mo><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">x\\in X</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span></span></span></span> to a probability distribution supported on its fiber <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>g</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">g^{-1}(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0641em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span>.</li>\n</ul>\n</li>\n<li>\n<ul>\n<li>This way, when we apply <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>g</mi></mrow><annotation encoding=\"application/x-tex\">g</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span></span></span></span> after <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi></mrow><annotation encoding=\"application/x-tex\">f</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span></span></span></span>, all the 'mass' goes back to <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span>.</li>\n</ul>\n</li>\n<li>Outside of FinStoch, the same intuition holds but things are a little more involved, a kernel like <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi></mrow><annotation encoding=\"application/x-tex\">f</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span></span></span></span> is sometimes called a <a href=\"https://arxiv.org/pdf/2403.16104#section.3\">proper kernel</a>.</li>\n</ul>\n<p>I don't know how to relate this to causality, but I hope it helps!</p>",
        "id": 547279684,
        "sender_full_name": "Paolo Perrone",
        "timestamp": 1761572542
    },
    {
        "content": "<p>Thanks, Paolo! It seems that many people were after some way of measuring a process as causally efficacious, where the ideal is for a specific effect to be brought about uniquely and deterministically by a specific cause:</p>\n<p><a href=\"/user_uploads/21317/j2AkzXPuPMrbCj39qJBJk4Q6/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/21317/j2AkzXPuPMrbCj39qJBJk4Q6/image.png\" title=\"image.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"621x231\" src=\"/user_uploads/thumbnail/21317/j2AkzXPuPMrbCj39qJBJk4Q6/image.png/840x560.webp\"></a></div><p>(<a href=\"https://arxiv.org/abs/2202.01854\">Causal emergence is widespread across measures of causation</a>, Fig. 1)</p>\n<p>For their version of this measure, the latest Hoel paper (with Jansma), <a href=\"https://arxiv.org/abs/2510.02649\">Engineering Emergence</a>, looks at how it varies under coarse-graining a Markov chain. Greater determinacy and less degeneracy may emerge after coarse-graining from the microscale.</p>",
        "id": 547300174,
        "sender_full_name": "David Corfield",
        "timestamp": 1761577240
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"302507\">David Corfield</span> <a href=\"#narrow/channel/229199-learning.3A-questions/topic/Hoel.20et.20al.20on.20emergence/near/547042453\">said</a>:</p>\n<blockquote>\n<p>I think a split epi from <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\">A</span></span></span></span> to <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi></mrow><annotation encoding=\"application/x-tex\">B</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span></span></span></span> should be such that for every <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>b</mi><mo>∈</mo><mi>B</mi></mrow><annotation encoding=\"application/x-tex\">b \\in B</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7335em;vertical-align:-0.0391em;\"></span><span class=\"mord mathnormal\">b</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span></span></span></span> there's an <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>a</mi></mrow><annotation encoding=\"application/x-tex\">a</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">a</span></span></span></span> such that <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>b</mi><mi mathvariant=\"normal\">∣</mi><mi>a</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">P(b|a)=1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">b</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\">a</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">1</span></span></span></span>. Then there's a suitable deterministic map backwards.</p>\n</blockquote>\n<p>Just to confirm this, yes, those are precisely the split epis. You've already explained why the condition is sufficient, and the fact that it's necessary follows from Paolo's comment on almost sure determinism.</p>\n<p>The split monos are those <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo>:</mo><mi>A</mi><mo>→</mo><mi>B</mi></mrow><annotation encoding=\"application/x-tex\">P : A \\to B</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\">A</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span></span></span></span> for which the distributions <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mo>−</mo><mi mathvariant=\"normal\">∣</mi><mi>a</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">P(-|a)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\">−</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\">a</span><span class=\"mclose\">)</span></span></span></span> have disjoint support as <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>a</mi></mrow><annotation encoding=\"application/x-tex\">a</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">a</span></span></span></span> varies.</p>",
        "id": 547413986,
        "sender_full_name": "Tobias Fritz",
        "timestamp": 1761630012
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"302507\">David Corfield</span> <a href=\"#narrow/channel/229199-learning.3A-questions/topic/Hoel.20et.20al.20on.20emergence/near/546875992\">said</a>:</p>\n<blockquote>\n<p>So Comolatti and Hoel (<a href=\"https://arxiv.org/abs/2202.01854\">Causal emergence is widespread across measures of causation</a>) explore emergence in terms of differences in causal strength (CS) calculated at different levels, where CS is measuring the control one has on effects (E) via causes (C). If this were perfect, there would be an isomorphism <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi><mo>→</mo><mi>E</mi></mrow><annotation encoding=\"application/x-tex\">C \\to E</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span></span></span></span>.</p>\n<p>In general, the process is a probabilistic mapping, a matrix with non-negative entries, each row summing to <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>1.</mn></mrow><annotation encoding=\"application/x-tex\">1.</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">1.</span></span></span></span> A cause is sufficient for an effect if <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>e</mi><mi mathvariant=\"normal\">∣</mi><mi>c</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">P(e|c) = 1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">e</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\">c</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">1</span></span></span></span>, and necessary if <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>e</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">¬</mi><mi>c</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">P(e|\\neg c) = 0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">e</span><span class=\"mord\">∣¬</span><span class=\"mord mathnormal\">c</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0</span></span></span></span>.</p>\n</blockquote>\n<p>Is this in the setting of a Bayesian network where the DAG is simply <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi><mo>→</mo><mi>E</mi></mrow><annotation encoding=\"application/x-tex\">C \\to E</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span></span></span></span>? Or are we merely given a stochastic matrix <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo>:</mo><mi>C</mi><mo>→</mo><mi>E</mi></mrow><annotation encoding=\"application/x-tex\">P : C \\to E</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span></span></span></span> without a distribution on <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi></mrow><annotation encoding=\"application/x-tex\">C</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span></span></span></span>? In the latter case, what does <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>e</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">¬</mi><mi>c</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">P(e|\\neg c)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">e</span><span class=\"mord\">∣¬</span><span class=\"mord mathnormal\">c</span><span class=\"mclose\">)</span></span></span></span> mean if <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>c</mi></mrow><annotation encoding=\"application/x-tex\">c</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">c</span></span></span></span> has more than two elements? Perhaps the condition formally reads as <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>e</mi><mi mathvariant=\"normal\">∣</mi><msup><mi>c</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup><mo stretchy=\"false\">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">P(e|c&#x27;) = 0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0019em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">e</span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\">c</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7519em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0</span></span></span></span> for all <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>c</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup><mo mathvariant=\"normal\">≠</mo><mi>c</mi></mrow><annotation encoding=\"application/x-tex\">c&#x27; \\neq c</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9463em;vertical-align:-0.1944em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">c</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7519em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\"><span class=\"mrel\"><span class=\"mord vbox\"><span class=\"thinbox\"><span class=\"rlap\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"inner\"><span class=\"mord\"><span class=\"mrel\"></span></span></span><span class=\"fix\"></span></span></span></span></span><span class=\"mrel\">=</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">c</span></span></span></span>?</p>",
        "id": 547414345,
        "sender_full_name": "Tobias Fritz",
        "timestamp": 1761630290
    },
    {
        "content": "<p>Assuming that my interpretation of necessary is correct, it looks to me like your idea that \"split epi = each effect has a sufficient cause\" and \"split mono = each cause is necessary to its effects\" works out very nicely. Interesting!</p>",
        "id": 547415467,
        "sender_full_name": "Tobias Fritz",
        "timestamp": 1761631042
    },
    {
        "content": "<p>Thanks, Tobias! As to the setting for this, in the most recent paper </p>\n<ul>\n<li>Abel Jansma and Erik Hoel, <a href=\"https://arxiv.org/abs/2510.02649\">Engineering Emergence</a></li>\n</ul>\n<p>we see them considering a transition probability matrix, each node considered as a cause probabilistically realising its effects. Then starting out with a distribution over nodes (chosen to be uniform), they can calculate a specificity (= <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>1</mn><mo>−</mo></mrow><annotation encoding=\"application/x-tex\">1-</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">1</span><span class=\"mord\">−</span></span></span></span> degeneracy) measure and a determinacy measure for the network, <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span></span></span></span>, and so a value measuring how near the transition probability matrix is to being a permutation matrix, (<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi><mi>P</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">CP = 1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">CP</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">1</span></span></span></span>):</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi><mi>P</mi><mo>=</mo><msub><mtext>determinacy</mtext><mi>T</mi></msub><mo>+</mo><msub><mtext>specificity</mtext><mi>T</mi></msub><mo>−</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">CP = \\text{determinacy}_T + \\text{specificity}_T - 1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">CP</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.9386em;vertical-align:-0.2441em;\"></span><span class=\"mord\"><span class=\"mord text\"><span class=\"mord\">determinacy</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2342em;\"><span style=\"top:-2.4559em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2441em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.9386em;vertical-align:-0.2441em;\"></span><span class=\"mord\"><span class=\"mord text\"><span class=\"mord\">specificity</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2342em;\"><span style=\"top:-2.4559em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2441em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">1</span></span></span></span></p>\n<p>I was wondering whether, if we put things in a good category-theoretic setting, then there would be a natural measure of the departure from isomorphism between causes and effects. </p>\n<p>Jansma and Hoel then consider all the possible coarse-grainings of the network of a  transition probability matrix to see how this <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi><mi>P</mi></mrow><annotation encoding=\"application/x-tex\">CP</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">CP</span></span></span></span> value changes, how the causality appears at different scales.</p>",
        "id": 547436607,
        "sender_full_name": "David Corfield",
        "timestamp": 1761641187
    },
    {
        "content": "<p>So in other words, one can more directly write <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi><mi>P</mi><mo>=</mo><mrow><mi mathvariant=\"normal\">d</mi><mi mathvariant=\"normal\">e</mi><mi mathvariant=\"normal\">t</mi><mi mathvariant=\"normal\">e</mi><mi mathvariant=\"normal\">r</mi><mi mathvariant=\"normal\">m</mi><mi mathvariant=\"normal\">i</mi><mi mathvariant=\"normal\">n</mi><mi mathvariant=\"normal\">a</mi><mi mathvariant=\"normal\">c</mi><mi mathvariant=\"normal\">y</mi></mrow><mo>−</mo><mrow><mi mathvariant=\"normal\">d</mi><mi mathvariant=\"normal\">e</mi><mi mathvariant=\"normal\">g</mi><mi mathvariant=\"normal\">e</mi><mi mathvariant=\"normal\">n</mi><mi mathvariant=\"normal\">e</mi><mi mathvariant=\"normal\">r</mi><mi mathvariant=\"normal\">a</mi><mi mathvariant=\"normal\">c</mi><mi mathvariant=\"normal\">y</mi></mrow></mrow><annotation encoding=\"application/x-tex\">CP = \\mathrm{determinacy} - \\mathrm{degeneracy}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">CP</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord\"><span class=\"mord mathrm\" style=\"margin-right:0.01389em;\">determinacy</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord\"><span class=\"mord mathrm\" style=\"margin-right:0.01389em;\">degeneracy</span></span></span></span></span>? In this form it reminds me of the <a href=\"https://en.wikipedia.org/wiki/Linear_map#Index\">index of a linear map</a>. It's not a perfect analogy because of CP = 1 for isomorphisms while index = 0 for invertible linear maps, but perhaps one can make the analogy more precise by using different conventions?</p>",
        "id": 547443822,
        "sender_full_name": "Tobias Fritz",
        "timestamp": 1761643474
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276702\">Tobias Fritz</span> <a href=\"#narrow/channel/229199-learning.3A-questions/topic/Hoel.20et.20al.20on.20emergence/near/547443822\">said</a>:</p>\n<blockquote>\n<p>So in other words, one can more directly write <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi><mi>P</mi><mo>=</mo><mrow><mi mathvariant=\"normal\">d</mi><mi mathvariant=\"normal\">e</mi><mi mathvariant=\"normal\">t</mi><mi mathvariant=\"normal\">e</mi><mi mathvariant=\"normal\">r</mi><mi mathvariant=\"normal\">m</mi><mi mathvariant=\"normal\">i</mi><mi mathvariant=\"normal\">n</mi><mi mathvariant=\"normal\">a</mi><mi mathvariant=\"normal\">c</mi><mi mathvariant=\"normal\">y</mi></mrow><mo>−</mo><mrow><mi mathvariant=\"normal\">d</mi><mi mathvariant=\"normal\">e</mi><mi mathvariant=\"normal\">g</mi><mi mathvariant=\"normal\">e</mi><mi mathvariant=\"normal\">n</mi><mi mathvariant=\"normal\">e</mi><mi mathvariant=\"normal\">r</mi><mi mathvariant=\"normal\">a</mi><mi mathvariant=\"normal\">c</mi><mi mathvariant=\"normal\">y</mi></mrow></mrow><annotation encoding=\"application/x-tex\">CP = \\mathrm{determinacy} - \\mathrm{degeneracy}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">CP</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord\"><span class=\"mord mathrm\" style=\"margin-right:0.01389em;\">determinacy</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord\"><span class=\"mord mathrm\" style=\"margin-right:0.01389em;\">degeneracy</span></span></span></span></span>?</p>\n</blockquote>\n<p>Yes, I was wondering why they did that (\"For simplicity’s sake\"). </p>\n<p>I reckon there could be something useful in the paper I mentioned above, Puca et al. <a href=\"https://arxiv.org/abs/2307.14461\">Obstructions to Compositionality</a>, and their measure of divergence from isomorphism.</p>\n<p>I had a brief exchange with <span class=\"user-mention\" data-user-id=\"549203\">@Caterina Puca</span> on X a while ago. I was wondering about comparison of their work with the cohomological approach of Elie Adam's thesis <a href=\"https://elieadam.com/eadam_PhDThesis.pdf\">Systems, Generativity and Interactional Effects</a> </p>\n<p><a href=\"/user_uploads/21317/AG9_oxGLO_SBomqlEu3nA5tA/image.png\">image.png</a><br>\n<a href=\"/user_uploads/21317/izB4vktybWknIyfix3L1atpw/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/21317/AG9_oxGLO_SBomqlEu3nA5tA/image.png\" title=\"image.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"558x441\" src=\"/user_uploads/thumbnail/21317/AG9_oxGLO_SBomqlEu3nA5tA/image.png/840x560.webp\"></a></div><div class=\"message_inline_image\"><a href=\"/user_uploads/21317/izB4vktybWknIyfix3L1atpw/image.png\" title=\"image.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"519x210\" src=\"/user_uploads/thumbnail/21317/izB4vktybWknIyfix3L1atpw/image.png/840x560.webp\"></a></div><p>and their</p>\n<p><a href=\"/user_uploads/21317/tQS79_UXqojEo10c-8tLBdTQ/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/21317/tQS79_UXqojEo10c-8tLBdTQ/image.png\" title=\"image.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"789x467\" src=\"/user_uploads/thumbnail/21317/tQS79_UXqojEo10c-8tLBdTQ/image.png/840x560.webp\"></a></div><p>She supported the idea that you can view emergence as failure of compositionality.</p>",
        "id": 547450946,
        "sender_full_name": "David Corfield",
        "timestamp": 1761645628
    },
    {
        "content": "<p>On the other hand, you may not want a measure of causal strength to behave like an index, because an index can be negative, and having index 0 is necessary but not sufficient for being an isomorphism.</p>",
        "id": 547450988,
        "sender_full_name": "Tobias Fritz",
        "timestamp": 1761645640
    },
    {
        "content": "<p>One might hope for Jansma-Hoel meets Baez-Courser on <a href=\"https://arxiv.org/abs/1710.11343\">Coarse-Graining Open Markov Processes</a>. Let's see if <span class=\"user-mention\" data-user-id=\"275920\">@John Baez</span> can help me out.</p>\n<p>Is there some kind of measure on open Markov processes which generalizes (and maybe modifies) the quantities that Jansma-Hoel are assigning to closed Markov processes (failure to be a deterministic permutation) so that we can get a handle on what makes for a \"good\" coarse-graining? Some kind of lax double functor from <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"double-struck\">M</mi><mrow><mi mathvariant=\"bold\">a</mi><mi mathvariant=\"bold\">r</mi><mi mathvariant=\"bold\">k</mi></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathbb{M}\\mathbf{ark}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathbb\">M</span><span class=\"mord\"><span class=\"mord mathbf\">ark</span></span></span></span></span> which detects how close a Markov process is to being deterministic and non-degenerate.</p>",
        "id": 547473270,
        "sender_full_name": "David Corfield",
        "timestamp": 1761652401
    },
    {
        "content": "<p>I don't know the Jansma-Hoel metric (or whatever it is).   For finite n, there's a unique nice topology on n x n stochastic matrices, coming from the Euclidean topology on n x n real matrices.  Any decent metric should give that topology.  But some metrics might be well-motivated.</p>",
        "id": 547542206,
        "sender_full_name": "John Baez",
        "timestamp": 1761669398
    },
    {
        "content": "<p>In the infinite-dimensional case things get more tricky.</p>",
        "id": 547542394,
        "sender_full_name": "John Baez",
        "timestamp": 1761669446
    },
    {
        "content": "<p>So it seems that people are thinking about two different things when it comes to emergence, two things which could be jointly treated via double categories. </p>\n<p><strong>Loose</strong>: The loose direction of double categories of systems is usually associated with composition: the cospan-like composition of open Petri nets, etc.; the span-like composition of the Jan Willems' behavioral approach; the operadic composition of Moore machines. </p>\n<p><strong>Tight</strong>: The loose direction of double categories of systems is usually associated with comparison of systems which may include locating trajectories of a kind by maps in, but in the context of emergence is usually considered by coarse-graining maps out (think surjections, equivalence classes).</p>\n<p>So in the Loose direction we're wondering about the relationship between the properties and behaviours of systems with respect to some kind of sum of properties and behaviours of their parts. We need some kind of mapping (double functor) from our systems and their composition to some measure of their performance. </p>\n<p>We're seeing this in </p>\n<ul>\n<li><span class=\"user-mention\" data-user-id=\"549203\">@Caterina Puca</span>, <span class=\"user-mention\" data-user-id=\"276363\">@Amar Hadzihasanovic</span>, <span class=\"user-mention\" data-user-id=\"679887\">@Fabrizio Romano Genovese</span>,  <span class=\"user-mention\" data-user-id=\"276692\">@Bob Coecke</span>, <a href=\"https://arxiv.org/abs/2307.14461\">Obstructions to Compositionality</a>,</li>\n</ul>\n<p><a href=\"/user_uploads/21317/s0Xj5nxPRAU78ge-vGgCosaw/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/21317/s0Xj5nxPRAU78ge-vGgCosaw/image.png\" title=\"image.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"639x379\" src=\"/user_uploads/thumbnail/21317/s0Xj5nxPRAU78ge-vGgCosaw/image.png/840x560.webp\"></a></div><p>One example is given of cospan composition of open graphs and the connectedness of nodes. They're looking for deviations from isomorphism of the composition of the connections of subgraphs and the connections of the composition of subgraphs.</p>\n<p>We see a comparable approach in Elie Adam's thesis </p>\n<ul>\n<li><a href=\"https://elieadam.com/eadam_PhDThesis.pdf\">Systems, Generativity and Interactional Effects</a> </li>\n</ul>\n<p>Meanwhile, in the Tight direction, we're wondering about the effects of coarse-graining on some measurable property/structure. So in the work by Hoel et al. I've mentioned at the start, it's about what coarse-graining does to the description of a system in terms of the quantity they call \"CP\" at a scale. This is the measure of a system as 'deteminacy minus degeneracy', a distance from there being necessary and sufficient causes for each effect, so an isomorphism between causes and effects.</p>\n<p>Hence my interest above in <span class=\"user-mention\" data-user-id=\"275920\">@John Baez</span>'s <a href=\"https://arxiv.org/abs/1710.11343\">Coarse-Graining Open Markov Processes</a>, since he and Courser place systems (open Markov processes) in a double category and think about the tight direction as coarse-graining. They even provide us with a double functor from the double category of open Markov processes to that of Linear relations, known as \"black-boxing\". But this is strict so no chance to think about emergence via Puca et al's laxator.</p>\n<p>It might be interesting then to have a double category of systems with a lax double functor to a double category of quantities to explore emergence in both directions simultaneously.</p>",
        "id": 548114949,
        "sender_full_name": "David Corfield",
        "timestamp": 1761904052
    },
    {
        "content": "<p>All this is very nice!</p>",
        "id": 548126551,
        "sender_full_name": "John Baez",
        "timestamp": 1761907857
    },
    {
        "content": "<p>One could perhaps get persistent homology to appear in the tight direction, as in <a href=\"https://arxiv.org/abs/2206.02530\">Persistent Homology of Coarse Grained State Space Networks</a>.</p>",
        "id": 548129009,
        "sender_full_name": "David Corfield",
        "timestamp": 1761908618
    },
    {
        "content": "<p>You can see the two directions of composition for flavored Petri nets in <span class=\"user-mention\" data-user-id=\"751249\">@David Jaz Myers</span>'s <a href=\"https://www.youtube.com/watch?v=sQW9KI9hdTI&amp;t=169s\">talk</a>. The coarse-graining/blackboxing/refinement direction from around 27 mins:</p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"sQW9KI9hdTI\" href=\"https://www.youtube.com/watch?v=sQW9KI9hdTI&amp;t=169s\"><img src=\"https://uploads.zulipusercontent.net/a57d2ed67912a33edccf3370d6551695dd746dbd/68747470733a2f2f692e7974696d672e636f6d2f76692f735157394b4939686454492f6d7164656661756c742e6a7067\"></a></div><p><a href=\"/user_uploads/21317/glEQgElglqebEGpdHhtdAlEL/Screenshot-2025-11-25-11.56.04.png\">Screenshot 2025-11-25 11.56.04.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/21317/glEQgElglqebEGpdHhtdAlEL/Screenshot-2025-11-25-11.56.04.png\" title=\"Screenshot 2025-11-25 11.56.04.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"1047x641\" src=\"/user_uploads/thumbnail/21317/glEQgElglqebEGpdHhtdAlEL/Screenshot-2025-11-25-11.56.04.png/840x560.webp\"></a></div><p>And the gluing direction for two nets (47 mins):</p>\n<p><a href=\"/user_uploads/21317/49kLdzj5L6RrqjKj84miGOYR/Screenshot-2025-11-25-12.18.30.png\">Screenshot 2025-11-25 12.18.30.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/21317/49kLdzj5L6RrqjKj84miGOYR/Screenshot-2025-11-25-12.18.30.png\" title=\"Screenshot 2025-11-25 12.18.30.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"1020x504\" src=\"/user_uploads/thumbnail/21317/49kLdzj5L6RrqjKj84miGOYR/Screenshot-2025-11-25-12.18.30.png/840x560.webp\"></a></div><p>and more generally (53 mins):</p>\n<p><a href=\"/user_uploads/21317/e-mBeA4voBeYPtIs0fss2Vai/Screenshot-2025-11-25-12.24.46.png\">Screenshot 2025-11-25 12.24.46.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/21317/e-mBeA4voBeYPtIs0fss2Vai/Screenshot-2025-11-25-12.24.46.png\" title=\"Screenshot 2025-11-25 12.24.46.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"683x239\" src=\"/user_uploads/thumbnail/21317/e-mBeA4voBeYPtIs0fss2Vai/Screenshot-2025-11-25-12.24.46.png/840x560.webp\"></a></div><p>(<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"double-struck\">C</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbb{C}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6889em;\"></span><span class=\"mord mathbb\">C</span></span></span></span> is the double category of colors/flavors.)</p>",
        "id": 560145378,
        "sender_full_name": "David Corfield",
        "timestamp": 1764074997
    },
    {
        "content": "<p>Has anyone looked to take the category-theoretic work on entropy of <span class=\"user-mention\" data-user-id=\"275920\">@John Baez</span>, <span class=\"user-mention\" data-user-id=\"276702\">@Tobias Fritz</span>, Tom Leinster, </p>\n<ul>\n<li><a href=\"https://ncatlab.org/johnbaez/show/A+characterization+of+entropy+in+terms+of+information+loss\">A characterization of entropy in terms of information loss</a></li>\n</ul>\n<p>in the direction of double categories? </p>\n<p>If there is a notion of the entropy of a Markov process, I wonder if that might be made to fit with double categories of <a href=\"https://arxiv.org/abs/1710.11343\">open Markov processes</a>. And more generally, the double-operadic construction of dynamical systems.</p>",
        "id": 564026223,
        "sender_full_name": "David Corfield",
        "timestamp": 1765886850
    },
    {
        "content": "<p>I don't know of anyone who has done that. <span class=\"user-mention\" data-user-id=\"276702\">@Tobias Fritz</span> is more likely to know.</p>\n<p>We were assigning entropy to a stochastic map between finite sets <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">X</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span></span></span></span> and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Y</mi></mrow><annotation encoding=\"application/x-tex\">Y</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span></span></span></span>, i.e. a map <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi><mo>:</mo><mi>X</mi><mo>×</mo><mi>Y</mi><mo>→</mo><mo stretchy=\"false\">[</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">p: X \\times Y \\to [0,1]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">]</span></span></span></span> such that for any <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span> the sum of the <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">p(x,y)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span></span></span></span> over <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">y</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span></span></span> is 1.   So to embed this in a double category framework, one question is what you'd want as your double category.  Stochastic maps as loose morphisms and ordinary maps as tight ones?   Then every tight morphism has a companion: you can see an ordinary map as a special case of a stochastic map.</p>",
        "id": 564065380,
        "sender_full_name": "John Baez",
        "timestamp": 1765897820
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"302507\">David Corfield</span> <a href=\"#narrow/channel/229199-learning.3A-questions/topic/Hoel.20et.20al.20on.20emergence/near/564026223\">said</a>:</p>\n<blockquote>\n<p>Has anyone looked to take the category-theoretic work on entropy of <span class=\"user-mention silent\" data-user-id=\"275920\">John Baez</span>, <span class=\"user-mention silent\" data-user-id=\"276702\">Tobias Fritz</span>, Tom Leinster, </p>\n<ul>\n<li><a href=\"https://ncatlab.org/johnbaez/show/A+characterization+of+entropy+in+terms+of+information+loss\">A characterization of entropy in terms of information loss</a></li>\n</ul>\n<p>in the direction of double categories? </p>\n<p>If there is a notion of the entropy of a Markov process, I wonder if that might be made to fit with double categories of <a href=\"https://arxiv.org/abs/1710.11343\">open Markov processes</a>. And more generally, the double-operadic construction of dynamical systems.</p>\n</blockquote>\n<p>Hi!</p>\n<p>I am not sure it answers your question, but I have been working on the double point of view for a while now, although I haven't dealt with entropy (yet); I put a draft on ArXiv: <a href=\"https://arxiv.org/abs/2502.02517\">https://arxiv.org/abs/2502.02517</a><br>\nIt's outdated though, I will update it soon!<br>\nI allow \"morphisms of open Markov processes\" to be stochastic, though care must be taken when composing.</p>\n<p>Best,<br>\nPaul</p>",
        "id": 564216217,
        "sender_full_name": "Paul Wang",
        "timestamp": 1765967048
    },
    {
        "content": "<p>Thanks for this! I'll take a look later this week when I have a moment. My hunch at the moment is for coarse-graining entropy/information loss in the tight direction and process composition in the loose.</p>",
        "id": 564227205,
        "sender_full_name": "David Corfield",
        "timestamp": 1765970549
    },
    {
        "content": "<p>Btw, my work with Fritz and Leinster said nothing about Markov processes, so I think of \"double categories of Markov processes\" and \"getting entropy as a functor out of a category where morphisms are stochastic maps\" to be separate ideas, though of course one could try to combine them.   A Markov process is a 1-parameter semigroup of stochastic maps.</p>",
        "id": 564251411,
        "sender_full_name": "John Baez",
        "timestamp": 1765978172
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"275920\">John Baez</span> <a href=\"#narrow/channel/229199-learning.3A-questions/topic/Hoel.20et.20al.20on.20emergence/near/564251411\">said</a>:</p>\n<blockquote>\n<p>though of course one could try to combine them</p>\n</blockquote>\n<p>A first guess: take <a href=\"https://ncatlab.org/johnbaez/show/A+characterization+of+entropy+in+terms+of+information+loss\">your category</a> of measure-preserving functions between finite sets equipped with probability measures in the tight direction. Then in the loose direction, take some kind of open Markov chains, something along the lines of <a href=\"https://www.cs.mcgill.ca/~prakash/Pubs/bicats_final.pdf\">Bicategories of Markov Processes</a>, but where input and output sets are equipped with probability measures.</p>\n<p>We know there's some entropic quantity associated to open Markov processes, as in <a href=\"https://arxiv.org/abs/1410.6531\">A Second Law for Open Markov Processes</a>.</p>\n<p>One might imagine a comparison of the composition of a Markov process entropy gain and a coarse-graining entropy gain with the composition following the other way around the square. </p>\n<p>But of course the important thing is to see if something like this works.</p>",
        "id": 564735163,
        "sender_full_name": "David Corfield",
        "timestamp": 1766161630
    }
]