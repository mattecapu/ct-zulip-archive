[
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"276438\">@Fabrizio Genovese</span> Can you explain your claim on #general that switching from the free pregroup to the free autonomous/CCC defeats the purpose? I thought about exactly this a year or 2 ago and convinced myself that it's a good idea, and that Anne Preller was right and everyone else was wrong</p>",
        "id": 191729154,
        "sender_full_name": "Jules Hedges",
        "timestamp": 1585134364
    },
    {
        "content": "<p>I think of it like the free autonomous cat is a proof-relevant version of the free pregroup. So the linear map you apply to your word vector depends on the derivation, not just on the fact that a derivation exists</p>",
        "id": 191729270,
        "sender_full_name": "Jules Hedges",
        "timestamp": 1585134450
    },
    {
        "content": "<p>In general, generative grammar is logic, and history tells us [controversial claim but probably not around here] that categorical semantics is better than posetal semantics</p>",
        "id": 191729850,
        "sender_full_name": "Jules Hedges",
        "timestamp": 1585134735
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"275901\">Jules Hedges</span> <a href=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191729154\" title=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191729154\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"276438\">Fabrizio Genovese</span> Can you explain your claim on #general that switching from the free pregroup to the free autonomous/CCC defeats the purpose? I thought about exactly this a year or 2 ago and convinced myself that it's a good idea, and that Anne Preller was right and everyone else was wrong</p>\n</blockquote>\n<p>So the original idea of discocat is \"we tag every word with an element of the pregroup (noun, sentence, whatevs) and then we use the pregroup rules to infer the wiring. The reason why you can't do this is because you can prove that the vector space you get is trivial (as Preller did). So we resort to generate this huge category with all the words in it. Then things clearly work, but I guess you lose the original purpose of the idea, that is, separating tags from semantics, and encoding the tagging system in the functor. Now tags, semantics and tagging systems are all more or less conflated in the free CCC you generate.</p>",
        "id": 191733690,
        "sender_full_name": "Fabrizio Genovese",
        "timestamp": 1585137290
    },
    {
        "content": "<p>So yes, categorically it works, but from a practical/computational point of view I find it to be quite unsatisfying.</p>",
        "id": 191733725,
        "sender_full_name": "Fabrizio Genovese",
        "timestamp": 1585137316
    },
    {
        "content": "<p>Yes, probably you want to flip that</p>",
        "id": 191749404,
        "sender_full_name": "Fabrizio Genovese",
        "timestamp": 1585145124
    },
    {
        "content": "<p>What I mean is that at that point tags and their assignments to words become all jumbled together</p>",
        "id": 191749447,
        "sender_full_name": "Fabrizio Genovese",
        "timestamp": 1585145143
    },
    {
        "content": "<p>So yes, that works, but then I don't see a real reason for not doing the wires directly in the semantics</p>",
        "id": 191749548,
        "sender_full_name": "Fabrizio Genovese",
        "timestamp": 1585145175
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276424\">Rongmin Lu</span> <a href=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191750502\" title=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191750502\">said</a>:</p>\n<blockquote>\n<p>Practically speaking, that's how I'd imagine languages behave. The <a href=\"https://arxiv.org/abs/1907.12412v1\" title=\"https://arxiv.org/abs/1907.12412v1\">ERNIE work</a> I cited over in #general showed how their system improved when they allowed some form of \"chunking\", which seems to me to mess up the neat tagging system envisioned in the original idea (at least to the best of my understanding of your description). Their original motivation was to improve the processing of Chinese, where you often smoosh characters together to make a word that has a meaning not obvious from the surface meanings of its characters. Similar things happen in English as well: proper nouns, idioms, sayings, etc.</p>\n</blockquote>\n<p>Yes. This has to do with the fact that, as you said, current method basically work well only for romance languages, maybe indo-european. I'm a language geek myself and I had my share of non-european languages, and I agree that current approaches in DiscoCat scale quite badly outside of Romance/Germanic languages.</p>",
        "id": 191751374,
        "sender_full_name": "Fabrizio Genovese",
        "timestamp": 1585145935
    },
    {
        "content": "<p>So the reason why I focused on Hieroglyphs is something that I then found to happen also in Asian languages such as Japanese. Basically people are happy with having a lot of indeterminateness going around, to be clarified from context.</p>",
        "id": 191751508,
        "sender_full_name": "Fabrizio Genovese",
        "timestamp": 1585145988
    },
    {
        "content": "<p>So while in English, say, I always have to communicate <em>when</em> an action is happening (dobe my picking a tense), this is not true in Egyptian, or in Japanese to some extent. Japanese is particularly interesting, because if on one hand they care very little about being specific in our western grammatical sense, on the other they are very careful wrt other things we are totally oblivious of, such as who you are speaking to (the same sentence can be said in many different ways depending on the degree of politeness you want to use, and for westeners it's insane how much granular this can be)</p>",
        "id": 191751768,
        "sender_full_name": "Fabrizio Genovese",
        "timestamp": 1585146095
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276424\">Rongmin Lu</span> <a href=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191750873\" title=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191750873\">said</a>:</p>\n<blockquote>\n<p>I'm reminded also of a Twitter thread that might have started with <span class=\"user-mention silent\" data-user-id=\"275901\">Jules Hedges</span> (although I could be wrong), where someone opined that analysts don't find category theory useful because they're often juggling half a dozen conditions simultaneously. The idea was floated that perhaps we should have a more flexible notion of a category to accommodate such situations, and I believe <span class=\"user-mention silent\" data-user-id=\"275965\">Evan Patterson</span>  mentioned something along that line, although I forgot what the technical name was. Something similar seems to be happening here: my feeling is DisCoCat is rather rigid for the ambitions that people have for it.</p>\n</blockquote>\n<p>I feel the topic <code>measuring non-compositonality</code> deals exactly with this sort of problems. Language is one of the reasons why we started thinking about it</p>",
        "id": 191751980,
        "sender_full_name": "Fabrizio Genovese",
        "timestamp": 1585146176
    },
    {
        "content": "<p>Well, a friend of mine told me this lifesaver thing: When you are in Japan and you are still very bad with the language, just begin any conversation by saying \"Hey, I'm just learning and I am not good. Could you speak to me like I were a child?\" In this way:</p>\n<ul>\n<li>You are somehow justified for being rude, since you don't know any better</li>\n<li>They talk to you in a simpler way, making your struggle less intense :)</li>\n</ul>",
        "id": 191752279,
        "sender_full_name": "Fabrizio Genovese",
        "timestamp": 1585146287
    },
    {
        "content": "<p>Ancient Greek is quite the opposite. Ancient Greek and Sanskrit are increadibly precise in the western grammatical sense.</p>",
        "id": 191754437,
        "sender_full_name": "Fabrizio Genovese",
        "timestamp": 1585147178
    },
    {
        "content": "<p>Hebrew yes, I agree with you. The reason for this is that Sanskrit and Ancient Greek are the languages that retain the most from the proto-indo-european, which is highly sintethic. Hebrew on the contrary is a semitic language, so a whole different thing.</p>",
        "id": 191754636,
        "sender_full_name": "Fabrizio Genovese",
        "timestamp": 1585147244
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276438\">Fabrizio Genovese</span> <a href=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191754437\" title=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191754437\">said</a>:</p>\n<blockquote>\n<p>Ancient Greek is quite the opposite. Ancient Greek and Sanskrit are increadibly precise in the western grammatical sense.</p>\n</blockquote>\n<p>Good to know, and not too surprising in hindsight. After all, these two ancient societies were pretty obsessed about grammar and teaching it well.</p>",
        "id": 191755218,
        "sender_full_name": "(=_=)",
        "timestamp": 1585147443
    },
    {
        "content": "<p>Those two are by far the most difficult languages I studied.</p>",
        "id": 191755349,
        "sender_full_name": "Fabrizio Genovese",
        "timestamp": 1585147500
    },
    {
        "content": "<p>But I should mention that I explicitly avoided having anything to do with Na-Dene languages (e.g. Navajo) which I think are the most difficult languages on the planet (at least considering the ones I am aware of)</p>",
        "id": 191755597,
        "sender_full_name": "Fabrizio Genovese",
        "timestamp": 1585147598
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"276424\">@Rongmin Lu</span> <span class=\"user-mention\" data-user-id=\"276438\">@Fabrizio Genovese</span> Replying to functor between grammar and meaning in whatever direction; neither are any good, really.  In the first paper I wrote, as well as in the latest, there is a single category that both has structures (including grammar but not exclusively) and meaning.  Understanding what this structure is is part of the effort, in the same way as better understanding what the meaning spaces are, and these two problems are obviously not two separate ones, but a single one.</p>",
        "id": 191853817,
        "sender_full_name": "Bob Coecke",
        "timestamp": 1585212770
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276424\">Rongmin Lu</span> <a href=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191877552\" title=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191877552\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"276692\">Bob Coecke</span>  <span class=\"user-mention silent\" data-user-id=\"276438\">Fabrizio Genovese</span>  Could you please briefly explain what a meaning space is? My nagging suspicion is that it's an abstraction that's not adequately fit for purpose. It may have been useful as a first-approximation prototype, but there may well be higher structure that's been missed with the underlying assumptions.</p>\n</blockquote>\n<p>I can answer only WRT what we were doing when I was doing it. So for instance you have the sentence \"Clowns Tell Jokes\". Now \"Clowns\" and \"Jokes\" are states, that is, vectors that live in vector spaces that you can build more or less easily by doing thesaurus extraction of whatnot. \"Tell\" is a verb, so it expects a noun on the left, a noun on the right (which you compose using caps) and spits out a state (hence a vector) in some other vector space,  which is the space where sentences live. Clearly one of the main problems there is that no one had a clue about how this space looked like, or how to build it. Another approach we pursued was a cognitive-oriented one, which is the one I used in my PhD thesis. That was conceptually satisfying, but without learning techniques it was basically impossible to build real-life spaces and do something more than toy models</p>",
        "id": 191878429,
        "sender_full_name": "Fabrizio Genovese",
        "timestamp": 1585226965
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"276692\">@Bob Coecke</span> claims to have solved this problem in the last paper. The idea of describing verbs as \"applying things to nouns\" is nice because gets rid of this sentence space altogether and allows you to live only in the spaces you already have but I don't know if it works for any verb. About the functor, the first DisCoCat paper was great because there wasn't any functor, and relationships between grammar/semantics were done using products. So yes, it was a unique category but things were still neatly separated, somehow. I still think that a functor Semantics -&gt; Grammar is useful, not from the NLP point of view, but from a linguistic perspective. It is also a nice point to tackle a lot of problems in Applied Category Theory that pop up pretty much everywhere, but are more pronounced for language, such as the fact that categories are more or less bad to deal with exceptions.</p>",
        "id": 191878789,
        "sender_full_name": "Fabrizio Genovese",
        "timestamp": 1585227165
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276424\">Rongmin Lu</span> <a href=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191882631\" title=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191882631\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"276438\">Fabrizio Genovese</span> <a href=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191878789\" title=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191878789\">said</a>:</p>\n<blockquote>\n<p>categories are more or less bad to deal with exceptions.</p>\n</blockquote>\n<p>Ask a CS person maybe? They know a lot about exceptions. <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span></p>\n</blockquote>\n<p>Kleisli categories of  relevant monads are excellent ways to deal with exceptions and they often come with convenient enrichments. I'm actually working in those as we speak.</p>",
        "id": 191883235,
        "sender_full_name": "Stelios Tsampas",
        "timestamp": 1585229114
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276424\">Rongmin Lu</span> <a href=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191882631\" title=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191882631\">said</a>:</p>\n<blockquote>\n<blockquote>\n<p>I still think that a functor Semantics -&gt; Grammar is useful, not from the NLP point of view, but from a linguistic perspective.</p>\n</blockquote>\n<p>I'm not convinced a functor exists, even in a hand-wavy sense. I think you need something less rigid. \"Semantics\" and \"Grammar\" probably aren't even categories to begin with.</p>\n</blockquote>\n<p>I'm probably taking this out of context, so I apologize if that's the case. Lawvere theories (which are categories) can model syntax with or without extra equations.</p>",
        "id": 191883674,
        "sender_full_name": "Stelios Tsampas",
        "timestamp": 1585229326
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"275900\">Stelios Tsampas</span> <a href=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191883674\" title=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191883674\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"276424\">Rongmin Lu</span> <a href=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191882631\" title=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191882631\">said</a>:</p>\n<blockquote>\n<blockquote>\n<p>I still think that a functor Semantics -&gt; Grammar is useful, not from the NLP point of view, but from a linguistic perspective.</p>\n</blockquote>\n<p>I'm not convinced a functor exists, even in a hand-wavy sense. I think you need something less rigid. \"Semantics\" and \"Grammar\" probably aren't even categories to begin with.</p>\n</blockquote>\n<p>I'm probably taking this out of context, so I apologize if that's the case. Lawvere theories (which are categories) can model syntax with or without extra equations.</p>\n</blockquote>\n<p>Maybe I went overboard with \"Grammar\", but I feel that part of the reason why \"Semantics\" is so difficult is that it is very likely not a category. I'm not saying CT is of no use here. Rather, a plain vanilla category is probably not the abstraction you're looking for, and so it's probably not a good idea to ask for a plain vanilla functor.</p>",
        "id": 191884160,
        "sender_full_name": "(=_=)",
        "timestamp": 1585229523
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276424\">Rongmin Lu</span> <a href=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191884160\" title=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191884160\">said</a>:</p>\n<blockquote>\n<p>Maybe I went overboard with \"Grammar\", but I feel that part of the reason why \"Semantics\" is so difficult is that it is very likely not a category. I'm not saying CT is of no use here. Rather, a plain vanilla category is probably not the abstraction you're looking for, and so it's probably not a good idea to ask for a plain vanilla functor.</p>\n</blockquote>\n<p>A plain, vanilla 1-category is most likely not \"Semantics\", I'll give you just that :P.</p>",
        "id": 191885456,
        "sender_full_name": "Stelios Tsampas",
        "timestamp": 1585230090
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276424\">Rongmin Lu</span> <a href=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191883619\" title=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191883619\">said</a>:</p>\n<blockquote>\n<p>Anyway, now that I get a rough idea of what these spaces are, here's what I think is missing: recursion. I haven't seen any provision for recursion in this framework, and per Chomsky, this is a key feature of human language. My guess is that you need to provide for recursion in order to handle any expressions less trivial than simple grade 1 sentences, which means exploring more intricate categorical structures. The properads thread may be one place to look. I see polycategories gathering a lot of interest here, and at first glance, these look useful. Monads (and maybe 2-monads) too, perhaps.</p>\n</blockquote>\n<p>I spent an entire chapter in my thesis disagreeing with Chomsky about this, I don't think recursion is a key feature of human language and I don't think chomskian approach to language will get us very far, frankly</p>",
        "id": 191886152,
        "sender_full_name": "Fabrizio Genovese",
        "timestamp": 1585230354
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"276424\">@Rongmin Lu</span> <span class=\"user-mention\" data-user-id=\"276438\">@Fabrizio Genovese</span> One can talk endless on what is missing and what not.  Evidently, unlike physics, practical NLP is not an exact science.  Things make progress by little steps, sometimes taking many centuries...it took Einstein's relativity theory for putting the sun in the middle outperform epicycles!  The initial goal of DisCoCat was to account for grammatical structure when considering meanings like those living in vector spaces that were used in practical NLP, which at the time were treated as a bag of words.  In that we succeeded I think.  Ok, let's talk on what to do next a.k.a. what needs improving (cf planets don't move on circles, but on ellipses, and things don't actually move faster than light).  Ok, there is no functor, I agree, and in neither of the directions.</p>",
        "id": 191898357,
        "sender_full_name": "Bob Coecke",
        "timestamp": 1585235409
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"276692\">@Bob Coecke</span> <a href=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191898357\" title=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191898357\">said</a>:</p>\n<blockquote>\n<p>The initial goal of DisCoCat was to account for grammatical structure when considering meanings like those living in vector spaces that were used in practical NLP, which at the time were treated as a bag of words.  In that we succeeded I think. </p>\n</blockquote>\n<p>That's what I loved about DisCoCat when I first stumbled upon it: finally, something that can counteract Frederick Jelinek's oft-quoted sentiment that</p>\n<blockquote>\n<p>\"Every time I fire a linguist, the performance of the speech recognizer goes up\".</p>\n</blockquote>\n<p>I think that might have been true when the problem was coming up with something that could solve a low-level pattern recognition problem in NLP, but now that that's (mostly) done, we need to find better tools to cope with the higher-level NLP problems, and DisCoCat turned out to be a step in the right direction.</p>\n<blockquote>\n<p>Ok, let's talk on what to do next a.k.a. what needs improving (cf planets don't move on circles, but on ellipses, and things don't actually move faster than light).  Ok, there is no functor, I agree, and in neither of the directions.</p>\n</blockquote>\n<p>I think DisCoCirc looks interesting, and if you have circuits, operads and friends are probably something to look at. I think semantics and grammar interact both ways, but functors are perhaps too simple to model that interaction. I think we've been ignoring the very important <em>context</em> plays in semantics, both in terms of syntactic context and \"embodied\" or \"environmental\" context. For good reasons, I hasten to add: the latter is definitely still a big and messy problem to deal with, even as the former seems to be getting more tractable.</p>",
        "id": 191989428,
        "sender_full_name": "(=_=)",
        "timestamp": 1585299037
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"276424\">@Rongmin Lu</span> <span class=\"user-mention\" data-user-id=\"276438\">@Fabrizio Genovese</span> Re:<br>\n\"Every time I fire a linguist, the performance of the speech recognizer goes up\".<br>\nWith his attitude the machines on which he does his speech recognition would never have existed, that's all that needs pointing out to morons like that (and the world is packed with them).</p>",
        "id": 191999413,
        "sender_full_name": "Bob Coecke",
        "timestamp": 1585305326
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"276692\">@Bob Coecke</span> <a href=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191999413\" title=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191999413\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"276424\">Rongmin Lu</span> <span class=\"user-mention silent\" data-user-id=\"276438\">Fabrizio Genovese</span> Re:<br>\n\"Every time I fire a linguist, the performance of the speech recognizer goes up\".<br>\nWith his attitude the machines on which he does his speech recognition would never have existed, that's all that needs pointing out to morons like that (and the world is packed with them).</p>\n</blockquote>\n<p>I think that was the prevailing attitude in practical NLP at the time DisCoCat came out, because Frederick Jelinek <a href=\"https://web.archive.org/web/20110728025129/http://www.signalprocessingsociety.org/technical-committees/list/sl-tc/spl-nl/2010-11/jelinek/\" title=\"https://web.archive.org/web/20110728025129/http://www.signalprocessingsociety.org/technical-committees/list/sl-tc/spl-nl/2010-11/jelinek/\">pioneered the application of information theory to speech recognition</a> with great success. I think it's only now, with speech recognition being somewhat serviceable but making high-level mistakes, that linguistic knowledge would come to the forefront.</p>",
        "id": 192008435,
        "sender_full_name": "(=_=)",
        "timestamp": 1585311224
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276438\">Fabrizio Genovese</span> <a href=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191886152\" title=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191886152\">said</a>:</p>\n<blockquote>\n<p>I spent an entire chapter in my thesis disagreeing with Chomsky about this, I don't think recursion is a key feature of human language and I don't think chomskian approach to language will get us very far, frankly</p>\n</blockquote>\n<p>Oh dear. TIL. <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span> </p>\n<p>I don't think we disagree. In fact, I really enjoyed your discussion about the PirahaÌƒ. I think I was reaching for some concept like interacting feedback loops and landed on recursion instead, sorry.</p>",
        "id": 192008780,
        "sender_full_name": "(=_=)",
        "timestamp": 1585311518
    },
    {
        "content": "<p>I really love Everett's approach to linguistics. Language is a tool, and as any tool it is created to solve some problems</p>",
        "id": 192008941,
        "sender_full_name": "Fabrizio Genovese",
        "timestamp": 1585311653
    },
    {
        "content": "<p>This perspective has the virtue of taking into account also the context in which a language develops. For instance, Piraha can be completely whistled, and this most likely has developed as a solution to the problem of hunting and communicating over long distances</p>",
        "id": 192009052,
        "sender_full_name": "Fabrizio Genovese",
        "timestamp": 1585311729
    },
    {
        "content": "<p>Also I think that the approach of having \"one monolithic theory that describes every particular instance of something\" is a remnant of the XIX century, so in this sense I don't understand Chomsky's effort to differentiate human and animal communication in terms of, say, recursion. The whole sense of the \"universal grammar\" approach escapes me...</p>",
        "id": 192009243,
        "sender_full_name": "Fabrizio Genovese",
        "timestamp": 1585311852
    },
    {
        "content": "<p>Definitely agree on no clear break between human and animal, but also don't think of language as a tool; what is is the embodiment of it, but the fundamental ontology for me is a representation of reality, and grammar represents the interaction structures of that reality.</p>",
        "id": 192009396,
        "sender_full_name": "Bob Coecke",
        "timestamp": 1585311974
    },
    {
        "content": "<p>But the need of representing reality serves itself a purpose. Many living things don't do this, while humans somehow found a way to represent reality so that these representations can be shared. If this didn't serve any purpose, we would have most likely lost this ability by now</p>",
        "id": 192009683,
        "sender_full_name": "Fabrizio Genovese",
        "timestamp": 1585312181
    },
    {
        "content": "<p>When I say \"language as a tool\" what I really focus on is this: There are many different languages. some are highly inflected, some aren't inflected at all. Some can be even whistled, others have a very scarce phonetic inventory etc. I don't think these differences arise by chance. Instead, I think they arise because a language with some features is more efficient than another with different features in a given context.</p>",
        "id": 192009856,
        "sender_full_name": "Fabrizio Genovese",
        "timestamp": 1585312277
    },
    {
        "content": "<p>The language of math is probably the greatest example of this. As soon as we are \"stuck\" at being able to communicate something, we design new mathematical tools to do so. <span aria-label=\"slight smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"slight smile\">:slight_smile:</span></p>",
        "id": 192009951,
        "sender_full_name": "Fabrizio Genovese",
        "timestamp": 1585312326
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276438\">Fabrizio Genovese</span> <a href=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191733690\" title=\"#narrow/stream/229156-applied-category.20theory/topic/DisCoCat/near/191733690\">said</a>:</p>\n<blockquote>\n<p>So the original idea of discocat is \"we tag every word with an element of the pregroup (noun, sentence, whatevs) and then we use the pregroup rules to infer the wiring. The reason why you can't do this is because you can prove that the vector space you get is trivial (as Preller did). So we resort to generate this huge category with all the words in it. Then things clearly work, but I guess you lose the original purpose of the idea, that is, separating tags from semantics, and encoding the tagging system in the functor. Now tags, semantics and tagging systems are all more or less conflated in the free CCC you generate.</p>\n</blockquote>\n<p>I'm not sure if I understand this characterization of the free compact closed category. My understanding is that the words are still freely generated by grammatical types, the key difference between this category and a pregroup, is that the free compact closed category is not a preorder (meaning that there can be more than one morphism between pairs of objects). To use <span class=\"user-mention\" data-user-id=\"276692\">@Bob Coecke</span>'s favorite phrase, this is a feature not a bug because  it allows you to keep better track of the way in which the meanings of sentences are computed.</p>",
        "id": 192304598,
        "sender_full_name": "Jade Master",
        "timestamp": 1585596025
    }
]