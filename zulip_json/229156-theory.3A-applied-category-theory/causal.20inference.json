[
    {
        "content": "<p>New paper by Rémy Tuyéras, \"A category theoretical argument for causal inference\" <a href=\"https://arxiv.org/abs/2004.09999\" title=\"https://arxiv.org/abs/2004.09999\">https://arxiv.org/abs/2004.09999</a></p>",
        "id": 194914206,
        "sender_full_name": "Jules Hedges",
        "timestamp": 1587552774
    },
    {
        "content": "<p>This paper is amazing. Do you know of any other papers at the direct intersection of statistics and CT? And if so, how do I find more? (I know that Brendan Fong did his MA thesis on categorified Beysian networks, and that Peter MCullagh published a paper about categorified statistical models way back in 2002 but that's about it. My list is very short.)</p>",
        "id": 195217150,
        "sender_full_name": "Oliver Shetler",
        "timestamp": 1587747876
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"276053\">@Brendan Fong</span> 's Master's thesis is related, <span class=\"user-mention\" data-user-id=\"275965\">@Evan Patterson</span> is also working on CT + Stats</p>",
        "id": 195296096,
        "sender_full_name": "James Fairbanks",
        "timestamp": 1587838128
    },
    {
        "content": "<p>Thanks James! I'll look into it. I'm collecting literature because I want to do my own (statistics) Masters' thesis on something in this area. Any idea who is both knowledgable and friendly enough to tolerate a green grad student's questions about open problems in the area?</p>",
        "id": 195297761,
        "sender_full_name": "Oliver Shetler",
        "timestamp": 1587840913
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"275965\">@Evan Patterson</span> is here sometimes, and he's both friendly and knowledgeable.   I'm not knowledgeable, but I'm friendly.  I kept telling Brendan to publish his master's thesis (he did his PhD with me).  I haven't read Remy Tuyeras' <a href=\"https://arxiv.org/abs/2004.09999\" title=\"https://arxiv.org/abs/2004.09999\">new paper</a> but from the abstract it looks important.</p>",
        "id": 195305198,
        "sender_full_name": "John Baez",
        "timestamp": 1587852853
    },
    {
        "content": "<p>Hi Oliver, my list of papers is not much longer than yours. Recently both Tobias Fritz and Bart Jacobs' group have done really nice work on synthetic and diagrammatic approaches to probability/stats, which you might be aware of. However, these papers are closer to probability than to statistics, at least compared to the works by Fong and McCullagh that you mentioned. I have not yet read the new paper in this thread but it looks very interesting.</p>\n<p>In about a month I will put out a PhD thesis at the direct intersection of statistics and CT. It will have elements recognizable from many of the above works, as well as some elements of its own that I hope people will find interesting.</p>\n<p>I'd be happy to chat about stats + CT and answer any questions that I can. For the next month I will be working manically to finish this dang thesis so that I can graduate on time, but after that my schedule will open up.</p>",
        "id": 195307323,
        "sender_full_name": "Evan Patterson",
        "timestamp": 1587856901
    },
    {
        "content": "<p>That sounds great. I'd love to discuss when you have more time. In the mean time, I'll collect my thoughts and take a look at Fritz and Jacobs' work.</p>",
        "id": 195307981,
        "sender_full_name": "Oliver Shetler",
        "timestamp": 1587857947
    },
    {
        "content": "<p>Lol, <span class=\"user-mention\" data-user-id=\"275920\">@John Baez</span> careful who you say these things to. Now you'll be the first person I'll bother when I have a question...</p>\n<p>Such as this one: (and I think this is still relevant to causal inference), a friend and I conjectured that products of graphs are computed by tensor products of connection matrices but weren't able to prove it. Do you know if this is true? And if so, does it extend to weighted graphs or causal diagrams?</p>",
        "id": 195308433,
        "sender_full_name": "Oliver Shetler",
        "timestamp": 1587858828
    },
    {
        "content": "<p>The difficulty with your question is that \"products of graphs\" means many different things.  This Wikipedia article lists 10 different definitions:</p>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Graph_product\" title=\"https://en.wikipedia.org/wiki/Graph_product\">Graph products</a>.</li>\n</ul>\n<p>By \"connection matrix\" I'll assume you mean \"<a href=\"https://en.wikipedia.org/wiki/Incidence_matrix#Graph_theory\" title=\"https://en.wikipedia.org/wiki/Incidence_matrix#Graph_theory\">incidence matrix</a>\": in graph theory people talk about the incidence matrix of a graph.</p>\n<p>So: I promise you that for <em>one</em> of the ten listed definitions of \"product of graph\", the incidence matrix of a product of graphs is the tensor product of their incidence matrices!</p>",
        "id": 195311080,
        "sender_full_name": "John Baez",
        "timestamp": 1587864135
    },
    {
        "content": "<p>If not, there are a few more to choose from: in <em>Associative Products of Graphs</em> (<a href=\"https://link.springer.com/article/10.1007/BF01472575\" title=\"https://link.springer.com/article/10.1007/BF01472575\">https://link.springer.com/article/10.1007/BF01472575</a>), they enumerate all of them.</p>",
        "id": 195311814,
        "sender_full_name": "Nathanael Arkor",
        "timestamp": 1587865594
    },
    {
        "content": "<p>Looking at the Wikipedia article I think the product you want is the one that graph theorists call the <a href=\"https://en.wikipedia.org/wiki/Tensor_product_of_graphs\" title=\"https://en.wikipedia.org/wiki/Tensor_product_of_graphs\">tensor product of graphs</a>. So, I'm claiming the incidence matrix of the tensor product of graphs is the tensor product of the incidence matrices of those graphs!</p>",
        "id": 195312472,
        "sender_full_name": "John Baez",
        "timestamp": 1587866841
    },
    {
        "content": "<p>(Pro tip: what graph theorists call the \"tensor product\" of graphs is what category theorists would call the \"cartesian product\", or simply \"product\", of graphs.   But what graph theorists call the \"cartesian product\" of graphs is something else!  <span aria-label=\"dizzy\" class=\"emoji emoji-1f635\" role=\"img\" title=\"dizzy\">:dizzy:</span>)</p>",
        "id": 195312813,
        "sender_full_name": "John Baez",
        "timestamp": 1587867497
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"275965\">@Evan Patterson</span> Yes, please let us know when you are finished! Or even if you're willing to share a draft, that would be phenomenal (but I completely understand if you prefer not too). </p>\n<p>I've been following a lot of people in this area and have been using these the techniques to study their quantum variants, and I've constantly been amazed at how much the categorical approach says about the structure of quantum probability as well! </p>\n<p><span class=\"user-mention\" data-user-id=\"285161\">@Oliver Shetler</span> , The notion of disintegration was used to study Bayesian inversion by Culbertson and Sturtz (<a href=\"https://arxiv.org/abs/1205.1488\" title=\"https://arxiv.org/abs/1205.1488\">https://arxiv.org/abs/1205.1488</a>). Besides Jacobs' work, there is also work of Clerc, Danos, Dahlqvist, Garnier, Panangaden, and others who studied disintegration and Bayesian inversion and disintegrations in a way similar to what Panagaden discussed in his talk a few weeks ago (though their earlier articles do not discuss this connection). \"Pointless learning\" is a good place to start and follow that up with \"Bayesian inversion by ω-complete cone duality\" (this last paper has an excellent overview and continues where Panangaden's talk left off). These papers assume you're comfortable with some measure theory and L_p-space stuff though! As you know, Fong's masters thesis is also an excellent place to start (and if I'm not mistaken, that's the first place Bayesian inference was drawn as a string diagram), and where he left off, Cho and Jacobs continued. They introduced a categorical notion of a.e. equivalence, which is crucial for uniqueness results in statistics. Fritz' recent paper (<a href=\"https://arxiv.org/abs/1908.07021\" title=\"https://arxiv.org/abs/1908.07021\">https://arxiv.org/abs/1908.07021</a>) continues from there and is incredibly accessible (and you'll find many open questions there, too!). The general relationship between disintegrations and Bayesian inversion is described in <a href=\"https://arxiv.org/abs/2001.08375\" title=\"https://arxiv.org/abs/2001.08375\">https://arxiv.org/abs/2001.08375</a> (although I focused more on the quantum case, there are some results in the finite, classical setting, many of which I suspect are valid in the standard Borel setting). You'll also find more references in the linked articles. I hope this list isn't overwhelming <span aria-label=\"grimacing\" class=\"emoji emoji-1f62c\" role=\"img\" title=\"grimacing\">:grimacing:</span></p>",
        "id": 195324753,
        "sender_full_name": "Arthur Parzygnat",
        "timestamp": 1587890953
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span>The difficulty with your question is\n that &quot;products of graphs&quot; means\n many different things.  This\n Wikipedia article lists 10 different\n definitions:\n\n* [Graph products](https://en.wikipedia.org/wiki/Graph_product).\n\nBy &quot;connection matrix&quot; I&#39;ll assume\n you mean &quot;[incidence matrix]\n(https://en.wikipedia.org/wiki/Incidence_matrix#Graph_theory)&quot;:\n in graph theory people talk about the incidence matrix of a graph.\n\nSo: I promise you that for *one* of\n the ten listed definitions of &quot;product\n of graph&quot;, the incidence matrix of\n a product of graphs is the tensor\n product of their incidence matrices!\n</pre></div>\n\n\n<p>Wow, there was lot of room for ambiguity here! I should have been clearer by citing my example. I was referring to the category of graphs as defined in Lawvere's Conceptual Mathematics (Where each object is comprised of two sets: Arrows and Objects, with two morphisms Source and Target). And I was referring to the standard categorical product (the terminal object in the category of discrete two-legged cones).</p>",
        "id": 195335393,
        "sender_full_name": "Oliver Shetler",
        "timestamp": 1587908532
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span>(Pro tip: what graph theorists call\n the &quot;tensor product&quot; of graphs is\n what category theorists would call\n the &quot;cartesian product&quot;, or simply\n &quot;product&quot;, of graphs.   But what\n graph theorists call the &quot;cartesian\n product&quot; of graphs is something\n else!  :dizzy:)\n</pre></div>\n\n\n<p>Okay, sounds like there's a whole diverse array of graph products. Thank you for the thorough explanation.</p>\n<p>Thanks for the Wikipedia link. An outline of the proof was sitting there the whole time!</p>",
        "id": 195335665,
        "sender_full_name": "Oliver Shetler",
        "timestamp": 1587908959
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"296639\">@Arthur Parzygnat</span>  Thank you! We should discuss more. Do you use zoom?</p>\n<blockquote>\n<p>I hope this list isn't overwhelming <span aria-label=\"grimacing\" class=\"emoji emoji-1f62c\" role=\"img\" title=\"grimacing\">:grimacing:</span></p>\n</blockquote>\n<p>Nope! This is exactly what I'm asking for! Lit review here I come! 🧐</p>",
        "id": 195335964,
        "sender_full_name": "Oliver Shetler",
        "timestamp": 1587909426
    },
    {
        "content": "<p>Glad to be of help, <span class=\"user-mention\" data-user-id=\"285161\">@Oliver Shetler</span>!   Btw, it looks like you're using the \"code\" format to quote me instead of the quote format, which you invoke by write three left quotes and the word \"quote\" at the start of a line:</p>\n<blockquote>\n<p>giving a quote like this.</p>\n</blockquote>\n<p>If you leave out the word \"quote\" you'll get</p>\n<div class=\"codehilite\"><pre><span></span>something like this.\n</pre></div>",
        "id": 195339985,
        "sender_full_name": "John Baez",
        "timestamp": 1587916179
    },
    {
        "content": "<blockquote>\n<p>Glad to be of help, <span class=\"user-mention silent\" data-user-id=\"285161\">Oliver Shetler</span>!   Btw, it looks like you're using the \"code\" format to quote me instead of the quote format, which you invoke by write three left quotes and the word \"quote\" at the start of a line:</p>\n</blockquote>\n<p>Thanks!</p>",
        "id": 195340105,
        "sender_full_name": "Oliver Shetler",
        "timestamp": 1587916327
    },
    {
        "content": "<p>I'd like to also point out that \"graph products\" is also used to refer to specifying an operation on algebraic gizmos (eg groups) via a simple graph.</p>",
        "id": 195353511,
        "sender_full_name": "Joe Moeller",
        "timestamp": 1587936635
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"285161\">Oliver Shetler</span> <a href=\"#narrow/stream/229156-practice.3A-applied.20ct/topic/causal.20inference/near/195335964\" title=\"#narrow/stream/229156-practice.3A-applied.20ct/topic/causal.20inference/near/195335964\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"296639\">Arthur Parzygnat</span>  Thank you! We should discuss more. Do you use zoom?</p>\n<blockquote>\n<p>I hope this list isn't overwhelming <span aria-label=\"grimacing\" class=\"emoji emoji-1f62c\" role=\"img\" title=\"grimacing\">:grimacing:</span></p>\n</blockquote>\n<p>Nope! This is exactly what I'm asking for! Lit review here I come! 🧐</p>\n</blockquote>\n<p>I've been using it for these seminars, but otherwise I don't use zoom much. Feel free to message me if you have questions.</p>",
        "id": 195356331,
        "sender_full_name": "Arthur Parzygnat",
        "timestamp": 1587940623
    }
]