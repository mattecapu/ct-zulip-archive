[
    {
        "content": "<p>Is there an existing axiomatization of uniform distributions in Markov categories (in which they exist)? I notice Bart Jacobs denotes them with the \"ground\" symbol (the upside-down version of which he uses for deletion) and mentions some basic properties, but I'd expect that there's more to say about the matter. For instance, if G is a group (more generally, a hopf algebra in a Markov cat), then multiplying the identity on G with the uniform distribution  should be equal to discarding the input and just ouptutting the uniform distribution.</p>",
        "id": 240469369,
        "sender_full_name": "Martti Karvonen",
        "timestamp": 1622123117
    },
    {
        "content": "<p>The first thing that came to mind is that a uniform distribution <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>I</mi><mo>→</mo><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">I \\to X</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span></span></span></span> should not be changed by any iso <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi><mo>→</mo><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">X \\to X</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span></span></span></span></p>",
        "id": 240474737,
        "sender_full_name": "Jules Hedges",
        "timestamp": 1622125250
    },
    {
        "content": "<p>True in FinStoch, but in the abstract case I don't have an intuition whether this should hold for all isos or only the deterministic ones.</p>",
        "id": 240475404,
        "sender_full_name": "Martti Karvonen",
        "timestamp": 1622125524
    },
    {
        "content": "<p><a href=\"https://arxiv.org/abs/1102.2368\">Picturing classical and quantum Bayesian inference</a> is one paper that comes to mind. Here, Coecke and Spekkens have axiomatized the category of finite sets with <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi mathvariant=\"double-struck\">R</mi><mo>+</mo></msub></mrow><annotation encoding=\"application/x-tex\">\\mathbb{R}_+</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.897221em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.25833100000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">+</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span></span></span></span>-valued matrices as what we would now call a hypergraph category (plus a dagger). The uniform distributions are encoded as scalar multiples of the counits. So as long as you're dealing with discrete probability only, then Markov categories may not be the right framewok, and the Coecke-Spekkens approach may indeed be the way to go. (Though it may be worth noting that their treatment of conditionals suffers from inconsistencies arising from zero probabilities.) Markov categories on the other hand are intended primarily for measure-theoretic probability, where one can't expect a sensible concept of uniform distribution, and in particular there isn't any probability measure that would be invariant under all deterministic isos. (BTW, isos are necessarily deterministic in most Markov categories of interest, unless you have negative probabilities?)</p>\n<p>On the other hand, there are also good reasons to argue that <em>even in the discrete case</em>, one shouldn't single out any particular distributions as uniform. For example, the distribution <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo separator=\"true\">,</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo separator=\"true\">,</mo><mn>0</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(\\frac{1}{2}, \\frac{1}{2}, 0)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.190108em;vertical-align:-0.345em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">0</span><span class=\"mclose\">)</span></span></span></span> on a three-element set is essentially isomorphic to <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo separator=\"true\">,</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(\\frac{1}{2}, \\frac{1}{2})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.190108em;vertical-align:-0.345em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose\">)</span></span></span></span> on a two-element set. So calling the latter uniform but not the former would do some violence to the spirit of probability, although to what extent this is a problem will of course depend on your context.</p>",
        "id": 240528730,
        "sender_full_name": "Tobias Fritz",
        "timestamp": 1622148289
    },
    {
        "content": "<p>The fact that multiplying with the uniform distribution on a group amounts to discarding the input amounts to this equation:<br>\n<a href=\"/user_uploads/21317/wiCu4ExxMKhDyALJm50XgFyf/haar_integral.png\">haar_integral.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/21317/wiCu4ExxMKhDyALJm50XgFyf/haar_integral.png\" title=\"haar_integral.png\"><img src=\"/user_uploads/21317/wiCu4ExxMKhDyALJm50XgFyf/haar_integral.png\"></a></div>",
        "id": 240531243,
        "sender_full_name": "Tobias Fritz",
        "timestamp": 1622149361
    },
    {
        "content": "<p>(To be read from bottom to top, with the red structure the Hopf algebra multiplication, and the green the Hopf algebra counit respectively the uniform distribution = Haar integral.) This sort of thing is naturally part of the theory of <a href=\"https://arxiv.org/abs/1601.04964\">interacting Frobenius algebras</a>.</p>",
        "id": 240531304,
        "sender_full_name": "Tobias Fritz",
        "timestamp": 1622149387
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276702\">Tobias Fritz</span> <a href=\"#narrow/stream/253118-theory.3A-probability/topic/Uniform.20distributions.20in.20categorical.20probability.3F/near/240531243\">said</a>:</p>\n<blockquote>\n<p>The fact that multiplying with the uniform distribution on a group amounts to discarding the input amounts to this equation:<br>\n<a href=\"/user_uploads/21317/wiCu4ExxMKhDyALJm50XgFyf/haar_integral.png\">haar_integral.png</a></p>\n</blockquote>\n<p>Yeah this is the equation I had doodled before asking - I guess I'd actually like to derive it from some more \"basic\" properties of uniform distributions. However, you're probably right that Markov cats are not the right tool as I mostly care about discrete probability this time. Thanks for the answer!</p>",
        "id": 240597598,
        "sender_full_name": "Martti Karvonen",
        "timestamp": 1622205382
    },
    {
        "content": "<p>What is really cool is that they show that this equation is actually a pullback of matrices.</p>",
        "id": 240600264,
        "sender_full_name": "Cole Comfort",
        "timestamp": 1622206834
    },
    {
        "content": "<p>Now that you mentioned it, you've piqued my interest: if one works with quasiprobabilities of some sort or another, how do the corresponding Markov categories change categorically? You already mentioned the possibility of isos that are not deterministic, is there anything else that stands out at the categorical level?</p>",
        "id": 240601843,
        "sender_full_name": "Martti Karvonen",
        "timestamp": 1622207622
    },
    {
        "content": "<p>Ha, interesting question! The Markov category of stochastic matrices with possibly negative entries behaves quite differently from its nonnegative counterpart <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"sans-serif\">F</mi><mi mathvariant=\"sans-serif\">i</mi><mi mathvariant=\"sans-serif\">n</mi><mi mathvariant=\"sans-serif\">S</mi><mi mathvariant=\"sans-serif\">t</mi><mi mathvariant=\"sans-serif\">o</mi><mi mathvariant=\"sans-serif\">c</mi><mi mathvariant=\"sans-serif\">h</mi></mrow><annotation encoding=\"application/x-tex\">\\mathsf{FinStoch}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathsf\">FinStoch</span></span></span></span></span>, and basically <em>everything</em> breaks down. It doesn't have conditionals. It fails the causality axiom, which says that if<br>\n<a href=\"/user_uploads/21317/vqbf2QvwI6QyC3N1GVYzzyoq/causality1.png\">causality1.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/21317/vqbf2QvwI6QyC3N1GVYzzyoq/causality1.png\" title=\"causality1.png\"><img src=\"/user_uploads/21317/vqbf2QvwI6QyC3N1GVYzzyoq/causality1.png\"></a></div>",
        "id": 240613919,
        "sender_full_name": "Tobias Fritz",
        "timestamp": 1622213101
    },
    {
        "content": "<p>then also<br>\n<a href=\"/user_uploads/21317/pVpoq-GSypjdFFkbmHGnGnoL/causality2.png\">causality2.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/21317/pVpoq-GSypjdFFkbmHGnGnoL/causality2.png\" title=\"causality2.png\"><img src=\"/user_uploads/21317/pVpoq-GSypjdFFkbmHGnGnoL/causality2.png\"></a></div>",
        "id": 240613947,
        "sender_full_name": "Tobias Fritz",
        "timestamp": 1622213114
    },
    {
        "content": "<p>and it fails the positivity axiom, which says that if a composite <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>g</mi><mi>f</mi></mrow><annotation encoding=\"application/x-tex\">gf</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span></span></span></span> is deterministic, then also<br>\n<a href=\"user_uploads/21317/pvpmf_4TjBejr3kLMBIkh-vu/positivity.png\">positivity.png</a></p>\n<div class=\"message_inline_image\"><a href=\"user_uploads/21317/pvpmf_4TjBejr3kLMBIkh-vu/positivity.png\" title=\"positivity.png\"><img src=\"user_uploads/21317/pvpmf_4TjBejr3kLMBIkh-vu/positivity.png\"></a></div>",
        "id": 240614069,
        "sender_full_name": "Tobias Fritz",
        "timestamp": 1622213163
    },
    {
        "content": "<p>However, these failures are not independent, since conditionals implies causality implies positivity (where the last implication was proven only recently by <span class=\"user-mention\" data-user-id=\"309295\">@Dario Stein</span>). So it's really only the failure of positivity, and that's why I had called that condition the \"positivity axiom\".</p>",
        "id": 240614204,
        "sender_full_name": "Tobias Fritz",
        "timestamp": 1622213233
    },
    {
        "content": "<p>This from <span class=\"user-mention\" data-user-id=\"277067\">@Tom Leinster</span> may be of relevance: <a href=\"https://golem.ph.utexas.edu/category/2020/11/the_uniform_measure.html\">https://golem.ph.utexas.edu/category/2020/11/the_uniform_measure.html</a></p>",
        "id": 241372846,
        "sender_full_name": "Eigil Rischel",
        "timestamp": 1622716376
    }
]