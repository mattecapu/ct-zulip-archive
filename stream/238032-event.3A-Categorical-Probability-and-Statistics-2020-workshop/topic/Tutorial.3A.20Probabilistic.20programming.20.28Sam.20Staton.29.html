<!DOCTYPE html>
<html>
<head>
  	<meta charset="utf-8" />
  	<meta http-equiv="X-UA-Compatible" content="IE=edge" />
  	<meta name="viewport" content="width=device-width, initial-scale=1" />
  
<link rel="stylesheet" href="https://mattecapu.github.io/ct-zulip-archive/style.css" /><title>Tutorial: Probabilistic programming (Sam Staton) · event: Categorical Probability and Statistics 2020 workshop · Zulip Chat Archive</title>
</head>
<body>
<header>
<a href="https://mattecapu.github.io/ct-zulip-archive" class="home-link">
        <img class="logo" src="https://zulip-avatars.s3.amazonaws.com/21317/realm/icon.png?version=3" />
        <h1>Category Theory<br/>Zulip Server<br/>Archive</h1>
        </a>
        <p>
        You're reading the public-facing archive of the <a href="https://categorytheory.zulipchat.com/">Category Theory Zulip server</a>.<br/>
        
        To join the server you need an invite. Anybody can get an invite by contacting <a href="https://matteocapucci.wordpress.com">Matteo Capucci</a> at <em>name dot surname at gmail dot com</em>.<br/>
        
        For all things related to this archive refer to the same person.
        </p>
        </header>
        <hr />
    
<h2>Stream: <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/index.html">event: Categorical Probability and Statistics 2020 workshop</a></h2>
<h3>Topic: <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Tutorial.3A.20Probabilistic.20programming.20.28Sam.20Staton.29.html">Tutorial: Probabilistic programming (Sam Staton)</a></h3>

<hr>

<base href="https://categorytheory.zulipchat.com">

<a name="199412771"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Tutorial%3A%20Probabilistic%20programming%20%28Sam%20Staton%29/near/199412771" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Paolo Perrone <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Tutorial.3A.20Probabilistic.20programming.20.28Sam.20Staton.29.html#199412771">(Jun 01 2020 at 19:32)</a>:</h4>
<p>Hello! Here's Sam Staton's tutorial video, a categorical tutorial about probabilistic programming.<br>
<a href="https://youtu.be/JimCpEG0nts">https://youtu.be/JimCpEG0nts</a><br>
Any questions about the video go in this thread!</p>
<div class="youtube-video message_inline_image"><a data-id="JimCpEG0nts" href="https://youtu.be/JimCpEG0nts"><img src="https://i.ytimg.com/vi/JimCpEG0nts/default.jpg"></a></div>



<a name="199426772"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Tutorial%3A%20Probabilistic%20programming%20%28Sam%20Staton%29/near/199426772" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Tobias Fritz <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Tutorial.3A.20Probabilistic.20programming.20.28Sam.20Staton.29.html#199426772">(Jun 01 2020 at 21:32)</a>:</h4>
<p>That is a great talk, Sam! I have a few questions if you don't mind.</p>
<ul>
<li>Could you elaborate a bit on why you prefer thinking of the/a category of probability kernels as a multicategory rather than a symmetric monoidal category?</li>
<li>What are the main differences between different probabilistic programming languages? How much do they differ with respect to which kernels can be defined?</li>
<li>With the question about whether s-finite kernels form a Kleisli category, are you considering all measurable spaces as objects? Or only a subclass like Polish spaces?</li>
</ul>



<a name="199500905"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Tutorial%3A%20Probabilistic%20programming%20%28Sam%20Staton%29/near/199500905" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sam Staton <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Tutorial.3A.20Probabilistic.20programming.20.28Sam.20Staton.29.html#199500905">(Jun 02 2020 at 14:32)</a>:</h4>
<p>Hi Tobias!</p>
<p><span class="user-mention silent" data-user-id="276702">Tobias Fritz</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Tutorial.3A.20Probabilistic.20programming.20(Sam.20Staton)/near/199426772">said</a>:<br>
<code>Could you elaborate a bit on why you prefer thinking of the/a category of probability kernels as a multicategory rather than a symmetric monoidal category?</code></p>
<ul>
<li>It's not a big deal in the big picture, but the fact that they do form a multicategory / monoidal category relies on Fubini's theorem, which is perhaps slightly clearer in the multicategory formulation. Also I think that in general programming language / type theory syntax is closer to multicategories than to monoidal categories.</li>
</ul>
<p><code>What are the main differences between different probabilistic programming languages? How much do they differ with respect to which kernels can be defined?</code></p>
<p>I'll just list some:</p>
<ul>
<li>Some of the languages are lisp-based and untyped, which means even understanding programs as probability kernels is very difficult. </li>
<li>Some languages are really good for certain inference algorithms, which leads to some restrictions. e.g. Stan is really good for Hamiltonian Monte Carlo simulation, which means you're supposed to only build differentiable densities, and you have to go round the houses to make a mixture model.  Infer.Net is really good for variational message passing, but that means you have to use distribution families carefully. </li>
<li>Some languages (like Pyro) interface with GPU code, allowing us to work with variational autoencoders from a probabilistic programming viewpoint</li>
<li>Some languages (like Pyro and Gen) have  facilities for tying a clean model to a more intricate inference set-up. For example, in variational inference you might tie bits of your model to different things in a "guide" for a posterior, and for Metropolis Hastings you might specify a particular proposal if you expect things to correlate in a certain way. I think this is really important ongoing work. </li>
<li>Some languages support non-parametric features to a greater or lesser extent. Personally I find this fascinating. </li>
</ul>
<p><code>With the question about whether s-finite kernels form a Kleisli category, are you considering all measurable spaces as objects? Or only a subclass like Polish spaces?</code></p>
<ul>
<li>Several of us have tried both questions -- all measurable spaces, and just the standard Borel spaces -- and we have no answers. <br>
(I do know that they can be made into a Kleisli category over quasi-Borel spaces, but that's almost cheating.)</li>
</ul>



<a name="199518613"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Tutorial%3A%20Probabilistic%20programming%20%28Sam%20Staton%29/near/199518613" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Tobias Fritz <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Tutorial.3A.20Probabilistic.20programming.20.28Sam.20Staton.29.html#199518613">(Jun 02 2020 at 16:31)</a>:</h4>
<p>Very interesting, thanks! Yes, I see the point about the de Finetti theorem having more of a multicategorical flavour.</p>
<p>Out of curiosity: to what extent are you a user and/or developer of probabilistic programming languages, in addition to studying them at the theoretical level?</p>



<a name="199523746"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Tutorial%3A%20Probabilistic%20programming%20%28Sam%20Staton%29/near/199523746" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Paolo Perrone <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Tutorial.3A.20Probabilistic.20programming.20.28Sam.20Staton.29.html#199523746">(Jun 02 2020 at 17:12)</a>:</h4>
<p>David Myers once made me notice that lax monoidal functors, as opposed to strong, are naturally the morphisms not quite of monoidal categories, but rather of the underlying multicategories. If the structural functors that appear on probability kernels tend to be lax monoidal instead of strong (the underlying functor to the probability monad certainly is in this form), this could be an additional witness that "really Fubini is about multicategories".</p>



<a name="199525991"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Tutorial%3A%20Probabilistic%20programming%20%28Sam%20Staton%29/near/199525991" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Oscar Cunningham <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Tutorial.3A.20Probabilistic.20programming.20.28Sam.20Staton.29.html#199525991">(Jun 02 2020 at 17:30)</a>:</h4>
<p>Why is it more natural for a functor between multicategories rather than monoidal categories to be lax?</p>



<a name="199533890"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Tutorial%3A%20Probabilistic%20programming%20%28Sam%20Staton%29/near/199533890" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Paolo Perrone <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Tutorial.3A.20Probabilistic.20programming.20.28Sam.20Staton.29.html#199533890">(Jun 02 2020 at 18:30)</a>:</h4>
<p><span class="user-mention silent" data-user-id="276945">Oscar Cunningham</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Tutorial.3A.20Probabilistic.20programming.20(Sam.20Staton)/near/199525991">said</a>:</p>
<blockquote>
<p>Why is it more natural for a functor between multicategories rather than monoidal categories to be lax?</p>
</blockquote>
<p>The idea is that if T is lax monoidal, then it canonically maps a morphism f: A x B -&gt; C to a morphism TA x TB -&gt; TC.</p>



<a name="199535776"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Tutorial%3A%20Probabilistic%20programming%20%28Sam%20Staton%29/near/199535776" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sam Staton <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Tutorial.3A.20Probabilistic.20programming.20.28Sam.20Staton.29.html#199535776">(Jun 02 2020 at 18:45)</a>:</h4>
<p><span class="user-mention silent" data-user-id="276702">Tobias Fritz</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Tutorial.3A.20Probabilistic.20programming.20(Sam.20Staton)/near/199518613">said</a>:</p>
<blockquote>
<p>to what extent are you a user and/or developer of probabilistic programming languages</p>
</blockquote>
<p>I dabble a bit, mainly because I'm interested to know what could be useful. I'm involved in a project with some social scientists on analyzing hate events on twitter and I've been writing probabilistic programs for that.</p>



<a name="199683270"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Tutorial%3A%20Probabilistic%20programming%20%28Sam%20Staton%29/near/199683270" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Tomáš Gonda <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Tutorial.3A.20Probabilistic.20programming.20.28Sam.20Staton.29.html#199683270">(Jun 03 2020 at 22:08)</a>:</h4>
<p>Hi Sam, thanks for the tutorial! I was a bit confused by the first example (4 buses in an hour) of the weighted Monte Carlo, so let me rephrase it to check if I got it right:</p>
<ul>
<li>There is no actual "simulation" going on. The algorithm just samples from a uniform distribution and then scores each sample with the likelihood that on the given sampled day, one would see 4 buses. In the end, one then counts the weighted proportion of samples corresponding to a given hypothesis to get a posterior.</li>
</ul>
<p>I think what threw me off at first was the naive intuition that, in this example, somehow the most 'complicated' part of the calculation is computing the likelihood. Therefore, I was subconsciously expecting the simulation to be approximating that, but then the likelihoods just entered as an input to the algorithm.</p>



<a name="199706843"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Tutorial%3A%20Probabilistic%20programming%20%28Sam%20Staton%29/near/199706843" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sam Staton <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Tutorial.3A.20Probabilistic.20programming.20.28Sam.20Staton.29.html#199706843">(Jun 04 2020 at 05:33)</a>:</h4>
<p>Hi! Good question. <span class="user-mention silent" data-user-id="302756">Tomáš Gonda</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Tutorial.3A.20Probabilistic.20programming.20(Sam.20Staton)/near/199683270">said</a>:</p>
<blockquote>
<p>The [weighted Monte Carlo] algorithm just samples from a uniform distribution and then scores each sample with the likelihood that on the given sampled day, one would see 4 buses. In the end, one then counts the weighted proportion of samples corresponding to a given hypothesis to get a posterior.</p>
</blockquote>
<p>That's exactly right. (The example is very simple, and in practice you would be sampling from a more interesting prior.)</p>
<blockquote>
<p>somehow the most 'complicated' part of the calculation is computing the likelihood</p>
</blockquote>
<p>Indeed, there are various approaches to automatically converting a generative model into a density / likelihood function. But here I assume that the likelihood function is given to us (the Poisson density), and that is often the approach taken in probabilistic programming in practice.</p>



<a name="199863094"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Tutorial%3A%20Probabilistic%20programming%20%28Sam%20Staton%29/near/199863094" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Arthur Parzygnat <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Tutorial.3A.20Probabilistic.20programming.20.28Sam.20Staton.29.html#199863094">(Jun 05 2020 at 11:26)</a>:</h4>
<p>Thanks for your talk! I have some very basic questions. Let <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>:</mo><mo>=</mo><mi>A</mi><mo>×</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">X:=A\times B</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault">A</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span></span></span></span> be the space describing the values <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">a</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">b</span></span></span></span> in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mi>a</mi><mo>+</mo><mi>b</mi><mi>x</mi></mrow><annotation encoding="application/x-tex">y=a+bx</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault">a</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">b</span><span class="mord mathdefault">x</span></span></span></span>, so it's the space parametrizing affine maps from <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="double-struck">R</mi></mrow><annotation encoding="application/x-tex">\mathbb{R}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68889em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbb">R</span></span></span></span></span> to itself. Given a fixed <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(a,b)</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mclose">)</span></span></span></span>, it is not guaranteed that when an observation is made, the values will all lie along a straight line. If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi></mrow><annotation encoding="application/x-tex">O</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span></span></span></span> denotes the observation space, then this is described by a Markov kernel <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>⇝</mo><mi>O</mi></mrow><annotation encoding="application/x-tex">X\rightsquigarrow O</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel amsrm">⇝</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span></span></span></span>. If we assume that there is a definite value of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(a,b)</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mclose">)</span></span></span></span> then this corresponds to a Dirac delta measure <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mo>∙</mo><mo stretchy="false">}</mo><mo>→</mo><mi>X</mi></mrow><annotation encoding="application/x-tex">\{\bullet\}\rightarrow X</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord">∙</span><span class="mclose">}</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span></span></span></span>. We can push forward this measure to get one on the observation space <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi></mrow><annotation encoding="application/x-tex">O</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span></span></span></span> which is describing the probabilities of witnessing certain observations. But what is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi></mrow><annotation encoding="application/x-tex">O</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span></span></span></span> exactly in this example? If we have <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">n</span></span></span></span> observed data points, is it just <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mo>∐</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mi mathvariant="double-struck">R</mi></mrow><annotation encoding="application/x-tex">\coprod_{i=1}^{n}\mathbb{R}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1.104002em;vertical-align:-0.29971000000000003em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∐</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.804292em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathbb">R</span></span></span></span></span>? (the disjoint union of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">n</span></span></span></span> copies of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="double-struck">R</mi></mrow><annotation encoding="application/x-tex">\mathbb{R}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68889em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbb">R</span></span></span></span></span>)? If so, to obtain the posterior that you plotted visually as a collection of straight lines, we apply Bayesian inversion to produce the associated Markov kernel  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo>⇝</mo><mi>A</mi><mo>×</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">O\rightsquigarrow A\times B</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel amsrm">⇝</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault">A</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span></span></span></span> having witnessed the specific observation of data?</p>



<a name="199873936"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Tutorial%3A%20Probabilistic%20programming%20%28Sam%20Staton%29/near/199873936" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Sam Staton <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Tutorial.3A.20Probabilistic.20programming.20.28Sam.20Staton.29.html#199873936">(Jun 05 2020 at 13:15)</a>:</h4>
<p>Hi <span class="user-mention silent" data-user-id="296639">Arthur Parzygnat</span>. I think <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo>=</mo><mo stretchy="false">(</mo><msup><mi mathvariant="double-struck">R</mi><mn>2</mn></msup><msup><mo stretchy="false">)</mo><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">O=(\mathbb{R}^2)^n</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span></span></span></span></span></span></span>, if there are $n$ observations in the plane. But maybe I misunderstood your notation?</p>



<a name="199888896"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Tutorial%3A%20Probabilistic%20programming%20%28Sam%20Staton%29/near/199888896" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Arthur Parzygnat <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Tutorial.3A.20Probabilistic.20programming.20.28Sam.20Staton.29.html#199888896">(Jun 05 2020 at 15:01)</a>:</h4>
<p><span class="user-mention" data-user-id="308397">@Sam Staton</span>  Ah, I assumed that because the x values are only natural numbers then you get the disjoint union. But yes, if you allow arbitrary x positions, then yes. Okay, but it's good to know we agree.</p>



<footer class="site-footer">

<hr><p>Last updated: Nov 01 2025 at 12:09 UTC</p>
This archive runs on a customization of <a href="https://github.com/zulip/zulip-archive">zulip-archive</a>
</footer>
</body>

</html>