<!DOCTYPE html>
<html>
<head>
  	<meta charset="utf-8" />
  	<meta http-equiv="X-UA-Compatible" content="IE=edge" />
  	<meta name="viewport" content="width=device-width, initial-scale=1" />
  
<link rel="stylesheet" href="https://mattecapu.github.io/ct-zulip-archive/style.css" /><title>Jun 6: Paolo Perrone&#x27;s talk · event: Categorical Probability and Statistics 2020 workshop · Zulip Chat Archive</title>
</head>
<body>
<header>
<a href="https://mattecapu.github.io/ct-zulip-archive" class="home-link">
        <img class="logo" src="https://zulip-avatars.s3.amazonaws.com/21317/realm/icon.png?version=3" />
        <h1>Category Theory<br/>Zulip Server<br/>Archive</h1>
        </a>
        <p>
        You're reading the public-facing archive of the <a href="https://categorytheory.zulipchat.com/">Category Theory Zulip server</a>.<br/>
        
        To join the server you need an invite. Anybody can get an invite by contacting <a href="https://matteocapucci.wordpress.com">Matteo Capucci</a> at <em>name dot surname at gmail dot com</em>.<br/>
        
        For all things related to this archive refer to the same person.
        </p>
        </header>
        <hr />
    
<h2>Stream: <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/index.html">event: Categorical Probability and Statistics 2020 workshop</a></h2>
<h3>Topic: <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html">Jun 6: Paolo Perrone&#x27;s talk</a></h3>

<hr>

<base href="https://categorytheory.zulipchat.com">

<a name="199794284"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/199794284" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Paolo Perrone <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#199794284">(Jun 04 2020 at 19:12)</a>:</h4>
<p>Hey all,<br>
This is the discussion thread of my talk, "Probability monads and stochastic dominance".<br>
The talk, besides being on Zoom, is livestreamed here: <a href="https://youtu.be/kKDMCDUaxxE">https://youtu.be/kKDMCDUaxxE</a></p>
<div class="youtube-video message_inline_image"><a data-id="kKDMCDUaxxE" href="https://youtu.be/kKDMCDUaxxE"><img src="https://i.ytimg.com/vi/kKDMCDUaxxE/default.jpg"></a></div>



<a name="199796139"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/199796139" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Paolo Perrone <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#199796139">(Jun 04 2020 at 19:24)</a>:</h4>
<p>Date and time: Saturday, 6 Jun, 15h UTC.</p>



<a name="199977588"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/199977588" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Paolo Perrone <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#199977588">(Jun 06 2020 at 14:30)</a>:</h4>
<p>Hi! We start in 30 minutes.</p>



<a name="199981512"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/199981512" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Joscha Diehl <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#199981512">(Jun 06 2020 at 15:57)</a>:</h4>
<p>Great talk.<br>
Can you say something about the bar construction mentioned in the abstract?</p>



<a name="199981569"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/199981569" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Joshua Meyers <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#199981569">(Jun 06 2020 at 15:58)</a>:</h4>
<p>Do these ideas have anything to say about deciding between two investments p, q with nonzero probability of both p&lt;=q and p&gt;q, on the basis of expected return and risk?</p>



<a name="199981577"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/199981577" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Peter Arndt <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#199981577">(Jun 06 2020 at 15:59)</a>:</h4>
<p>Yes, great talk!<br>
Is there a formal formulation for this process of "moving the mass"? Maybe pullback along projetion and then pushforward?</p>



<a name="199981732"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/199981732" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Tomáš Gonda <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#199981732">(Jun 06 2020 at 16:02)</a>:</h4>
<p>I am wondering what is the main reason for considering order isomorphisms rather than homomorphisms for the complete metric space case? That is, why do we exclude coarse-grainings (of the order information)? Is (one) reason that we would be mixing up the first-order and second-order dominance (since the latter is related to coarse-grainings)?</p>



<a name="199982005"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/199982005" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Tomáš Gonda <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#199982005">(Jun 06 2020 at 16:09)</a>:</h4>
<p>A more exotic question: Is there a chance to have a unified treatment (which is still sufficiently expressive) of both first-order and second-order dominance at some level of abstraction? There are parallels between them, but also some important differences.</p>



<a name="199984868"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/199984868" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Paolo Perrone <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#199984868">(Jun 06 2020 at 17:18)</a>:</h4>
<p><span class="user-mention silent" data-user-id="303393">Joscha Diehl</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199981512">said</a>:</p>
<blockquote>
<p>Great talk.<br>
Can you say something about the bar construction mentioned in the abstract?</p>
</blockquote>
<p><span class="user-mention" data-user-id="303393">@Joscha Diehl</span>  Thanks! Yep. The maps <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi></mrow><annotation encoding="application/x-tex">E</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">P e</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault">e</span></span></span></span> which give the equivalent characterization to second-order stochastic dominance are exactly the source and target maps of 1-simplices in the bar construction. This turns out to be quite structural!<br>
There's quite a bit to talk about - if you want I can expand. For now, two references are Chapter 4 of my thesis, and my MFPS talk here: <a href="https://youtu.be/28EASeG1RBA">https://youtu.be/28EASeG1RBA</a> (paper here: <a href="https://arxiv.org/abs/1810.06037">https://arxiv.org/abs/1810.06037</a>)</p>
<div class="youtube-video message_inline_image"><a data-id="28EASeG1RBA" href="https://youtu.be/28EASeG1RBA"><img src="https://i.ytimg.com/vi/28EASeG1RBA/default.jpg"></a></div>



<a name="199984876"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/199984876" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Paolo Perrone <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#199984876">(Jun 06 2020 at 17:18)</a>:</h4>
<p>By the way, here's the link to my thesis: <a href="http://paoloperrone.org/phdthesis.pdf">http://paoloperrone.org/phdthesis.pdf</a></p>



<a name="199985065"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/199985065" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Paolo Perrone <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#199985065">(Jun 06 2020 at 17:24)</a>:</h4>
<p><span class="user-mention silent" data-user-id="280784">Joshua Meyers</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199981569">said</a>:</p>
<blockquote>
<p>Do these ideas have anything to say about deciding between two investments p, q with nonzero probability of both p&lt;=q and p&gt;q, on the basis of expected return and risk?</p>
</blockquote>
<p>If I understand you correctly, yes. So one can prove that if we are over a <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span></span></span></span>-algebras, for example real numbers, then if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span></span></span></span> is lower than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span> in the stochastic order, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span></span></span></span> has lower expectation value than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span> - this expectation map is even <em>strictly</em> monotone. <br>
For what concerns risk, the second-order stochastic dominance is precisely the "riskiness". One can also use the two orders together, and that's sometimes also called second-order stochastic dominance. I can expand on this, if you want. In any case if you want a reference, this is worked out in my thesis, the link is above.</p>



<a name="199985116"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/199985116" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Paolo Perrone <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#199985116">(Jun 06 2020 at 17:25)</a>:</h4>
<p><span class="user-mention silent" data-user-id="303936">Peter Arndt</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199981577">said</a>:</p>
<blockquote>
<p>Yes, great talk!<br>
Is there a formal formulation for this process of "moving the mass"? Maybe pullback along projetion and then pushforward?</p>
</blockquote>
<p>Yes, but in general it's a <em>random</em> transport map, not a deterministic one. In the sense that the mass over a certain point may be split, and sent to two different points.</p>



<a name="199985180"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/199985180" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Paolo Perrone <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#199985180">(Jun 06 2020 at 17:27)</a>:</h4>
<p><span class="user-mention silent" data-user-id="302756">Tomáš Gonda</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199981732">said</a>:</p>
<blockquote>
<p>I am wondering what is the main reason for considering order isomorphisms rather than homomorphisms for the complete metric space case? That is, why do we exclude coarse-grainings (of the order information)? Is (one) reason that we would be mixing up the first-order and second-order dominance (since the latter is related to coarse-grainings)?</p>
</blockquote>
<p>Oh, we are not using only order isomorphisms, but homomorphisms. We can coarse-grain all we want. Only the unit of the monad (the Dirac delta) happens to be an order-embedding, everything else is not. Sorry if that wasn't clear!</p>



<a name="199985238"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/199985238" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Paolo Perrone <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#199985238">(Jun 06 2020 at 17:28)</a>:</h4>
<p><span class="user-mention silent" data-user-id="302756">Tomáš Gonda</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199982005">said</a>:</p>
<blockquote>
<p>A more exotic question: Is there a chance to have a unified treatment (which is still sufficiently expressive) of both first-order and second-order dominance at some level of abstraction? There are parallels between them, but also some important differences.</p>
</blockquote>
<p>Yep, there is, unfortunately I didn't have time to talk about that. It even satisfies a very nice universal property, it's a "lax codescent object". A way to obtain this composite order is to take the coinserter of the two maps <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mo separator="true">,</mo><mi>T</mi><mi>e</mi><mo>:</mo><mi>P</mi><mi>A</mi><mo>→</mo><mi>A</mi></mrow><annotation encoding="application/x-tex">E, Te:PA\to A</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault">e</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault">A</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">A</span></span></span></span>. I can expand on this, if you want.</p>



<a name="199985382"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/199985382" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Tomáš Gonda <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#199985382">(Jun 06 2020 at 17:32)</a>:</h4>
<p><span class="user-mention silent" data-user-id="275989">Paolo Perrone</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199985180">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="302756">Tomáš Gonda</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199981732">said</a>:</p>
<blockquote>
<p>I am wondering what is the main reason for considering order isomorphisms rather than homomorphisms for the complete metric space case? That is, why do we exclude coarse-grainings (of the order information)? Is (one) reason that we would be mixing up the first-order and second-order dominance (since the latter is related to coarse-grainings)?</p>
</blockquote>
<p>Oh, we are not using only order isomorphisms, but homomorphisms. We can coarse-grain all we want. Only the unit of the monad (the Dirac delta) happens to be an order-embedding, everything else is not. Sorry if that wasn't clear!</p>
</blockquote>
<p>hm, ok, so what was the extra property of morphisms in COMet besides being order-preserving and 1-Lipschitz?</p>



<a name="199985468"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/199985468" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Tomáš Gonda <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#199985468">(Jun 06 2020 at 17:35)</a>:</h4>
<p><span class="user-mention silent" data-user-id="275989">Paolo Perrone</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199985238">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="302756">Tomáš Gonda</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199982005">said</a>:</p>
<blockquote>
<p>A more exotic question: Is there a chance to have a unified treatment (which is still sufficiently expressive) of both first-order and second-order dominance at some level of abstraction? There are parallels between them, but also some important differences.</p>
</blockquote>
<p>Yep, there is, unfortunately I didn't have time to talk about that. It even satisfies a very nice universal property, it's a "lax codescent object". A way to obtain this composite order is to take the coinserter of the two maps <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mo separator="true">,</mo><mi>T</mi><mi>e</mi><mo>:</mo><mi>P</mi><mi>A</mi><mo>→</mo><mi>A</mi></mrow><annotation encoding="application/x-tex">E, Te:PA\to A</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault">e</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault">A</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">A</span></span></span></span>. I can expand on this, if you want.</p>
</blockquote>
<p>That sounds intriguing (although probably slightly different to what I actually had in mind). Does it give you the "combined" order (i.e. the intersection of the two order relations)? I would love to know more about that, is it in some of your articles?</p>



<a name="199987919"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/199987919" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Paolo Perrone <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#199987919">(Jun 06 2020 at 18:44)</a>:</h4>
<p><span class="user-mention silent" data-user-id="302756">Tomáš Gonda</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199985382">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="275989">Paolo Perrone</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199985180">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="302756">Tomáš Gonda</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199981732">said</a>:</p>
<blockquote>
<p>I am wondering what is the main reason for considering order isomorphisms rather than homomorphisms for the complete metric space case? That is, why do we exclude coarse-grainings (of the order information)? Is (one) reason that we would be mixing up the first-order and second-order dominance (since the latter is related to coarse-grainings)?</p>
</blockquote>
<p>Oh, we are not using only order isomorphisms, but homomorphisms. We can coarse-grain all we want. Only the unit of the monad (the Dirac delta) happens to be an order-embedding, everything else is not. Sorry if that wasn't clear!</p>
</blockquote>
<p>hm, ok, so what was the extra property of morphisms in COMet besides being order-preserving and 1-Lipschitz?</p>
</blockquote>
<p>That's not on the morphisms, it's on the orders. It's definition 4.1.1 in this paper: <a href="https://arxiv.org/abs/1808.09898">https://arxiv.org/abs/1808.09898</a><br>
It says that 1-Lipschitz monotone functions are "enough to tell the order", the order is never too "steep". Example 4.1.2 there gives a space which does not satisfy that property.</p>



<a name="199987935"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/199987935" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Paolo Perrone <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#199987935">(Jun 06 2020 at 18:45)</a>:</h4>
<p>By the way, we called those spaces "L-ordered" in honor of Lawvere - I should have said that since he was in the audience!</p>



<a name="199988019"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/199988019" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Paolo Perrone <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#199988019">(Jun 06 2020 at 18:47)</a>:</h4>
<p><span class="user-mention silent" data-user-id="302756">Tomáš Gonda</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199985468">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="275989">Paolo Perrone</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199985238">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="302756">Tomáš Gonda</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199982005">said</a>:</p>
<blockquote>
<p>A more exotic question: Is there a chance to have a unified treatment (which is still sufficiently expressive) of both first-order and second-order dominance at some level of abstraction? There are parallels between them, but also some important differences.</p>
</blockquote>
<p>Yep, there is, unfortunately I didn't have time to talk about that. It even satisfies a very nice universal property, it's a "lax codescent object". A way to obtain this composite order is to take the coinserter of the two maps <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mo separator="true">,</mo><mi>T</mi><mi>e</mi><mo>:</mo><mi>P</mi><mi>A</mi><mo>→</mo><mi>A</mi></mrow><annotation encoding="application/x-tex">E, Te:PA\to A</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault">e</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault">A</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">A</span></span></span></span>. I can expand on this, if you want.</p>
</blockquote>
<p>That sounds intriguing (although probably slightly different to what I actually had in mind). Does it give you the "combined" order (i.e. the intersection of the two order relations)? I would love to know more about that, is it in some of your articles?</p>
</blockquote>
<p>Oh, I think I see what you meant in your original question. I'd love to find a uniform treatment - so far we weren.t able to find it except pretty much for what I said during the talk. I suspect one can do this in Markov categories with conditionals though.<br>
If you want to know more about the combined order, see Section 4.3 of my thesis (link above). Hopefully it will become a paper soon.</p>



<a name="199988296"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/199988296" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Tomáš Gonda <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#199988296">(Jun 06 2020 at 18:55)</a>:</h4>
<p><span class="user-mention silent" data-user-id="275989">Paolo Perrone</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199987919">said</a>:</p>
<blockquote>
<p>That's not on the morphisms, it's on the orders. It's definition 4.1.1 in this paper: <a href="https://arxiv.org/abs/1808.09898">https://arxiv.org/abs/1808.09898</a><br>
It says that 1-Lipschitz monotone functions are "enough to tell the order", the order is never too "steep". Example 4.1.2 there gives a space which does not satisfy that property.</p>
</blockquote>
<p>oh, that makes a lot of sense, thanks! I must have had a brief attention glitch while you were explaining it <span aria-label="sleeping" class="emoji emoji-1f634" role="img" title="sleeping">:sleeping:</span></p>



<a name="199992095"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/199992095" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Tomáš Gonda <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#199992095">(Jun 06 2020 at 20:37)</a>:</h4>
<p><span class="user-mention silent" data-user-id="275989">Paolo Perrone</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199988019">said</a>:</p>
<blockquote>
<p>Oh, I think I see what you meant in your original question. I'd love to find a uniform treatment - so far we weren.t able to find it except pretty much for what I said during the talk. I suspect one can do this in Markov categories with conditionals though.<br>
If you want to know more about the combined order, see Section 4.3 of my thesis (link above). Hopefully it will become a paper soon.</p>
</blockquote>
<p>I guess one way to interpret what I'd like to have from my (biased) perspective is finding a class of resource theories that would have enough structure to allow one to prove classification theorems about their resource orderings and which would include, as special cases, the first-order and second-order stochastic dominance among other preorders.</p>



<a name="199995635"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/199995635" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Joshua Meyers <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#199995635">(Jun 06 2020 at 22:19)</a>:</h4>
<p><span class="user-mention silent" data-user-id="275989">Paolo Perrone</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199985065">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="280784">Joshua Meyers</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199981569">said</a>:</p>
<blockquote>
<p>Do these ideas have anything to say about deciding between two investments p, q with nonzero probability of both p&lt;=q and p&gt;q, on the basis of expected return and risk?</p>
</blockquote>
<p>If I understand you correctly, yes. So one can prove that if we are over a <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span></span></span></span>-algebras, for example real numbers, then if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span></span></span></span> is lower than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span> in the stochastic order, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span></span></span></span> has lower expectation value than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span> - this expectation map is even <em>strictly</em> monotone. <br>
For what concerns risk, the second-order stochastic dominance is precisely the "riskiness". One can also use the two orders together, and that's sometimes also called second-order stochastic dominance. I can expand on this, if you want. In any case if you want a reference, this is worked out in my thesis, the link is above.</p>
</blockquote>
<p>Yes but if the events p&lt;=q and p&gt;q both have nonzero probability, then neither has first-order stochastic dominance over the other, as you have defined it.  And second-order stochastic dominance doesn't even apply, as they are not about "the same data".</p>
<p>Yes p&lt;=q in the stochastic order implies that E(p)&lt;=E(q), but not conversely.</p>
<p>Update:  I should have said that the events p&lt;q and q&lt;p both have nonzero probability, sorry for the confusion.</p>



<a name="199996921"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/199996921" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Paolo Perrone <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#199996921">(Jun 06 2020 at 22:59)</a>:</h4>
<p><span class="user-mention silent" data-user-id="280784">Joshua Meyers</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199995635">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="275989">Paolo Perrone</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199985065">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="280784">Joshua Meyers</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199981569">said</a>:</p>
<blockquote>
<p>Do these ideas have anything to say about deciding between two investments p, q with nonzero probability of both p&lt;=q and p&gt;q, on the basis of expected return and risk?</p>
</blockquote>
<p>If I understand you correctly, yes. So one can prove that if we are over a <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span></span></span></span>-algebras, for example real numbers, then if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span></span></span></span> is lower than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span> in the stochastic order, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span></span></span></span> has lower expectation value than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span> - this expectation map is even <em>strictly</em> monotone. <br>
For what concerns risk, the second-order stochastic dominance is precisely the "riskiness". One can also use the two orders together, and that's sometimes also called second-order stochastic dominance. I can expand on this, if you want. In any case if you want a reference, this is worked out in my thesis, the link is above.</p>
</blockquote>
<p>Yes but if the events p&lt;=q and p&gt;q both have nonzero probability, then neither has first-order stochastic dominance over the other, as you have defined it.  And second-order stochastic dominance doesn't even apply, as they are not about "the same data".</p>
<p>Yes p&lt;=q in the stochastic order implies that E(p)&lt;=E(q), but not conversely.</p>
<p>Update:  I should have said that the events p&lt;q and q&lt;p both have nonzero probability, sorry for the confusion.</p>
</blockquote>
<p>Uhm, I think I don't understand. There are (at least) 2 orders that one can construct, first and second order stochastic dominance, and their composite order as well. What is the question exactly, possibly in other words?</p>



<a name="199997274"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/199997274" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Tobias Fritz <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#199997274">(Jun 06 2020 at 23:08)</a>:</h4>
<p>Perhaps Joshua is talking about the pointwise order on random variables that Paolo spoke about at the beginning? Joshua, what do you mean by the probability of the event p&lt;=q?</p>
<p>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span> are just probability measures on an ordered space, then it makes sense to try and compare them with respect to first-order stochastic dominance, even if no joint distribution is given, meaning that even if we cannot talk about the probability of "the event <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>≥</mo><mi>q</mi></mrow><annotation encoding="application/x-tex">p \ge q</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.8304100000000001em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span>". So you should think of it like this: if someone offers you a bet with 50:50 odds and someone else offers you one with 80:20 odds against you, then you'd rather choose the 50:50 one, right? (Assuming that the stakes are the same.) That's because the 50:50 is higher up in first-order stochastic dominance. And to make this decision, there's no need to know how the two bets are correlated or whether they're independent! It's merely a relation involving pairs of distributions.</p>



<a name="200001732"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/200001732" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Paolo Perrone <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#200001732">(Jun 07 2020 at 01:31)</a>:</h4>
<p>Hi all! Here's the video.<br>
<a href="https://youtu.be/auIuhRjMokQ">https://youtu.be/auIuhRjMokQ</a></p>
<div class="youtube-video message_inline_image"><a data-id="auIuhRjMokQ" href="https://youtu.be/auIuhRjMokQ"><img src="https://i.ytimg.com/vi/auIuhRjMokQ/default.jpg"></a></div>



<a name="200003653"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/200003653" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Paolo Perrone <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#200003653">(Jun 07 2020 at 02:35)</a>:</h4>
<p>By the way, somebody was asking whether the stochastic order can be equivalently obtained by comparing quantiles: the answer is, yes if X = R, while in the general case of a partial order one cannot define quantiles. (Thanks to Sharwin Rezagholi for pointing that out!)</p>



<a name="200019388"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/200019388" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Joshua Meyers <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#200019388">(Jun 07 2020 at 11:07)</a>:</h4>
<p>I am thinking that <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span> are random variables, perhaps <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span></span></span></span> is the return on investing in bananas and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span> is the return on investing in oranges.  Suppose that the sets <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mi>ω</mi><mo>∈</mo><mi mathvariant="normal">Ω</mi><mi mathvariant="normal">∣</mi><mi>q</mi><mo stretchy="false">(</mo><mi>ω</mi><mo stretchy="false">)</mo><mo>&gt;</mo><mi>p</mi><mo stretchy="false">(</mo><mi>ω</mi><mo stretchy="false">)</mo><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\omega\in\Omega | q(\omega)&gt;p(\omega)\}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">Ω</span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mclose">)</span><span class="mclose">}</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mi>ω</mi><mo>∈</mo><mi mathvariant="normal">Ω</mi><mi mathvariant="normal">∣</mi><mi>p</mi><mo stretchy="false">(</mo><mi>ω</mi><mo stretchy="false">)</mo><mo>&gt;</mo><mi>q</mi><mo stretchy="false">(</mo><mi>ω</mi><mo stretchy="false">)</mo><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex"> \{\omega\in\Omega | p(\omega)&gt;q(\omega)\}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">Ω</span><span class="mord">∣</span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mclose">)</span><span class="mclose">}</span></span></span></span> both have nonzero measure.  Then by your definition, we cannot say that either <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span></span></span></span> or <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span> has first-order stochastic dominance over the other.  (I am recalling that you define <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span></span></span></span> to have stochastic dominance over <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span> iff <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi><mo stretchy="false">(</mo><mo stretchy="false">{</mo><mi>ω</mi><mo>∈</mo><mi mathvariant="normal">Ω</mi><mi mathvariant="normal">∣</mi><mi>p</mi><mo stretchy="false">(</mo><mi>ω</mi><mo stretchy="false">)</mo><mo>≥</mo><mi>q</mi><mo stretchy="false">(</mo><mi>ω</mi><mo stretchy="false">)</mo><mo stretchy="false">}</mo><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\mu(\{\omega\in\Omega | p(\omega)\geq q(\omega)\})=1</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">μ</span><span class="mopen">(</span><span class="mopen">{</span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">Ω</span><span class="mord">∣</span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mclose">)</span><span class="mclose">}</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>.)  Is there a way to still compare them in this case?  (Tobias's example of the two uncorrelated bets is an example of this.)</p>



<a name="200019674"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/200019674" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Christoph Thies <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#200019674">(Jun 07 2020 at 11:15)</a>:</h4>
<p>Thank you very much for the effort to explain clearly and comprehensibly, <span class="user-mention" data-user-id="275989">@Paolo Perrone</span> . As a non-expert I deeply appreciate that, and I really enjoyed your talk, though much of it is way over my head. At least I feel your work is not completely out of reach for me, and that makes me very happy!</p>
<p>Please take the following as a gentle suggestion and not as criticism. How about occasionally replacing examples using goods and gains by examples using, e.g., biological traits and fitness (these happen to be the constructs I'm mostly interested in <span aria-label="see no evil" class="emoji emoji-1f648" role="img" title="see no evil">:see_no_evil:</span>)? Traits can be anything from a cell's production rate of a protein, to the kind of care given by a parent to its offspring, and to the ploidy of the genetic system of the organism (multiplicity of chromosomes) or the pinkness of unicorns. Fitness usually represents some sort of success in reproduction or persistence that, crucially, does not necessarily occur at the expense of other entities (I am aware this may be possible also in economic contexts). IMHO this setting provides much nicer stories. I apologise if this suggestion is inappropriate.</p>



<a name="200020315"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/200020315" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Paolo Perrone <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#200020315">(Jun 07 2020 at 11:34)</a>:</h4>
<p><span class="user-mention silent" data-user-id="280784">Joshua Meyers</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200019388">said</a>:</p>
<blockquote>
<p>I am thinking that <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span> are random variables, perhaps <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span></span></span></span> is the return on investing in bananas and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span> is the return on investing in oranges.  Suppose that the sets <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mi>ω</mi><mo>∈</mo><mi mathvariant="normal">Ω</mi><mi mathvariant="normal">∣</mi><mi>q</mi><mo stretchy="false">(</mo><mi>ω</mi><mo stretchy="false">)</mo><mo>&gt;</mo><mi>p</mi><mo stretchy="false">(</mo><mi>ω</mi><mo stretchy="false">)</mo><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\omega\in\Omega | q(\omega)&gt;p(\omega)\}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">Ω</span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mclose">)</span><span class="mclose">}</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mi>ω</mi><mo>∈</mo><mi mathvariant="normal">Ω</mi><mi mathvariant="normal">∣</mi><mi>p</mi><mo stretchy="false">(</mo><mi>ω</mi><mo stretchy="false">)</mo><mo>&gt;</mo><mi>q</mi><mo stretchy="false">(</mo><mi>ω</mi><mo stretchy="false">)</mo><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex"> \{\omega\in\Omega | p(\omega)&gt;q(\omega)\}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">Ω</span><span class="mord">∣</span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mclose">)</span><span class="mclose">}</span></span></span></span> both have nonzero measure.  Then by your definition, we cannot say that either <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span></span></span></span> or <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span> has first-order stochastic dominance over the other.  (I am recalling that you define <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span></span></span></span> to have stochastic dominance over <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span> iff <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi><mo stretchy="false">(</mo><mo stretchy="false">{</mo><mi>ω</mi><mo>∈</mo><mi mathvariant="normal">Ω</mi><mi mathvariant="normal">∣</mi><mi>p</mi><mo stretchy="false">(</mo><mi>ω</mi><mo stretchy="false">)</mo><mo>≥</mo><mi>q</mi><mo stretchy="false">(</mo><mi>ω</mi><mo stretchy="false">)</mo><mo stretchy="false">}</mo><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\mu(\{\omega\in\Omega | p(\omega)\geq q(\omega)\})=1</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">μ</span><span class="mopen">(</span><span class="mopen">{</span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">Ω</span><span class="mord">∣</span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="mclose">)</span><span class="mclose">}</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>.)  Is there a way to still compare them in this case?  (Tobias's example of the two uncorrelated bets is an example of this.)</p>
</blockquote>
<p>I see. If I understand correctly, if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span> come from random variables, and their joint assigns nonzero probability both to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>≤</mo><mi>y</mi></mrow><annotation encoding="application/x-tex">x \le y</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.7719400000000001em;vertical-align:-0.13597em;"></span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>≤</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">y\le x</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.8304100000000001em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span>, then they are not comparable as random variables. However, it could still be that there exists some <em>other</em> joint entirely supported on the order relation - in that case <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span> are comparable as random variables (in the stochastic order). It turns out that in many cases (such as over the real line) the stochastic order is a partial order, so if there is a joint assigning probability 1 to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>≤</mo><mi>y</mi></mrow><annotation encoding="application/x-tex">x\le y</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.7719400000000001em;vertical-align:-0.13597em;"></span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span> then there is no joint assigning probability 1 to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>≤</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">y\le x</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.8304100000000001em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span>. (A reference for the latter, for example, is this paper of Tobias, <a href="https://arxiv.org/abs/1810.06771">https://arxiv.org/abs/1810.06771</a>.)</p>



<a name="200020375"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/200020375" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Paolo Perrone <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#200020375">(Jun 07 2020 at 11:36)</a>:</h4>
<p><span class="user-mention silent" data-user-id="307303">Christoph Thies</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200019674">said</a>:</p>
<blockquote>
<p>Thank you very much for the effort to explain clearly and comprehensibly, <span class="user-mention silent" data-user-id="275989">Paolo Perrone</span> . As a non-expert I deeply appreciate that, and I really enjoyed your talk, though much of it is way over my head. At least I feel your work is not completely out of reach for me, and that makes me very happy!</p>
<p>Please take the following as a gentle suggestion and not as criticism. How about occasionally replacing examples using goods and gains by examples using, e.g., biological traits and fitness (these happen to be the constructs I'm mostly interested in <span aria-label="see no evil" class="emoji emoji-1f648" role="img" title="see no evil">:see_no_evil:</span>)? Traits can be anything from a cell's production rate of a protein, to the kind of care given by a parent to its offspring, and to the ploidy of the genetic system of the organism (multiplicity of chromosomes) or the pinkness of unicorns. Fitness usually represents some sort of success in reproduction or persistence that, crucially, does not necessarily occur at the expense of other entities (I am aware this may be possible also in economic contexts). IMHO this setting provides much nicer stories. I apologise if this suggestion is inappropriate.</p>
</blockquote>
<p>Thank you for the appreciation!<br>
It would be nice to use examples from biology. Unfortunately I don't know enough about it though. Do you have a particular example in mind, that you'd like to explain to me?</p>



<a name="200020426"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/200020426" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Paolo Perrone <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#200020426">(Jun 07 2020 at 11:38)</a>:</h4>
<p>By the way, some people asked which program I used as virtual blackboard. It's called Xournal, <a href="http://xournal.sourceforge.net/">http://xournal.sourceforge.net/</a>.</p>



<a name="200022712"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/200022712" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Dario Stein <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#200022712">(Jun 07 2020 at 12:44)</a>:</h4>
<p><span class="user-mention" data-user-id="275989">@Paolo Perrone</span> You showed that conditional expectations on X can be phrased as partial evaluation/double distributions in the case where X is convex. Do you know how this could connect to other synthetic notions of conditioning (assuming our Markov category comes from a monad)? What if X is not convex, e.g. can we somehow express conditioning on boolean outputs?</p>



<a name="200023369"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/200023369" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Christoph Thies <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#200023369">(Jun 07 2020 at 13:01)</a>:</h4>
<p><span class="user-mention silent" data-user-id="275989">Paolo Perrone</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200020375">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="307303">Christoph Thies</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200019674">said</a>:</p>
<blockquote>
<p>Thank you very much for the effort to explain clearly and comprehensibly, <span class="user-mention silent" data-user-id="275989">Paolo Perrone</span> . As a non-expert I deeply appreciate that, and I really enjoyed your talk, though much of it is way over my head. At least I feel your work is not completely out of reach for me, and that makes me very happy!</p>
<p>Please take the following as a gentle suggestion and not as criticism. How about occasionally replacing examples using goods and gains by examples using, e.g., biological traits and fitness (these happen to be the constructs I'm mostly interested in <span aria-label="see no evil" class="emoji emoji-1f648" role="img" title="see no evil">:see_no_evil:</span>)? Traits can be anything from a cell's production rate of a protein, to the kind of care given by a parent to its offspring, and to the ploidy of the genetic system of the organism (multiplicity of chromosomes) or the pinkness of unicorns. Fitness usually represents some sort of success in reproduction or persistence that, crucially, does not necessarily occur at the expense of other entities (I am aware this may be possible also in economic contexts). IMHO this setting provides much nicer stories. I apologise if this suggestion is inappropriate.</p>
</blockquote>
<p>Thank you for the appreciation!<br>
It would be nice to use examples from biology. Unfortunately I don't know enough about it though. Do you have a particular example in mind, that you'd like to explain to me?</p>
</blockquote>
<p>Hm, I don't have a specific example. In fact, wrt your talk I think your examples were perfectly appropriate. It just occurred to me this might be a useful suggestion since biology instantiates these abstract matters in ways quite different from economy.</p>
<p>Personally, I am interested for example in biological scenarios in which taking the codomain of random variables that represent, say, traits to be the real numbers is not adequate so that classical statistics becomes sort of dodgy as a language for reasoning about them (and I am here in order to understand better what I mean by this and other things I don't quite understand).</p>



<a name="200025684"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/200025684" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Paolo Perrone <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#200025684">(Jun 07 2020 at 14:06)</a>:</h4>
<p><span class="user-mention silent" data-user-id="309295">Dario Stein</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200022712">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="275989">Paolo Perrone</span> You showed that conditional expectations on X can be phrased as partial evaluation/double distributions in the case where X is convex. Do you know how this could connect to other synthetic notions of conditioning (assuming our Markov category comes from a monad)? What if X is not convex, e.g. can we somehow express conditioning on boolean outputs?</p>
</blockquote>
<p>That's a very good question! We are currently working on it actually (Tobias, Eigil, Tomáš and I), we suspect that you can. <br>
For non-convex things, when one conditions, one is usually doing one of these two things: either conditioning a function on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span></span></span></span> <em>into</em> a convex set (say, US states to political preferences), or, working on the free convex space <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mi>X</mi></mrow><annotation encoding="application/x-tex">PX</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span></span></span></span>.</p>



<a name="200025968"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/200025968" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Manuel Bärenz <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#200025968">(Jun 07 2020 at 14:15)</a>:</h4>
<p><span class="user-mention" data-user-id="275989">@Paolo Perrone</span> I don't understand your example in the beginning. Why is the white curve better than the yellow?</p>



<a name="200026177"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/200026177" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Paolo Perrone <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#200026177">(Jun 07 2020 at 14:21)</a>:</h4>
<p>(Following up from in-person conversation: the intuition is that the white curve is both "higher up", so that you are likely to gain more, and "more peaked", so you have a better idea of how much exactly you will gain - which can be useful for planning a strategy.)</p>



<a name="200033475"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/200033475" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Dario Stein <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#200033475">(Jun 07 2020 at 17:23)</a>:</h4>
<p><span class="user-mention silent" data-user-id="275989">Paolo Perrone</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200025684">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="309295">Dario Stein</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200022712">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="275989">Paolo Perrone</span> You showed that conditional expectations on X can be phrased as partial evaluation/double distributions in the case where X is convex. Do you know how this could connect to other synthetic notions of conditioning (assuming our Markov category comes from a monad)? What if X is not convex, e.g. can we somehow express conditioning on boolean outputs?</p>
</blockquote>
<p>That's a very good question! We are currently working on it actually (Tobias, Eigil, Tomáš and I), we suspect that you can. <br>
For non-convex things, when one conditions, one is usually doing one of these two things: either conditioning a function on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span></span></span></span> <em>into</em> a convex set (say, US states to political preferences), or, working on the free convex space <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mi>X</mi></mrow><annotation encoding="application/x-tex">PX</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span></span></span></span>.</p>
</blockquote>
<p>Fantastic, very interested by that. Sam's and my Beta-Bernoulli monad encodes essentially the conjugate prior relationship of the two distributions and nothing more; I'd be keen to work out if we can formalize conditioning on the Bernoulli flips in a synthetic way (the main difficulty so far was the central position of if/coproducts in the language, which Markov categories still don't reflect well).</p>



<a name="200039167"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/200039167" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Arthur Parzygnat <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#200039167">(Jun 07 2020 at 19:46)</a>:</h4>
<p><span class="user-mention silent" data-user-id="309295">Dario Stein</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200033475">said</a>:</p>
<blockquote>
<p>Fantastic, very interested by that. Sam's and my Beta-Bernoulli monad encodes essentially the conjugate prior relationship of the two distributions and nothing more; I'd be keen to work out if we can formalize conditioning on the Bernoulli flips in a synthetic way (the main difficulty so far was the central position of if/coproducts in the language, which Markov categories still don't reflect well).</p>
</blockquote>
<p>I'd like to understand what you mean in a little more detail, if you could elaborate or point me to a reference. For example, what exactly is the Beta-Bernoulli monad? Perhaps <a href="http://math.mit.edu/~freer//papers/SSYAFR-Beta-Bernoulli.pdf">this paper</a> of yours? And is what you're talking about related to Jacobs' work on conjugate priors [Ref: <a href="https://arxiv.org/abs/1707.00269]">https://arxiv.org/abs/1707.00269]</a>? From my understanding of his paper, he had a nice description of conjugate priors in the Markov category language.</p>



<a name="200064453"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/200064453" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Joscha Diehl <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#200064453">(Jun 08 2020 at 07:16)</a>:</h4>
<p><span class="user-mention silent" data-user-id="275989">Paolo Perrone</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199984868">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="303393">Joscha Diehl</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199981512">said</a>:</p>
<blockquote>
<p>Great talk.<br>
Can you say something about the bar construction mentioned in the abstract?</p>
</blockquote>
<p><span class="user-mention silent" data-user-id="303393">Joscha Diehl</span>  Thanks! Yep. The maps <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi></mrow><annotation encoding="application/x-tex">E</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">P e</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault">e</span></span></span></span> which give the equivalent characterization to second-order stochastic dominance are exactly the source and target maps of 1-simplices in the bar construction. This turns out to be quite structural!<br>
There's quite a bit to talk about - if you want I can expand. For now, two references are Chapter 4 of my thesis, and my MFPS talk here: <a href="https://youtu.be/28EASeG1RBA">https://youtu.be/28EASeG1RBA</a> (paper here: <a href="https://arxiv.org/abs/1810.06037">https://arxiv.org/abs/1810.06037</a>)</p>
</blockquote>
<p>Thanks! The paper should be a good entry point for me to get what's going on. I was thinking of the bar construction in algebra, that builds a coalgebra out of an algebra. I guess the categorial bar construction is an abstraction of that?<br>
More conceptually: is the hope in understanding 'your' bar construction, to get to third-order dominance, etc?</p>



<a name="200085491"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/200085491" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Paolo Perrone <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#200085491">(Jun 08 2020 at 11:38)</a>:</h4>
<p><span class="user-mention silent" data-user-id="303393">Joscha Diehl</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200064453">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="275989">Paolo Perrone</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199984868">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="303393">Joscha Diehl</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/199981512">said</a>:</p>
<blockquote>
<p>Great talk.<br>
Can you say something about the bar construction mentioned in the abstract?</p>
</blockquote>
<p><span class="user-mention silent" data-user-id="303393">Joscha Diehl</span>  Thanks! Yep. The maps <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi></mrow><annotation encoding="application/x-tex">E</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">P e</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault">e</span></span></span></span> which give the equivalent characterization to second-order stochastic dominance are exactly the source and target maps of 1-simplices in the bar construction. This turns out to be quite structural!<br>
There's quite a bit to talk about - if you want I can expand. For now, two references are Chapter 4 of my thesis, and my MFPS talk here: <a href="https://youtu.be/28EASeG1RBA">https://youtu.be/28EASeG1RBA</a> (paper here: <a href="https://arxiv.org/abs/1810.06037">https://arxiv.org/abs/1810.06037</a>)</p>
</blockquote>
<p>Thanks! The paper should be a good entry point for me to get what's going on. I was thinking of the bar construction in algebra, that builds a coalgebra out of an algebra. I guess the categorial bar construction is an abstraction of that?<br>
More conceptually: is the hope in understanding 'your' bar construction, to get to third-order dominance, etc?</p>
</blockquote>
<p><span class="user-mention" data-user-id="303393">@Joscha Diehl</span> I don't know if we get a coalgebra in this general case, it could be interesting! Anybody knows how this works?<br>
In any case, here's roughly what happens. In the category of sets, the functor given by multiplying with a group (or monoid) <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>↦</mo><mi>G</mi><mo>×</mo><mi>X</mi></mrow><annotation encoding="application/x-tex">X\mapsto G\times X</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.69433em;vertical-align:-0.011em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">↦</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault">G</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span></span></span></span> has a natural monad structure, with unit and multiplication given by those of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">G</span></span></span></span>. It's called the <em>action monad</em>, or <em>writer monad</em> in computer science, <a href="https://ncatlab.org/nlab/show/action+monad">https://ncatlab.org/nlab/show/action+monad</a><br>
Algebra over this monad are <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">G</span></span></span></span>-sets, i.e. sets with a <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">G</span></span></span></span>-action. The very same holds in the category of Abelian groups if you take a ring <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span></span></span></span> and the functor given by tensoring with the ring. Algebras in this case are <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span></span></span></span>-modules.<br>
Now it turns out that in order to define the bar construction, one does not need a group or a ring, the monad structure is enough. Outside the category of Abelian groups one gets a simplicial object, which in the Abelian case is "the same" as a chain complex by the Dold-Kan correspondence.<br>
If you do that for probability monads, this simplicial object is such that 0-simplices are probability measures over a convex space (such as R), and 1-simplices are (basically) conditional expectations. Two measures are connected by an "edge" if one can be obtained by "concentrating" the other one (as we did in the US states example). </p>
<p>The question about third-order stochastic dominance is very interesting, I've always wondered how to obtain it in this framework, but I never figured it out. Do you have an idea in mind?</p>



<a name="200088962"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/200088962" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Dario Stein <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#200088962">(Jun 08 2020 at 12:18)</a>:</h4>
<p><span class="user-mention silent" data-user-id="296639">Arthur Parzygnat</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200039167">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="309295">Dario Stein</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200033475">said</a>:</p>
<blockquote>
<p>Fantastic, very interested by that. Sam's and my Beta-Bernoulli monad encodes essentially the conjugate prior relationship of the two distributions and nothing more; I'd be keen to work out if we can formalize conditioning on the Bernoulli flips in a synthetic way (the main difficulty so far was the central position of if/coproducts in the language, which Markov categories still don't reflect well).</p>
</blockquote>
<p>I'd like to understand what you mean in a little more detail, if you could elaborate or point me to a reference. For example, what exactly is the Beta-Bernoulli monad? Perhaps <a href="http://math.mit.edu/~freer//papers/SSYAFR-Beta-Bernoulli.pdf">this paper</a> of yours? And is what you're talking about related to Jacobs' work on conjugate priors [Ref: <a href="https://arxiv.org/abs/1707.00269]">https://arxiv.org/abs/1707.00269]</a>? From my understanding of his paper, he had a nice description of conjugate priors in the Markov category language.</p>
</blockquote>
<p><span class="user-mention" data-user-id="296639">@Arthur Parzygnat</span> yes, I meant that paper -- we didn't frame things very categorically there, but this amounts to giving a commutative&amp;affine monad on the functor category [Fin,Set] (Sam mentioned this approach in his talk). Its Kleisli category is thus a minimalistic combinatorial Markov category that encodes beta+bernoulli+their conjugate relationship. Thanks for the reference to Bart's paper, I'll have a look at it.</p>



<a name="200106354"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/200106354" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Joscha Diehl <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#200106354">(Jun 08 2020 at 14:38)</a>:</h4>
<p><span class="user-mention" data-user-id="275989">@Paolo Perrone</span> Thanks! Regarding third-order: no, I don't even know what third order dominance would mean. I'd hope it would pop out of the categorial view you have ..</p>



<a name="200106644"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/200106644" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Paolo Perrone <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#200106644">(Jun 08 2020 at 14:40)</a>:</h4>
<p><span class="user-mention silent" data-user-id="303393">Joscha Diehl</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200106354">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="275989">Paolo Perrone</span> Thanks! Regarding third-order: no, I don't even know what third order dominance would mean. I'd hope it would pop out of the categorial view you have ..</p>
</blockquote>
<p>My intuition would suggest, "the measure is more concentrated on lower values and more spread on higher values". But that's as much as I can say for now, nothing precise. (Imagine, on R, assigning a larger integral to functions such as f(x)=x^3.)</p>



<a name="200106922"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/200106922" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Joscha Diehl <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#200106922">(Jun 08 2020 at 14:42)</a>:</h4>
<p><span class="user-mention silent" data-user-id="275989">Paolo Perrone</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200106644">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="303393">Joscha Diehl</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200106354">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="275989">Paolo Perrone</span> Thanks! Regarding third-order: no, I don't even know what third order dominance would mean. I'd hope it would pop out of the categorial view you have ..</p>
</blockquote>
<p>My intuition would suggest, "the measure is more concentrated on lower values and more spread on higher values". But that's as much as I can say for now, nothing precise. (Imagine, on R, assigning a larger integral to functions such as f(x)=x^3.)</p>
</blockquote>
<p>Is there something like this already in the literature? Also, you might have mentioned it, but  it his obvious how first order and second order dominance are part of a 'ladder' of dominances?</p>



<a name="200107110"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/238032-event%3A%20Categorical%20Probability%20and%20Statistics%202020%20workshop/topic/Jun%206%3A%20Paolo%20Perrone%27s%20talk/near/200107110" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Paolo Perrone <a href="https://mattecapu.github.io/ct-zulip-archive/stream/238032-event.3A-Categorical-Probability-and-Statistics-2020-workshop/topic/Jun.206.3A.20Paolo.20Perrone.27s.20talk.html#200107110">(Jun 08 2020 at 14:43)</a>:</h4>
<p><span class="user-mention silent" data-user-id="303393">Joscha Diehl</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200106922">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="275989">Paolo Perrone</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200106644">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="303393">Joscha Diehl</span> <a href="#narrow/stream/238032-Categorical-Probability.20and.20Statistics.202020.20workshop/topic/Jun.206.3A.20Paolo.20Perrone's.20talk/near/200106354">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="275989">Paolo Perrone</span> Thanks! Regarding third-order: no, I don't even know what third order dominance would mean. I'd hope it would pop out of the categorial view you have ..</p>
</blockquote>
<p>My intuition would suggest, "the measure is more concentrated on lower values and more spread on higher values". But that's as much as I can say for now, nothing precise. (Imagine, on R, assigning a larger integral to functions such as f(x)=x^3.)</p>
</blockquote>
<p>Is there something like this already in the literature? Also, you might have mentioned it, but  it his obvious how first order and second order dominance are part of a 'ladder' of dominances?</p>
</blockquote>
<p><span class="user-mention" data-user-id="303393">@Joscha Diehl</span>  Yep, but I don't understand them very well: <a href="https://en.wikipedia.org/wiki/Stochastic_dominance#Third-order">https://en.wikipedia.org/wiki/Stochastic_dominance#Third-order</a></p>



<footer class="site-footer">

<hr><p>Last updated: Nov 01 2025 at 12:09 UTC</p>
This archive runs on a customization of <a href="https://github.com/zulip/zulip-archive">zulip-archive</a>
</footer>
</body>

</html>