<!DOCTYPE html>
<html>
<head>
  	<meta charset="utf-8" />
  	<meta http-equiv="X-UA-Compatible" content="IE=edge" />
  	<meta name="viewport" content="width=device-width, initial-scale=1" />
  
<link rel="stylesheet" href="https://mattecapu.github.io/ct-zulip-archive/style.css" /><title>the politics of AI and cryptocurrencies · community: discussion · Zulip Chat Archive</title>
</head>
<body>
<header>
<a href="https://mattecapu.github.io/ct-zulip-archive" class="home-link">
        <img class="logo" src="https://zulip-avatars.s3.amazonaws.com/21317/realm/icon.png?version=3" />
        <h1>Category Theory<br/>Zulip Server<br/>Archive</h1>
        </a>
        <p>
        You're reading the public-facing archive of the <a href="https://categorytheory.zulipchat.com/">Category Theory Zulip server</a>.<br/>
        
        To join the server you need an invite. Anybody can get an invite by contacting <a href="https://matteocapucci.wordpress.com">Matteo Capucci</a> at <em>name dot surname at gmail dot com</em>.<br/>
        
        For all things related to this archive refer to the same person.
        </p>
        </header>
        <hr />
    
<h2>Stream: <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/index.html">community: discussion</a></h2>
<h3>Topic: <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html">the politics of AI and cryptocurrencies</a></h3>

<hr>

<base href="https://categorytheory.zulipchat.com">

<a name="452295704"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/452295704" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> John Baez <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#452295704">(Jul 18 2024 at 09:30)</a>:</h4>
<p><a href="https://mathstodon.xyz/@johncarlosbaez/112806557618056885">Today I learned</a> that  Trump's vice presidential pick has unlocked a lot of financial support from Silicon Valley billionaires, because Vance is deeply connected to folks like Peter Thiel and Marc Andreesen, who are afraid that Biden will rein in AI and crypto.   I hope everyone using applied category theory for these technologies, or tech in general, keeps paying attention to these developments.</p>



<a name="452375596"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/452375596" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Morgan Rogers (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#452375596">(Jul 18 2024 at 15:30)</a>:</h4>
<p>Oof where are the billionaires funding AI legislation?</p>



<a name="452404118"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/452404118" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Ryan Wisnesky <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#452404118">(Jul 18 2024 at 17:46)</a>:</h4>
<p>fwiw, we try to compete against Thiel and palantir not just on tech, but on ethics. The open-source ACT community clip art associating sigma/delta/pi with Tolkien's Lord of the Rings silmarils jewels at <a href="http://silmarils.tech">http://silmarils.tech</a> actually has an anti-palantir bent: in Lord of the Rings, the creators of the palantiri had a great foe, who wore a crown with three jewels.  So I can offer this artwork as a symbol of resistance.</p>



<a name="452410356"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/452410356" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Kevin Carlson <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#452410356">(Jul 18 2024 at 18:15)</a>:</h4>
<p>Kind of odd to imagine identifying with Team Morgoth, but I see where you're coming from!</p>



<a name="453731133"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/453731133" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Ryan Wisnesky <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#453731133">(Jul 24 2024 at 15:43)</a>:</h4>
<p>the onion's thoughts on the matter: <a href="https://www.theonion.com/j-d-vance-vows-to-fight-for-forgotten-communities-in-s-1851602605">https://www.theonion.com/j-d-vance-vows-to-fight-for-forgotten-communities-in-s-1851602605</a></p>



<a name="485217919"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/485217919" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Posina Venkata Rayudu <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#485217919">(Nov 30 2024 at 11:04)</a>:</h4>
<p><a href="https://seasonaltokens.org/">Cryptocommodity</a> is a good thing!</p>
<p>Bye bye dollar ;)</p>



<a name="496052417"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/496052417" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Patrick Nicodemus <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#496052417">(Jan 27 2025 at 07:34)</a>:</h4>
<p>I'm pretty disappointed by Robert Ghrist's recent writing on AI and mathematics. A lot of writing on AI seems to carry a note of bitter vindictiveness against mathematicians who are interested in logical rigor and correct arguments, as these are a form of Luddism in the age of AI.</p>
<blockquote>
<p>3A// academics : your life is more complicated still. you have to teach the courses, write the grants, manage your phd students. the students are using AI to write their theses. they are either better at it than you or not -- either way, you are frustrated. your vaunted network effects (conferences, journal editors you know personally, your cadre of students) have diminishing returns as AI advances. what good is knowing terry tao personally when anyone can hit up the TT API from DeepSeek? plus -- and this is crucial -- you're a research mathematician, which means you are very conservative and probably don't believe in all that AI crap since it's just linear algebra and probability. can't fool you, no. you'll wake up too late and be too behind. HFSP (have fun staying pure)</p>
</blockquote>



<a name="496052716"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/496052716" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Patrick Nicodemus <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#496052716">(Jan 27 2025 at 07:36)</a>:</h4>
<blockquote>
<p>and as long as you have some taste and management skill, you can rival a top mathematician in terms of generating an army of phdai students to work with you / for you. oh, sure, it will be infinitely easier to write crank 500-page nonsense proofs of the trisection of an angle, but that's because AI is a force multiplier.</p>
</blockquote>
<p>A lab staffed by an army of "PhD" AI models is an interesting concept. I mostly think this is just fantasy though.</p>



<a name="496054078"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/496054078" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Patrick Nicodemus <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#496054078">(Jan 27 2025 at 07:46)</a>:</h4>
<blockquote>
<p>7/ end, for now. we'll see how this holds up in a few years. in the meantime, i've got some research to work on in fields that i've never published in before (neural networks architecture, financial network models, ...)</p>
</blockquote>
<p>I look forward to seeing his AI assisted research in new fields. I guess there's really nothing stopping us from publishing in several adjacent fields which are entirely new to us now that we can learn the basics in two weeks with AI. After all, medical science is expected to advance very quickly - <a href="https://observer.com/2025/01/anthropic-dario-amodei-ai-advances-double-human-lifespans/">https://observer.com/2025/01/anthropic-dario-amodei-ai-advances-double-human-lifespans/</a></p>



<a name="496060065"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/496060065" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Patrick Nicodemus <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#496060065">(Jan 27 2025 at 08:21)</a>:</h4>
<blockquote>
<p>2/ what does AI change? not today's AI -- the AI that is coming, that reasons better than a crack phd student, writes clearly, has creative ideas (but maybe not a sense of good taste), can upload to the ArXiV, and, most importantly, can be manifested in as large a group of agents as you (or a manager-AI) can handle...</p>
</blockquote>
<p>Wow, not just a lab staff of AI language models, but a manager too, to check their work and identify hallucinations. Like an ant farm of mathematicians. Lots to be optimistic about here.</p>



<a name="496102473"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/496102473" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Morgan Rogers (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#496102473">(Jan 27 2025 at 11:46)</a>:</h4>
<p>Wow I'm more than disappointed. That's deliberately irritating writing.</p>



<a name="496108458"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/496108458" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Capucci (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#496108458">(Jan 27 2025 at 12:18)</a>:</h4>
<p>Where did you get those quotes?</p>



<a name="496128261"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/496128261" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Josselin Poiret <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#496128261">(Jan 27 2025 at 13:56)</a>:</h4>
<p><span class="user-mention silent" data-user-id="275932">Matteo Capucci (he/him)</span> <a href="#narrow/channel/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies/near/496108458">said</a>:</p>
<blockquote>
<p>Where did you get those quotes?</p>
</blockquote>
<p>nitter doesn't work with articles, so here's a direct link to that other fascist's website <a href="https://x.com/robertghrist/article/1883646365777236306">https://x.com/robertghrist/article/1883646365777236306</a></p>



<a name="496130921"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/496130921" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Morgan Rogers (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#496130921">(Jan 27 2025 at 14:08)</a>:</h4>
<p>I guess he's looking to jump ship into tech?</p>



<a name="496170022"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/496170022" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> John Baez <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#496170022">(Jan 27 2025 at 16:56)</a>:</h4>
<p>By coincidence someone at our Lunar New Year party last night said that Ghrist was involved in some kind of "accelerationism" - I forget the adjective they stuck in front of that noun, but the idea was something like: the only way to save civilization is to accelerate the development of AI.   This person seemed to be saying Ghrist had written a kind of accelerationist manifesto.  Does anyone here know about that?</p>
<p>The <a href="https://x.com/robertghrist/article/1883646365777236306">article just mentioned</a> doesn't seem to be that manifesto, quite.</p>



<a name="496185592"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/496185592" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Joe Moeller <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#496185592">(Jan 27 2025 at 18:18)</a>:</h4>
<p>I think it was "effective accelerationism".</p>



<a name="496188983"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/496188983" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Ryan Wisnesky <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#496188983">(Jan 27 2025 at 18:37)</a>:</h4>
<p>Oh, yeah, "effective accelerationism" is like a religion in silicon valley <a href="https://en.wikipedia.org/wiki/Effective_accelerationism">https://en.wikipedia.org/wiki/Effective_accelerationism</a></p>



<a name="496196972"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/496196972" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Kevin Carlson <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#496196972">(Jan 27 2025 at 19:27)</a>:</h4>
<p>For context on this awful Internet nonsense, effective accelerationism is a movement named in parody of effective altruism that supposes we just need to go full speed ahead to let the AIs replace us with transhuman interdimensional beings or whatever. The leader of the movement, before being deanonymized, was known as Based Beff Jezos. It's rather grim to my mind that Ghrist is into this.</p>



<a name="496218576"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/496218576" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> John Baez <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#496218576">(Jan 27 2025 at 21:58)</a>:</h4>
<p>Thanks!  I don't actually <em>know</em> that Ghrist is into effective accelerationism, but the person I'm alluding to said he was. </p>
<p>I'm not sure if that explains Ghrist calling presheaves 'sheaves', but I suppose doing so speeds thing up a bit.   <span aria-label="upside down" class="emoji emoji-1f643" role="img" title="upside down">:upside_down:</span></p>



<a name="496361546"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/496361546" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> James Deikun <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#496361546">(Jan 28 2025 at 15:24)</a>:</h4>
<p>"e/acc" is dangerous pseudo-mystical claptrap that doesn't see any importance for the survival of humanity or human values in the future:</p>
<blockquote>
<p>The founders of the movement see it as rooted in <a href="https://en.wikipedia.org/wiki/Jeremy_England">Jeremy England</a>'s theory on the <a href="https://en.wikipedia.org/wiki/Abiogenesis">origin of life</a>, which is focused on <a href="https://en.wikipedia.org/wiki/Entropy">entropy</a> and <a href="https://en.wikipedia.org/wiki/Thermodynamics">thermodynamics</a>.<a href="https://en.wikipedia.org/wiki/Effective_accelerationism#cite_note-:7-11">[11]</a> According to them, the universe aims to increase entropy, and life is a way of increasing it. By spreading life throughout the universe and making life use up ever increasing amounts of energy, the universe's purpose would thus be fulfilled.<a href="https://en.wikipedia.org/wiki/Effective_accelerationism#cite_note-:7-11">[11]</a></p>
</blockquote>
<p>In other words, it means caring about life only insofar as life produces entropy.  Then as with libertarianism you get "(im)moderate optimists" who convince themselves that when following the core principle off of a cliff you actually won't encounter a cliff, and that the thing that maximizes production of entropy will be "sufficiently like humans" in some sense that's satisfying to them personally, thus having their cake and eating it too at the expense of intellectual honesty.</p>
<p>I find it pretty disturbing that people like that are allowed to be involved in the development of AI.</p>



<a name="496376807"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/496376807" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Morgan Rogers (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#496376807">(Jan 28 2025 at 16:35)</a>:</h4>
<p>"e/acc" more like "eek" am I right</p>



<a name="496394739"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/496394739" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Kevin Carlson <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#496394739">(Jan 28 2025 at 18:04)</a>:</h4>
<p>Well, the thing is, there’s no entity to with the affordance to “allow” or “not allow”, and having a mindset like that is very positively correlated with <em>wanting</em> to work on AI…</p>



<a name="496395997"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/496395997" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Mike Shulman <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#496395997">(Jan 28 2025 at 18:10)</a>:</h4>
<p>That's true in the strict sense of legality, but there are people making decisions about whether to <em>enable</em> such activity, such as those who give funding to these people, right?</p>



<a name="496405038"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/496405038" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Amar Hadzihasanovic <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#496405038">(Jan 28 2025 at 19:01)</a>:</h4>
<p>From what I've read from Ghrist, I'd guess that he aligns with e/acc on aesthetic before ethical grounds. To a certain extent a lot of this seems like a re-edition of Italian futurism, it stems from a pre-rational excitement with new technology and wish to be a "person of the new century" and not one of those left behind. As in the case of futurists largely embracing fascism, though, this often goes hand in hand with an ethos of "adapt or die" that's easy to exploit for reactionaries (who will choose who exactly is "standing in the way of progress").</p>



<a name="496408959"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/496408959" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Amar Hadzihasanovic <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#496408959">(Jan 28 2025 at 19:24)</a>:</h4>
<p>I mean, from what I see in his social media presence, Ghrist</p>
<ul>
<li>is genuinely excited about LLMs and aggressively using them in his work,</li>
<li>styles himself as an artist-polymath-intellectual,</li>
<li>has a penchant for contrarianism and a bit of provocation</li>
</ul>
<p>all of which make me think of futurist intellectuals, and also makes me doubt that he would genuinely embrace some form of sci-fi-utopianism (but not that he would claim ironically/provocatively to be on the side of those who do)</p>



<a name="496427214"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/496427214" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Kevin Carlson <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#496427214">(Jan 28 2025 at 21:27)</a>:</h4>
<p><span class="user-mention silent" data-user-id="276777">Mike Shulman</span> <a href="#narrow/channel/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies/near/496395997">said</a>:</p>
<blockquote>
<p>That's true in the strict sense of legality, but there are people making decisions about whether to <em>enable</em> such activity, such as those who give funding to these people, right?</p>
</blockquote>
<p>Mmm, yes, but those people still an extremely distributed entity, including every venture capitalist in the country, various different managers at every major tech company, every government research funding agency, not to mention analogous structures in Europe, China, etc... I don't think "allowed to work on AI" as a unified property of a person is a very meaningful frame. You could instead say "I think funders of AI should be discouraged from supporting such people working on AI", and at least that makes the problem clearer, of eg convincing every tech billionaire and everyone with budgetary authority at Microsoft, Google, or Meta independently not to fund such people.</p>



<a name="496427343"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/496427343" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Kevin Carlson <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#496427343">(Jan 28 2025 at 21:28)</a>:</h4>
<p>I like the analogy with futurism; everything obsessed with the new is old again, I suppose.</p>



<a name="496430587"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/496430587" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> John Baez <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#496430587">(Jan 28 2025 at 21:52)</a>:</h4>
<p>The US government tried to slow Chinese and Russian work on AI in various ways, including the <a href="https://en.wikipedia.org/wiki/CHIPS_and_Science_Act">CHIPS and Science act</a>:</p>
<blockquote>
<p>Companies are subjected to a ten-year ban prohibiting them from producing chips more advanced than <a href="https://en.wikipedia.org/wiki/28_nm_process">28 nanometers</a> in China and Russia if they are awarded subsidies under the law.</p>
</blockquote>
<p>But, it seems the Chinese behind <a href="https://www.newsweek.com/deepseek-elon-musk-microchip-claims-2021394">DeepSeek</a> figured out how to develop LLMs more efficiently:</p>
<blockquote>
<p>Deepseek says it only needed 2,000 specialized chips from <a href="https://www.newsweek.com/nvidia-cosmos-ai-chatgpt-moment-robotics-2010961">Nvidia to train</a> its V3. This is in comparison to a reported 16,000 or more required to train leading models, according to <em>The New York Times</em>.</p>
</blockquote>
<p>So, if you're going to try to stop someone from working on AI, you have to have a lot of power over them.</p>



<a name="496720909"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/496720909" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Capucci (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#496720909">(Jan 30 2025 at 08:46)</a>:</h4>
<p><span class="user-mention silent" data-user-id="276363">Amar Hadzihasanovic</span> <a href="#narrow/channel/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies/near/496405038">said</a>:</p>
<blockquote>
<p>To a certain extent a lot of this seems like a re-edition of Italian futurism, it stems from a pre-rational excitement with new technology and wish to be a "person of the new century" and not one of those left behind. As in the case of futurists largely embracing fascism, though, this often goes hand in hand with an ethos of "adapt or die" that's easy to exploit for reactionaries (who will choose who exactly is "standing in the way of progress").</p>
</blockquote>
<p>I <em>love</em> this comparison!</p>



<a name="496746477"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/496746477" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Josselin Poiret <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#496746477">(Jan 30 2025 at 10:55)</a>:</h4>
<p><span class="user-mention silent" data-user-id="276363">Amar Hadzihasanovic</span> <a href="#narrow/channel/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies/near/496408959">said</a>:</p>
<blockquote>
<p>and also makes me doubt that he would genuinely embrace some form of sci-fi-utopianism</p>
</blockquote>
<p>judging his personal intent here is completely irrelevant. i don't think we should extend goodwill and fall into the plausible deniability trap. the far right understands this very well, and actively exploits the inability of "nicer" actors to take a decisive stance. see the more extreme example of elon's fascist salutes.</p>
<p>if anyone, by their actions, actively promotes effective accelerationism, we should take them at face value. even <em>if</em> they were doing it solely because they're fascinated with the aesthetics, they need to understand that what they're putting out there is a problem and be called out for it.</p>



<a name="496747242"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/496747242" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Josselin Poiret <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#496747242">(Jan 30 2025 at 10:59)</a>:</h4>
<p>i keep far right propaganda, either IRL or on social media, that uses aesthetics as the primary hook, and that avoids mentioning any political stances they might have. this definitely works very well, and lots of people end up being radicalized in this way.</p>



<a name="496764495"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/496764495" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Amar Hadzihasanovic <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#496764495">(Jan 30 2025 at 12:31)</a>:</h4>
<p>I think it is both interesting and very relevant wrt political action to be curious about people's motivation. The far right e.g. has historically succeeded by building heterogeneous coalitions whose actors often had incompatible motivations, and to dismantle these coalitions, it may be necessary to target different actors with different strategies.</p>



<a name="496765929"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/241990-community%3A%20discussion/topic/the%20politics%20of%20AI%20and%20cryptocurrencies/near/496765929" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Amar Hadzihasanovic <a href="https://mattecapu.github.io/ct-zulip-archive/stream/241990-community.3A-discussion/topic/the.20politics.20of.20AI.20and.20cryptocurrencies.html#496765929">(Jan 30 2025 at 12:37)</a>:</h4>
<p>The example of Elon's salute is relevant, as, I believe, is part of a trollish right-wing culture which has made itself impermeable to being "called out" (winding up their political enemies is one of the things it craves), so that's not going to work out, unlike it would, e.g., with a more traditional far-right politician who has tried to style themselves as "respectable" and "reassuring".</p>



<footer class="site-footer">

<hr><p>Last updated: Feb 28 2026 at 12:12 UTC</p>
This archive runs on a customization of <a href="https://github.com/zulip/zulip-archive">zulip-archive</a>
</footer>
</body>

</html>