<!DOCTYPE html>
<html>
<head>
  	<meta charset="utf-8" />
  	<meta http-equiv="X-UA-Compatible" content="IE=edge" />
  	<meta name="viewport" content="width=device-width, initial-scale=1" />
  
<link rel="stylesheet" href="https://mattecapu.github.io/ct-zulip-archive/style.css" /><title>CT for Mechanistic Interpretability · learning: questions · Zulip Chat Archive</title>
</head>
<body>
<header>
<a href="https://mattecapu.github.io/ct-zulip-archive" class="home-link">
        <img class="logo" src="https://zulip-avatars.s3.amazonaws.com/21317/realm/icon.png?version=3" />
        <h1>Category Theory<br/>Zulip Server<br/>Archive</h1>
        </a>
        <p>
        You're reading the public-facing archive of the <a href="https://categorytheory.zulipchat.com/">Category Theory Zulip server</a>.<br/>
        
        To join the server you need an invite. Anybody can get an invite by contacting <a href="https://matteocapucci.wordpress.com">Matteo Capucci</a> at <em>name dot surname at gmail dot com</em>.<br/>
        
        For all things related to this archive refer to the same person.
        </p>
        </header>
        <hr />
    
<h2>Stream: <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/index.html">learning: questions</a></h2>
<h3>Topic: <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/CT.20for.20Mechanistic.20Interpretability.html">CT for Mechanistic Interpretability</a></h3>

<hr>

<base href="https://categorytheory.zulipchat.com">

<a name="554784886"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/CT%20for%20Mechanistic%20Interpretability/near/554784886" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Adel Ardalan <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/CT.20for.20Mechanistic.20Interpretability.html#554784886">(Nov 10 2025 at 20:23)</a>:</h4>
<p>Hi all! Wondering whether folks here have seen the following preprint and have thought about category theoretic interpretations of their framework. It feels like there might be some connections, although it is not clear to me what the categories are to begin with. </p>
<p><a href="https://arxiv.org/abs/2301.04709">https://arxiv.org/abs/2301.04709</a></p>



<a name="554851486"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/CT%20for%20Mechanistic%20Interpretability/near/554851486" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Jonty Male <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/CT.20for.20Mechanistic.20Interpretability.html#554851486">(Nov 11 2025 at 07:37)</a>:</h4>
<p>There's likely an optimal person to ask this question to and it's likely <a href="https://rick-ali.github.io/">https://rick-ali.github.io/</a>, who surprises me by not being in this server</p>



<a name="554892170"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/CT%20for%20Mechanistic%20Interpretability/near/554892170" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Dhurim Cakiqi <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/CT.20for.20Mechanistic.20Interpretability.html#554892170">(Nov 11 2025 at 11:30)</a>:</h4>
<p>These papers may be of interest to you, since the  original paper you posted talks about causal abstraction </p>
<p><a href="https://arxiv.org/pdf/2502.00407">https://arxiv.org/pdf/2502.00407</a><br>
<a href="https://proceedings.mlr.press/v161/rischel21a/rischel21a.pdf">https://proceedings.mlr.press/v161/rischel21a/rischel21a.pdf</a></p>



<a name="554924100"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/CT%20for%20Mechanistic%20Interpretability/near/554924100" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Adel Ardalan <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/CT.20for.20Mechanistic.20Interpretability.html#554924100">(Nov 11 2025 at 14:18)</a>:</h4>
<p><span class="user-mention silent" data-user-id="730304">Dhurim Cakiqi</span> <a href="#narrow/channel/229199-learning.3A-questions/topic/CT.20for.20Mechanistic.20Interpretability/near/554892170">said</a>:</p>
<blockquote>
<p>These papers may be of interest to you, since the  original paper you posted talks about causal abstraction </p>
<p><a href="https://arxiv.org/pdf/2502.00407">https://arxiv.org/pdf/2502.00407</a><br>
<a href="https://proceedings.mlr.press/v161/rischel21a/rischel21a.pdf">https://proceedings.mlr.press/v161/rischel21a/rischel21a.pdf</a></p>
</blockquote>
<p><span class="user-mention" data-user-id="988318">@Julian Gold</span> Both of these look quite relevant. Thanks a lot, <span class="user-mention" data-user-id="979285">@Jonty Male</span> and <span class="user-mention" data-user-id="730304">@Dhurim Cakiqi</span> <span aria-label="slight smile" class="emoji emoji-1f642" role="img" title="slight smile">:slight_smile:</span></p>



<a name="555243467"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/CT%20for%20Mechanistic%20Interpretability/near/555243467" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Julian Gold <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/CT.20for.20Mechanistic.20Interpretability.html#555243467">(Nov 12 2025 at 23:51)</a>:</h4>
<p>Thank you!!</p>



<a name="555495745"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/CT%20for%20Mechanistic%20Interpretability/near/555495745" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Noah Chrein <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/CT.20for.20Mechanistic.20Interpretability.html#555495745">(Nov 14 2025 at 02:44)</a>:</h4>
<p>This is awesome, I am primarily interested in mech interp, I think its a moral imperative to figure it out, I also think CT is ontologically fit for it. Though I believe that, perhaps, a framework for n-theories, is required for the sort of scale connectionism needs to derive paradigms that can be useful for interpreting systems. </p>
<p>For anyone interested in a casual chat centered around cognition and category theory, here's a signal link:<a href="https://signal.group/#CjQKIFdN_7SfeX1v9pb53cbbWhvj32GJ0MdV6gmuZ79_k-vkEhA7-ZbZMmGyQski9neFuK6H">https://signal.group/#CjQKIFdN_7SfeX1v9pb53cbbWhvj32GJ0MdV6gmuZ79_k-vkEhA7-ZbZMmGyQski9neFuK6H</a></p>
<p>I am trying to just get everyone I meet doing category theory for interpreting cognitive systems in there. Though I have been hesitant to post it in this zulip yet.</p>



<a name="555586256"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/CT%20for%20Mechanistic%20Interpretability/near/555586256" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Julian Gold <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/CT.20for.20Mechanistic.20Interpretability.html#555586256">(Nov 14 2025 at 13:23)</a>:</h4>
<p>“moral imperative” reminds me of one of my fave movies :) very cool, just sent join request in signal</p>



<a name="558766358"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/CT%20for%20Mechanistic%20Interpretability/near/558766358" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Noah Chrein <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/CT.20for.20Mechanistic.20Interpretability.html#558766358">(Nov 21 2025 at 23:32)</a>:</h4>
<p>yeah I just think mathematicians, like category theorists, have the power to effect the field of mech interp and help make AI safe.</p>



<footer class="site-footer">

<hr><p>Last updated: Feb 28 2026 at 12:12 UTC</p>
This archive runs on a customization of <a href="https://github.com/zulip/zulip-archive">zulip-archive</a>
</footer>
</body>

</html>