<!DOCTYPE html>
<html>
<head>
  	<meta charset="utf-8" />
  	<meta http-equiv="X-UA-Compatible" content="IE=edge" />
  	<meta name="viewport" content="width=device-width, initial-scale=1" />
  
<link rel="stylesheet" href="https://mattecapu.github.io/ct-zulip-archive/style.css" /><title>Relative entropy variable contributions · learning: questions · Zulip Chat Archive</title>
</head>
<body>
<header>
<a href="https://mattecapu.github.io/ct-zulip-archive" class="home-link">
        <img class="logo" src="https://zulip-avatars.s3.amazonaws.com/21317/realm/icon.png?version=3" />
        <h1>Category Theory<br/>Zulip Server<br/>Archive</h1>
        </a>
        <p>
        You're reading the public-facing archive of the <a href="https://categorytheory.zulipchat.com/">Category Theory Zulip server</a>.<br/>
        
        To join the server you need an invite. Anybody can get an invite by contacting <a href="https://matteocapucci.wordpress.com">Matteo Capucci</a> at <em>name dot surname at gmail dot com</em>.<br/>
        
        For all things related to this archive refer to the same person.
        </p>
        </header>
        <hr />
    
<h2>Stream: <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/index.html">learning: questions</a></h2>
<h3>Topic: <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/Relative.20entropy.20variable.20contributions.html">Relative entropy variable contributions</a></h3>

<hr>

<base href="https://categorytheory.zulipchat.com">

<a name="459935304"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/Relative%20entropy%20variable%20contributions/near/459935304" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Kalan Kucera <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/Relative.20entropy.20variable.20contributions.html#459935304">(Aug 11 2024 at 19:47)</a>:</h4>
<p>I was wondering wrt relative entropies between objects of a category, could you define specific contributions to the overall relative entropy measure due to a particular variable?</p>
<p>Let's say that I have  a category of models, with three models p, q, and r in it. I take 'r' to be a reference model, and then can look at the relative entropy between the other models and it, K(p||r) and K(q||r). If, for instance, both probability distributions created by models p and q had an unspecified, but seemingly measurable via K, dependence on some variable x of the model, would it be valid to to:<br>
1) directly compare the relative entropy measures for the two models?<br>
2) create a function (K/x) to quantify the variable's contribution to shifting the models q and p away from the reference r?</p>



<a name="459946049"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/Relative%20entropy%20variable%20contributions/near/459946049" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> JR <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/Relative.20entropy.20variable.20contributions.html#459946049">(Aug 11 2024 at 21:22)</a>:</h4>
<p><span class="user-mention silent" data-user-id="381883">Kalan Kucera</span> <a href="#narrow/stream/229199-learning.3A-questions/topic/Relative.20entropy.20variable.20contributions/near/459935304">said</a>:</p>
<blockquote>
<p>I was wondering wrt relative entropies between objects of a category, could you define specific contributions to the overall relative entropy measure due to a particular variable?</p>
<p>Let's say that I have  a category of models, with three models p, q, and r in it. I take 'r' to be a reference model, and then can look at the relative entropy between the other models and it, K(p||r) and K(q||r). If, for instance, both probability distributions created by models p and q had an unspecified, but seemingly measurable via K, dependence on some variable x of the model, would it be valid to to:<br>
1) directly compare the relative entropy measures for the two models?<br>
2) create a function (K/x) to quantify the variable's contribution to shifting the models q and p away from the reference r?</p>
</blockquote>
<p>Perhaps the Jensen-Shannon divergence of a uniform mixture of p, q, and r</p>



<a name="459947094"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/Relative%20entropy%20variable%20contributions/near/459947094" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Kalan Kucera <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/Relative.20entropy.20variable.20contributions.html#459947094">(Aug 11 2024 at 21:38)</a>:</h4>
<p><span class="user-mention silent" data-user-id="658891">JR</span> <a href="#narrow/stream/229199-learning.3A-questions/topic/Relative.20entropy.20variable.20contributions/near/459946049">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="381883">Kalan Kucera</span> <a href="#narrow/stream/229199-learning.3A-questions/topic/Relative.20entropy.20variable.20contributions/near/459935304">said</a>:</p>
<blockquote>
<p>I was wondering wrt relative entropies between objects of a category, could you define specific contributions to the overall relative entropy measure due to a particular variable?</p>
<p>Let's say that I have  a category of models, with three models p, q, and r in it. I take 'r' to be a reference model, and then can look at the relative entropy between the other models and it, K(p||r) and K(q||r). If, for instance, both probability distributions created by models p and q had an unspecified, but seemingly measurable via K, dependence on some variable x of the model, would it be valid to to:<br>
1) directly compare the relative entropy measures for the two models?<br>
2) create a function (K/x) to quantify the variable's contribution to shifting the models q and p away from the reference r?</p>
</blockquote>
<p>Perhaps the Jensen-Shannon divergence of a uniform mixture of p, q, and r</p>
</blockquote>
<p>In that scenario, would I just vary x and then the JSD would tell me when the variance of x had equivalent impact on the distributions of p and q relative to r?</p>



<a name="459948107"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/Relative%20entropy%20variable%20contributions/near/459948107" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Eric M Downes <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/Relative.20entropy.20variable.20contributions.html#459948107">(Aug 11 2024 at 21:56)</a>:</h4>
<p>Second the Jensen-Shannon divergence.</p>
<p>It sounds like you are working in ordinary probability / statistics ("models", "variance", "distributions", etc.).  If you need to work in a weaker setting, can you specify which category you are working in?  Or paper(s) you're working from?</p>
<p>Does your category have an equivalent for Bayes' Law and marginal distributions?  If so, say <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>X</mi></msub><mo separator="true">,</mo><msub><mi>q</mi><mi>X</mi></msub></mrow><annotation encoding="application/x-tex">p_X,q_X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> are two joint distributions over a product of variables <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>=</mo><mi>x</mi><mo>×</mo><mi>y</mi><mo>×</mo><mi>z</mi><mo>…</mo></mrow><annotation encoding="application/x-tex">X=x\times y\times z\ldots</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span></span></span></span>), their marginals over just <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> are <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>x</mi></msub><mo separator="true">,</mo><msub><mi>q</mi><mi>x</mi></msub></mrow><annotation encoding="application/x-tex">p_x,q_x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, and the distributions conditioned on <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> are <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mo>…</mo><mi mathvariant="normal">∣</mi><mi>x</mi></mrow></msub><mo separator="true">,</mo><msub><mi>q</mi><mrow><mo>…</mo><mi mathvariant="normal">∣</mi><mi>x</mi></mrow></msub></mrow><annotation encoding="application/x-tex">p_{\ldots|x},q_{\ldots|x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7858em;vertical-align:-0.3552em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="minner mtight">…</span><span class="mord mtight">∣</span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="minner mtight">…</span><span class="mord mtight">∣</span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span></span></span></span> then<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo stretchy="false">(</mo><msub><mi>p</mi><mi>X</mi></msub><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><msub><mi>q</mi><mi>X</mi></msub><mo stretchy="false">)</mo><mo>≤</mo><mi>K</mi><mo stretchy="false">(</mo><msub><mi>p</mi><mi>x</mi></msub><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><msub><mi>q</mi><mi>x</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mi>K</mi><mo stretchy="false">(</mo><msub><mi>p</mi><mrow><mo>…</mo><mi mathvariant="normal">∣</mi><mi>x</mi></mrow></msub><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><msub><mi>q</mi><mrow><mo>…</mo><mi mathvariant="normal">∣</mi><mi>x</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">K(p_X||q_X)\leq K(p_x||q_x)+K(p_{\ldots|x}||q_{\ldots|x})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1052em;vertical-align:-0.3552em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="minner mtight">…</span><span class="mord mtight">∣</span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span><span class="mord">∣∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="minner mtight">…</span><span class="mord mtight">∣</span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><br>
likely holds, which may be helpful.</p>



<a name="459949244"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/Relative%20entropy%20variable%20contributions/near/459949244" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Kalan Kucera <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/Relative.20entropy.20variable.20contributions.html#459949244">(Aug 11 2024 at 22:14)</a>:</h4>
<p>I think this will do the trick, thank you both for the suggestion. I am trying to do apply some of this analysis to a category I'm attempting to construct for some physical measurements (if you're familiar with creep in metals?) on the basis of the random distributions of test results. There are two different sets of data for these tests, there are the raw results from the characterization method, and the results determined by the model of the test, and I'm looking at the empirical data sets (where the only way affective variables arise are through applied constants and curve fitting) relative to the model results (variables applied in roughly the same form found from curve fitting). A kind of "relative entropy minimization" I suppose.</p>
<p>I want to say that because, in experiment, we know there is an effect from temperature, say, we could create some variable that is a portion of the relative entropy produced by variation in temperature based on the difference in KL. </p>
<p>What I'm hearing from y'all is that, for two different models, if the temperature had the same effect relative to the model, their JSD should be... 0?</p>



<a name="459950058"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/Relative%20entropy%20variable%20contributions/near/459950058" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Eric M Downes <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/Relative.20entropy.20variable.20contributions.html#459950058">(Aug 11 2024 at 22:24)</a>:</h4>
<p>Yeah I would definitely recommend just working in ordinary probability theory then.  (Also see above my correction to an inequality.)</p>
<p>Tai Danae Bradley does some good stuff with how to isolate variables without losing information (as one usually does with taking a marginal) <a href="https://arxiv.org/abs/2004.05631">in her thesis</a> -- its categorical but very readable and since you're doing physics the quantum mechanical analogies she makes should hopefully be pretty familiar to you.</p>



<a name="459951073"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/Relative%20entropy%20variable%20contributions/near/459951073" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Eric M Downes <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/Relative.20entropy.20variable.20contributions.html#459951073">(Aug 11 2024 at 22:37)</a>:</h4>
<blockquote>
<p>What I'm hearing from y'all is that, for two different models, if the temperature had the same effect relative to the model, their JSD should be... 0?</p>
</blockquote>
<p>Unfortunately I'm still a bit un certain of what you're actually doing, and I don't want to guess.</p>
<p>The intuitive explanation of whats going on is that relative entropy <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo stretchy="false">(</mo><mi>p</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>q</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">K(p||q)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mord">∣∣</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mclose">)</span></span></span></span> can be thought of as a distance on a manifold (like a curved surface).  But that manifold is <em>different</em> than the one on which <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo stretchy="false">(</mo><mi>q</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>p</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">K(q||p)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mord">∣∣</span><span class="mord mathnormal">p</span><span class="mclose">)</span></span></span></span> measures distances.  Thus <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> fails to be a metric (not symmetric).  The JSD forcibly symmetrizes this so that you end up with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mi>S</mi><mi>D</mi><mo stretchy="false">(</mo><mi>p</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>q</mi><mo stretchy="false">)</mo><mo>=</mo><mi>J</mi><mi>S</mi><mi>D</mi><mo stretchy="false">(</mo><mi>q</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>p</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">JSD(p||q)=JSD(q||p)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.09618em;">J</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mord">∣∣</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.09618em;">J</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mord">∣∣</span><span class="mord mathnormal">p</span><span class="mclose">)</span></span></span></span>, and thus a metric.  It necessarily loses some subtlety in doing so, however...</p>
<p>I expect what you're doing can probably be expressed just by looking at covariances vs conditional covariances.  That's much easier to think about and calculate.  If not, and you can produce a scatter plot showing that say a covariance is zero but the two variables are obviously <em>not independent</em> just by looking at the scatter plot, then indeed information theory can definitely help you.</p>



<a name="459955820"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/Relative%20entropy%20variable%20contributions/near/459955820" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Kalan Kucera <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/Relative.20entropy.20variable.20contributions.html#459955820">(Aug 11 2024 at 23:27)</a>:</h4>
<p>I don't think that the result necessary needs to be symmetric, each distribution corresponding to a specific creep model may, or may not, contribute equally to the overall phenomena.</p>
<p>Covariance could capture it, perhaps, I will mess with my data and see what pops out. I like working with information because the interpretation of what information represents physically is kind of what I'm trying to get at. </p>
<p>e.g., mechanisms in my field are particular pathways that some State Change of a physical system may undergo... I'm trying to show that, given categories of models, there can be some equivalence of pathways through state changes on the basis of some measure of information. I like KL because the image of a shift away from a model (which may be accurate to reality and precise to reality to varying degrees) works into that concept for me.</p>
<p>I don't know if any of that is clarifying lol. Thank you for the tips though, I really appreciate it!!</p>



<a name="459957976"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/Relative%20entropy%20variable%20contributions/near/459957976" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Kalan Kucera <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/Relative.20entropy.20variable.20contributions.html#459957976">(Aug 12 2024 at 00:05)</a>:</h4>
<p>A follow up: If I was going to look at the JSD, and had say 3 exp. models (P, Q, S) and 1 reference model (R), would I be calculating different "information radii" relative to R if I calculated JSD(P||Q), JSD(Q||S) and JSD (P||S)?</p>



<a name="459958198"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/Relative%20entropy%20variable%20contributions/near/459958198" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Eric M Downes <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/Relative.20entropy.20variable.20contributions.html#459958198">(Aug 12 2024 at 00:09)</a>:</h4>
<p>JSD works just like a metric so all your intuition applies, in particular<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo stretchy="false">)</mo><mo>≤</mo><mi>d</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>+</mo><mi>d</mi><mo stretchy="false">(</mo><mi>y</mi><mo separator="true">,</mo><mi>z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">d(x,z)\leq d(x,y)+d(y,z)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span></span></span></span><br>
for any metric, so you can measure something useful by looking at the rhs minus the lhs.  You could try that for different models <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span>.</p>



<a name="459968920"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/Relative%20entropy%20variable%20contributions/near/459968920" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Eric M Downes <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/Relative.20entropy.20variable.20contributions.html#459968920">(Aug 12 2024 at 01:57)</a>:</h4>
<p>But, if you're doing physics... do you know what the (physical) entropy of the states at the beginning and end of the paths are?  Or a state equation?  There are a lot of calculations from thermodynamics that come to mind if you do.</p>



<footer class="site-footer">

<hr><p>Last updated: Nov 01 2025 at 12:09 UTC</p>
This archive runs on a customization of <a href="https://github.com/zulip/zulip-archive">zulip-archive</a>
</footer>
</body>

</html>