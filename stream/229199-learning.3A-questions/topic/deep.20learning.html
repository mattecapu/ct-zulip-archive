<!DOCTYPE html>
<html>
<head>
  	<meta charset="utf-8" />
  	<meta http-equiv="X-UA-Compatible" content="IE=edge" />
  	<meta name="viewport" content="width=device-width, initial-scale=1" />
  
<link rel="stylesheet" href="https://mattecapu.github.io/ct-zulip-archive/style.css" /><title>deep learning · learning: questions · Zulip Chat Archive</title>
</head>
<body>
<header>
<a href="https://mattecapu.github.io/ct-zulip-archive" class="home-link">
        <img class="logo" src="https://zulip-avatars.s3.amazonaws.com/21317/realm/icon.png?version=3" />
        <h1>Category Theory<br/>Zulip Server<br/>Archive</h1>
        </a>
        <p>
        You're reading the public-facing archive of the <a href="https://categorytheory.zulipchat.com/">Category Theory Zulip server</a>.<br/>
        
        To join the server you need an invite. Anybody can get an invite by contacting <a href="https://matteocapucci.wordpress.com">Matteo Capucci</a> at <em>name dot surname at gmail dot com</em>.<br/>
        
        For all things related to this archive refer to the same person.
        </p>
        </header>
        <hr />
    
<h2>Stream: <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/index.html">learning: questions</a></h2>
<h3>Topic: <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html">deep learning</a></h3>

<hr>

<base href="https://categorytheory.zulipchat.com">

<a name="228284940"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228284940" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Joshua Meyers <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228284940">(Mar 01 2021 at 18:48)</a>:</h4>
<p>What are your goals in learning category theory <span class="user-mention" data-user-id="393406">@joaogui1 (he/him)</span>?</p>



<a name="228301052"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228301052" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> joaogui1 (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228301052">(Mar 01 2021 at 20:32)</a>:</h4>
<p>Because I love math and the abstractions of CT look really interesting. Second because I'm working on Deep Learning and I feel like a lot of stuff could benefit at least from categorical inspirations (compositionality is pretty much one of the assumptions of Deep Learning). Finally I feel like compositionality is a powerful idea in general, showing up in things like shell, Lisps. JAX and Julia</p>



<a name="228301808"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228301808" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Jules Hedges <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228301808">(Mar 01 2021 at 20:37)</a>:</h4>
<p>Ok! For deep learning in particular there are (a very small number of) specific papers you should read - with Backprop As Functor at the top of the list if you don't already know it - and (an equally small number of) specific people you should talk to - I'll tag <span class="user-mention" data-user-id="276875">@Bruno Gavranovic</span></p>



<a name="228303849"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228303849" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> joaogui1 (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228303849">(Mar 01 2021 at 20:52)</a>:</h4>
<p>He seems to have some pretty cool papers, nice!</p>



<a name="228304478"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228304478" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> John Baez <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228304478">(Mar 01 2021 at 20:56)</a>:</h4>
<p>Great question, <span class="user-mention" data-user-id="280784">@Joshua Meyers</span>!   There are many reasons for studying category theory, and how one should study it depends on what one is trying to do.</p>



<a name="228305276"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228305276" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> joaogui1 (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228305276">(Mar 01 2021 at 21:01)</a>:</h4>
<p>Hey <span class="user-mention" data-user-id="276875">@Bruno Gavranovic</span> what do you recommend for someone interested in ACT for Deep Learning?</p>



<a name="228326567"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228326567" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Joshua Meyers <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228326567">(Mar 01 2021 at 23:37)</a>:</h4>
<p>I definitely also recommend Backprop as Functor if you haven't already read it</p>



<a name="228328214"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228328214" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Joshua Meyers <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228328214">(Mar 01 2021 at 23:50)</a>:</h4>
<p>If you love math and are interested in category theory in its own right, you should look at something which is about pure category theory.  I really like these notes: <a href="https://home.gwu.edu/~wschmitt/papers/cat.pdf">https://home.gwu.edu/~wschmitt/papers/cat.pdf</a>  After working through these notes, I used Emily Riehl's book, which has a lot of examples from different fields of math --- if you don't know those fields, you won't get all the examples, but you can just skip the examples you don't get.  I've also heard other computer science people say they liked Awodey's book, though I have not looked at it much personally.  "Algebra Chapter 0" and "Topology: A Categorical Approach" would be great if you want to learn algebra and topology, do you want to learn these things?</p>



<a name="228328272"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228328272" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Joshua Meyers <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228328272">(Mar 01 2021 at 23:50)</a>:</h4>
<p>There are many directions you can go with this, it depends largely on which direction you want to go in.</p>



<a name="228330207"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228330207" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> joaogui1 (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228330207">(Mar 02 2021 at 00:06)</a>:</h4>
<p>They are among the things I want to learn. I've always been fascinated by Algebra and tried to take it when I began college, but Brazil's curricula are very strict and I only maanaged to audit the class. And topology also looks cool and useful for DL</p>



<a name="228333671"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228333671" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Joshua Meyers <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228333671">(Mar 02 2021 at 00:37)</a>:</h4>
<p>Then yeah those books sound good!</p>



<a name="228454592"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228454592" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Bruno Gavranović <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228454592">(Mar 02 2021 at 17:52)</a>:</h4>
<p><span class="user-mention silent" data-user-id="393406">joaogui1 (he/him)</span> <a href="#narrow/stream/229199-learning.3A-questions/topic/beginner.20questions/near/228305276">said</a>:</p>
<blockquote>
<p>Hey <span class="user-mention silent" data-user-id="276875">Bruno Gavranovic</span> what do you recommend for someone interested in ACT for Deep Learning?</p>
</blockquote>
<p>Hi Joao! Unfortunately ACT for Deep Learning is a relatively niche field, and I'm not sure if there's any introductory texts focused on understanding CT with examples from Deep learning. <br>
If what you're looking for is papers, then you're sort of in luck, because there's a few. I compiled a list a while ago <a href="https://github.com/bgavran/Category_Theory_Machine_Learning">https://github.com/bgavran/Category_Theory_Machine_Learning</a>  but most of these are probably pretty abstract if you're just getting into this. Nonetheless, as Jules says - it's good to read those and see what kind of things people are doing, even if its just getting a taste.</p>
<p>Interestingly enough, there's been a new paper on arxiv today (<a href="https://arxiv.org/abs/2103.01189">https://arxiv.org/abs/2103.01189</a>) about learners, and actually we should have our paper on Categorical Foundations of Gradient-Based Learning up on arxiv very very soon :)</p>



<a name="228456785"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228456785" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Jules Hedges <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228456785">(Mar 02 2021 at 18:05)</a>:</h4>
<p>Besides backprop as functor, you could do worse than starting with one of Bruno's recorded talks on Youtube</p>



<a name="228456873"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228456873" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Jules Hedges <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228456873">(Mar 02 2021 at 18:05)</a>:</h4>
<p>Since this is a recently active research topic, a bunch of happened during coronatime, which means recorded seminars</p>



<a name="228496898"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228496898" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Capucci (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228496898">(Mar 02 2021 at 22:17)</a>:</h4>
<p>Also I suggest getting acquainted with optics (e.g. from Riley's 'Category of optics' paper) and theleological string diagrams (I guess from <span class="user-mention" data-user-id="275901">@Jules Hedges</span> first paper on games? idk)</p>



<a name="228505730"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228505730" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Jules Hedges <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228505730">(Mar 02 2021 at 23:25)</a>:</h4>
<p>This is probably overkill as a starting point...</p>



<a name="228505932"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228505932" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Jules Hedges <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228505932">(Mar 02 2021 at 23:27)</a>:</h4>
<p>If you follow machine learning in the same direction as us (which I <em>think</em> is the "canonical" way of taking seriously the existing compositionality of deep learning - but being wrong is always an option, there could be some totally different way you could go) - you'll eventually meet the question "what the heck does game theory have to do with anything"</p>



<a name="228510988"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228510988" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> joaogui1 (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228510988">(Mar 03 2021 at 00:11)</a>:</h4>
<p>yeah, I keep seeing stuff like open games, what the heck does it have to do with anything?</p>



<a name="228515593"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228515593" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> John Baez <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228515593">(Mar 03 2021 at 00:57)</a>:</h4>
<p>Learning can be seen as a kind of game: that's a pretty basic observation.</p>



<a name="228520351"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228520351" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Jason Erbele <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228520351">(Mar 03 2021 at 01:44)</a>:</h4>
<p>That's kind of what I was thinking – why <em>wouldn't</em> game theory be involved in machine learning?</p>



<a name="228520716"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228520716" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Georgios Bakirtzis <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228520716">(Mar 03 2021 at 01:48)</a>:</h4>
<p>Ok why would it? (I know the answer btw but I don't think it is a basic observation and I am not sure I can answer succinctly)</p>



<a name="228522071"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228522071" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Jason Erbele <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228522071">(Mar 03 2021 at 02:02)</a>:</h4>
<p>As an outsider to ML, I don't have a good answer for exactly how it should connect.  But there has to be more than a superficial connection between learning goals and player goals, learning strategies and game theoretic strategies, etc.  Any kind of learning system/environment should at least be expressible as a formal game, and from there, game theory ought to at least offer some insights.  Same should apply to human learning, as well.</p>



<a name="228522348"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228522348" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Jason Erbele <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228522348">(Mar 03 2021 at 02:05)</a>:</h4>
<p>By the way, just because something is a basic observation doesn't necessarily mean it's an easy observation to make, especially for the first time.  E.g. it's a basic observation that the number zero is important to mathematics.</p>



<a name="228550024"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228550024" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Capucci (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228550024">(Mar 03 2021 at 07:48)</a>:</h4>
<p><span class="user-mention silent" data-user-id="275901">Jules Hedges</span> <a href="#narrow/stream/229199-learning.3A-questions/topic/beginner.20questions/near/228505730">said</a>:</p>
<blockquote>
<p>This is probably overkill as a starting point...</p>
</blockquote>
<p>Well, I said getting acquainted, not full expert. Bruno mentions optics like 5 minutes in his MSP101 talk, I guess. Also many theleological diagrams are drawn, so it's better to understand what's going on.</p>



<a name="228550127"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228550127" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Capucci (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228550127">(Mar 03 2021 at 07:49)</a>:</h4>
<p>Maybe the first of your Max Planck lectures would be a great place to get a quick intro to the diagrams</p>



<a name="228563628"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228563628" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Fawzi Hreiki <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228563628">(Mar 03 2021 at 09:50)</a>:</h4>
<p>I think the intuitive answer is that game theory studies distributed decision making and that intelligence rarely (if ever) emerges from individual decision making as opposed to distributed decision making</p>



<a name="228571446"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228571446" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Jules Hedges <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228571446">(Mar 03 2021 at 10:44)</a>:</h4>
<p>This is all true, but the connection been categorical approach to machine learning and game theory is more subtle than that. They're structurally the same. I think the true answer is actually closer to "game theory is a kind of machine learning" than the other way round - the central idea of compositional game theory turned out in retrospect to be a sort of "backpropagation of payoffs". In Strathclyde we're working towards a proper grand unification, but none of it's written down yet...</p>



<a name="228571858"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228571858" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> joaogui1 (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228571858">(Mar 03 2021 at 10:48)</a>:</h4>
<p>This looks extremly interesting :D</p>



<a name="228684170"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228684170" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> joaogui1 (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228684170">(Mar 03 2021 at 22:59)</a>:</h4>
<p><span class="user-mention silent" data-user-id="275932">Matteo Capucci (he/him)</span> <a href="#narrow/stream/229199-learning.3A-questions/topic/beginner.20questions/near/228550024">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="275901">Jules Hedges</span> <a href="#narrow/stream/229199-learning.3A-questions/topic/beginner.20questions/near/228505730">said</a>:</p>
<blockquote>
<p>This is probably overkill as a starting point...</p>
</blockquote>
<p>Well, I said getting acquainted, not full expert. Bruno mentions optics like 5 minutes in his MSP101 talk, I guess. Also many theleological diagrams are drawn, so it's better to understand what's going on.</p>
</blockquote>
<p>Is there a link to a recording of that talk?</p>



<a name="228684203"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228684203" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> joaogui1 (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228684203">(Mar 03 2021 at 23:00)</a>:</h4>
<p><span class="user-mention silent" data-user-id="275920">John Baez</span> <a href="#narrow/stream/229199-learning.3A-questions/topic/beginner.20questions/near/228684093">said</a>:</p>
<blockquote>
<p>Which talk?  Right now we're talking about ancient Greek phonetics for some reason.</p>
</blockquote>
<p>Sorry, still getting the hang of zulip</p>



<a name="228684639"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228684639" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> John Baez <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228684639">(Mar 03 2021 at 23:03)</a>:</h4>
<p>Yeah, I do that too: respond to a comment after the conversation has moved on, without noticing...</p>



<a name="228685003"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228685003" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> John Baez <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228685003">(Mar 03 2021 at 23:05)</a>:</h4>
<p>I found slides for an MSP101 talk by <span class="user-mention" data-user-id="276875">@Bruno Gavranovic</span> on "Categorical Foundation of Gradient-Based Learning":</p>
<p><a href="http://msp.cis.strath.ac.uk/msp101.html">http://msp.cis.strath.ac.uk/msp101.html</a></p>
<p>But no video, because it's a talk from "BC": before coronavirus.</p>



<a name="228685460"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228685460" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> joaogui1 (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228685460">(Mar 03 2021 at 23:08)</a>:</h4>
<p>A shame, but thanks!</p>



<a name="228685842"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228685842" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Dylan Braithwaite <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228685842">(Mar 03 2021 at 23:11)</a>:</h4>
<p>I think the talk you mention does have a video link on that page, John: <a href="https://www.youtube.com/watch?v=ji8MHKlQZ9w">https://www.youtube.com/watch?v=ji8MHKlQZ9w</a></p>
<div class="youtube-video message_inline_image"><a data-id="ji8MHKlQZ9w" href="https://www.youtube.com/watch?v=ji8MHKlQZ9w"><img src="https://i.ytimg.com/vi/ji8MHKlQZ9w/default.jpg"></a></div>



<a name="228685928"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228685928" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Conor McBride <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228685928">(Mar 03 2021 at 23:12)</a>:</h4>
<p>You beat me to it. It was a great talk!</p>



<a name="228686361"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228686361" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> joaogui1 (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228686361">(Mar 03 2021 at 23:15)</a>:</h4>
<p>Thanks :D</p>



<a name="228689262"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228689262" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> John Baez <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228689262">(Mar 03 2021 at 23:41)</a>:</h4>
<p>Oh - it said "slides" right over the talk title but those slides were for the <em>previous</em> talk.</p>



<a name="228689407"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228689407" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> John Baez <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228689407">(Mar 03 2021 at 23:42)</a>:</h4>
<p>I found this talk by cleverly typing "MSP101 bruno" into Google.</p>



<a name="228732503"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228732503" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Notification Bot <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228732503">(Mar 04 2021 at 08:15)</a>:</h4>
<p>This topic was moved here from <a class="stream-topic" data-stream-id="229199" href="/#narrow/stream/229199-learning.3A-questions/topic/beginner.20questions">#learning: questions &gt; beginner questions</a> by <span class="user-mention silent" data-user-id="275932">Matteo Capucci (he/him)</span></p>



<a name="228732504"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228732504" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Notification Bot <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228732504">(Mar 04 2021 at 08:15)</a>:</h4>
<p>This topic was moved by <span class="user-mention silent" data-user-id="275932">Matteo Capucci (he/him)</span> to <a class="stream-topic" data-stream-id="229451" href="/#narrow/stream/229451-general.3A-off-topic/topic/greek.20shenanigans.20and.20misspelled.20words">#general: off-topic &gt; greek shenanigans and misspelled words</a></p>



<a name="228732717"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228732717" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Capucci (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228732717">(Mar 04 2021 at 08:17)</a>:</h4>
<p><span class="user-mention silent" data-user-id="275920">John Baez</span> <a href="#narrow/stream/229199-learning.3A-questions/topic/beginner.20questions/near/228689407">said</a>:</p>
<blockquote>
<p>I found this talk by cleverly typing "MSP101 bruno" into Google.</p>
</blockquote>
<p>never underestimate the power of googling</p>



<a name="228732862"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228732862" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Capucci (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228732862">(Mar 04 2021 at 08:18)</a>:</h4>
<p>There's also his other talk for the CyberCats seminar <a href="https://www.youtube.com/watch?v=tKM8JdXJEII">https://www.youtube.com/watch?v=tKM8JdXJEII</a><br>
AFAIR there's a lot of overlap between the two, but just in case</p>
<div class="youtube-video message_inline_image"><a data-id="tKM8JdXJEII" href="https://www.youtube.com/watch?v=tKM8JdXJEII"><img src="https://i.ytimg.com/vi/tKM8JdXJEII/default.jpg"></a></div>



<a name="228737449"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228737449" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Dylan Braithwaite <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228737449">(Mar 04 2021 at 09:00)</a>:</h4>
<p><span class="user-mention silent" data-user-id="275901">Jules Hedges</span> <a href="#narrow/stream/229199-learning.3A-questions/topic/beginner.20questions/near/228571446">said</a>:</p>
<blockquote>
<p>I think the true answer is actually closer to "game theory is a kind of machine learning" than the other way round</p>
</blockquote>
<p>The correspondence I've seen already is that there's a functor from learners into games, which initially seems to suggest the converse to that. Does that suggest there's an interesting map in the other direction?</p>



<a name="228739144"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228739144" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Jason Erbele <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228739144">(Mar 04 2021 at 09:14)</a>:</h4>
<p>If there is a nice map in both directions (learners to games and games to learners), do we further have an adjunction between the two?</p>



<a name="228744752"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228744752" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Matteo Capucci (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228744752">(Mar 04 2021 at 10:01)</a>:</h4>
<p>It really depends on how you define stuff. I'm quite eager to make game and learners the same thing, since their categorical semantics is so similar. One key difference is in the computation of equilibria/learning process, but they can be put on the same footing as well (by swapping a gadget attached to them)<br>
It'd be nice to link to a paper now, but there's not one yet on this : <span aria-label="sweat smile" class="emoji emoji-1f605" role="img" title="sweat smile">:sweat_smile:</span></p>



<a name="228750781"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228750781" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Jules Hedges <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228750781">(Mar 04 2021 at 10:49)</a>:</h4>
<p><span class="user-mention silent" data-user-id="378472">Dylan Braithwaite</span> <a href="#narrow/stream/229199-learning.3A-questions/topic/beginner.20questions/near/228737449">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="275901">Jules Hedges</span> <a href="#narrow/stream/229199-learning.3A-questions/topic/beginner.20questions/near/228571446">said</a>:</p>
<blockquote>
<p>I think the true answer is actually closer to "game theory is a kind of machine learning" than the other way round</p>
</blockquote>
<p>The correspondence I've seen already is that there's a functor from learners into games, which initially seems to suggest the converse to that. Does that suggest there's an interesting map in the other direction?</p>
</blockquote>
<p>If you take the definitions exactly as given in Backprop As Functor and Compositional Game Theory then in a completely literal sense you get a functor from learners to games (I wrote the construction in this short tech report: <a href="https://arxiv.org/abs/1902.08666">https://arxiv.org/abs/1902.08666</a>), and I think not the other way. But in private we've been fiddling with the definitions of both so they are both subsumed under a single definition, since we had a gut feeling that it was a good idea. Mostly this involves making learners look more like games. In particular, almost all of the differences between the 2 papers arise from the fact that they're not talking about the differentiable structure that's in machine learning, they stick to Set (which in turn buys them some more generality to talk about other kinds of learners that don't use differentiation). Once you put the differentiable structure back into Backprop As Functor it <em>really</em> starts to look the same as open games - not that there's an adjunction or even an equivalence, but that they're literally the same category</p>



<a name="228807798"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228807798" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Bruno Gavranović <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228807798">(Mar 04 2021 at 16:48)</a>:</h4>
<p>Exactly - I'm still quite fascinated that it's now plausible to say that <em>exactly the same structure might be shared by learners and open games</em>. Now I'm actually thinking it might even be a good idea to create a stream here about category theory &amp; machine learning... there's definitely papers piling up, having finally  uploaded ours! :) <a href="https://arxiv.org/abs/2103.01931">Categorical Foundations of Gradient-Based Learning</a></p>



<a name="228808095"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228808095" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Morgan Rogers (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228808095">(Mar 04 2021 at 16:50)</a>:</h4>
<p><span class="user-mention" data-user-id="276875">@Bruno Gavranovic</span> do you want to mention that paper over on <a class="stream" data-stream-id="258900" href="/#narrow/stream/258900-practice.3A-our-papers">#practice: our papers</a> ?</p>



<a name="228808261"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228808261" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Bruno Gavranović <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228808261">(Mar 04 2021 at 16:50)</a>:</h4>
<p>Ah, I was just looking if there's a place to mention papers. Yes I will!</p>



<a name="228872878"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/228872878" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Peter Arndt <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#228872878">(Mar 05 2021 at 00:01)</a>:</h4>
<p>Please do create that stream on category theory &amp; machine learning! I would really like to teach a course on that, but I need some good arguments to convince the rest of my department...</p>



<a name="234258209"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/234258209" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Peiyuan Zhu <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#234258209">(Apr 13 2021 at 02:16)</a>:</h4>
<p>I’m reading Baez’s argument on Bayesian statistics. It’s interesting how he connects informational evolution and biological evolution.</p>



<a name="271662047"></a>
<h4><a href="https://categorytheory.zulipchat.com#narrow/stream/229199-learning%3A%20questions/topic/deep%20learning/near/271662047" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Peiyuan Zhu <a href="https://mattecapu.github.io/ct-zulip-archive/stream/229199-learning.3A-questions/topic/deep.20learning.html#271662047">(Feb 12 2022 at 01:54)</a>:</h4>
<p>I'm reading this article "Mathematics for AI: Categories, Toposes, Types": <a href="https://www.cambridge.org/core/books/mathematics-for-future-computing-and-communications/mathematics-for-ai-categories-toposes-types/F75B023A3C42FAB5D4F186376216FC76">https://www.cambridge.org/core/books/mathematics-for-future-computing-and-communications/mathematics-for-ai-categories-toposes-types/F75B023A3C42FAB5D4F186376216FC76</a></p>
<p>Here it talks about topos of a chain of feedforward neural network (is it just chain of neurons or actually chain of networks??). <a href="/user_uploads/21317/yAoFFFfHiUSbCSapCw46XvGZ/image.png">image.png</a> What does "freely generated" mean? Does "possible activities" mean the number of neurons that are active? Is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>b</mi><mi>a</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{ba}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ba</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> the same of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mrow><mi>b</mi><mi>a</mi></mrow></msub></mrow><annotation encoding="application/x-tex">W_{ba}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ba</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>? Does the functor sends a neuron to the multiplication of weights that precedes the neuron? What's the difference between <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Π</mi></mrow><annotation encoding="application/x-tex">\Pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Π</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span>? What is the functor <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="double-struck">X</mi></mrow><annotation encoding="application/x-tex">\mathbb{X}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6889em;"></span><span class="mord mathbb">X</span></span></span></span> trying to say? Since <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>w</mi><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup></mrow><annotation encoding="application/x-tex">w_a&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9989em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-2.453em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">a</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span> is undefined, I understand it as multiplying all the preceding weights like $W_a$, is the map <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>w</mi><mrow><mi>b</mi><mi>a</mi></mrow></msub><mo separator="true">,</mo><msubsup><mi>w</mi><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(w_{ba},w_a&#x27;)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ba</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-2.453em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">a</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> removing the weights between <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span></span></span></span> to get weights up to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span></span></span></span>? Is there a logical reason of defining such a presheaf? </p>
<div class="message_inline_image"><a href="/user_uploads/21317/yAoFFFfHiUSbCSapCw46XvGZ/image.png" title="image.png"><img src="/user_uploads/21317/yAoFFFfHiUSbCSapCw46XvGZ/image.png"></a></div><p>Here it talks about the subobject classifier of this topos, which I know exists but not sure why (How to get the subobject classifier out of a topos? <br>
 Can anyone provide a reference?). What does "localization <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn mathvariant="double-struck">1</mn><mi mathvariant="normal">∣</mi><mi>a</mi></mrow><annotation encoding="application/x-tex">\mathbb{1}|a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1∣</span><span class="mord mathnormal">a</span></span></span></span> mean? Why is it increasingly determined from initial layer to final layer? Why is it the "output information that an external observer can <strong>deduce</strong> from the activity within the inner layers"? <a href="/user_uploads/21317/_Q77JByv1TzHgezzAaRYQDzJ/image.png">image.png</a> </p>
<div class="message_inline_image"><a href="/user_uploads/21317/_Q77JByv1TzHgezzAaRYQDzJ/image.png" title="image.png"><img src="/user_uploads/21317/_Q77JByv1TzHgezzAaRYQDzJ/image.png"></a></div><p>Here it's talking about geometric morphism. Should I understand <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(A)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mclose">)</span></span></span></span> as the power set here? (which can be identified with subobject classifiers) <a href="/user_uploads/21317/VK5WpYbaE5CxxQioWdcSvj3N/image.png">image.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/21317/VK5WpYbaE5CxxQioWdcSvj3N/image.png" title="image.png"><img src="/user_uploads/21317/VK5WpYbaE5CxxQioWdcSvj3N/image.png"></a></div>



<footer class="site-footer">

<hr><p>Last updated: Nov 01 2025 at 12:09 UTC</p>
This archive runs on a customization of <a href="https://github.com/zulip/zulip-archive">zulip-archive</a>
</footer>
</body>

</html>